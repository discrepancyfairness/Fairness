{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "from time import time\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Import the three supervised learning models from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA    \n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#NG\n",
    "import time\n",
    "import pulp as p \n",
    "def min_sum_lpcna(data1,beta,eps,e,alpha,y):\n",
    "    import pulp as p \n",
    "    import math\n",
    "    #for bilal\n",
    "    #beta=[beta1[1], beta1[0],beta1[6],beta1[4],beta1[3],beta1[2],beta1[5]]\n",
    "    print(beta)\n",
    "    m=data1.shape[0]\n",
    "    n=data1.shape[1]\n",
    "    print('dimension of data')\n",
    "    print(m,n)\n",
    "    \n",
    "    ################ sorted result\n",
    "    a1=0\n",
    "    a2=0\n",
    "    b1=0\n",
    "    b2=0\n",
    "    c1=0\n",
    "    c2=0\n",
    "    d1=0\n",
    "    d2=0\n",
    "    e1=0\n",
    "    e2=0\n",
    "    h1=[]\n",
    "    h2=[]\n",
    "    h3=[]\n",
    "    h4=[]\n",
    "    h5=[]\n",
    "    h6=[]\n",
    "    h7=[]\n",
    "    key1=[]\n",
    "    key2=[]\n",
    "    key3=[]\n",
    "    key4=[]\n",
    "    key5=[]\n",
    "    key6=[]\n",
    "    key7=[]\n",
    "    cost=np.zeros(n,dtype=int)\n",
    "    data2=np.zeros((m,n),dtype=int)\n",
    "    for i in range(n):\n",
    "        if data1[0][i]==1:            \n",
    "\n",
    "            h1.append(e[i][1])\n",
    "            key1.append(i)\n",
    "            if data1[2][i]==1:\n",
    "                a1=a1+1\n",
    "            elif data1[3][i]==1:\n",
    "                b1=b1+1\n",
    "            elif data1[4][i]==1:\n",
    "                c1=c1+1 \n",
    "            elif data1[5][i]==1:\n",
    "                d1=d1+1\n",
    "            elif data1[6][i]==1:\n",
    "                e1=e1+1\n",
    "\n",
    "        elif data1[1][i]==1:\n",
    "            h2.append(e[i][1])\n",
    "            key2.append(i)\n",
    "            if data1[2][i]==1:\n",
    "                a2=a2+1\n",
    "            elif data1[3][i]==1:\n",
    "                b2=b2+1\n",
    "            elif data1[4][i]==1:\n",
    "                c2=c2+1 \n",
    "            elif data1[5][i]==1:\n",
    "                d2=d2+1\n",
    "            elif data1[6][i]==1:\n",
    "                e2=e2+1\n",
    "            \n",
    "        if data1[2][i]==1:\n",
    "            h3.append(e[i][1])\n",
    "            key3.append(i)\n",
    "            \n",
    "        elif data1[3][i]==1:\n",
    "            h4.append(e[i][1])\n",
    "            key4.append(i)\n",
    "        elif data1[4][i]==1:\n",
    "            h5.append(e[i][1])\n",
    "            key5.append(i)\n",
    "        elif data1[5][i]==1:\n",
    "            h6.append(e[i][1])\n",
    "            key6.append(i)\n",
    "        elif data1[6][i]==1:\n",
    "            h7.append(e[i][1])\n",
    "            key7.append(i)\n",
    "#print(hc)\n",
    "#     print(key1)\n",
    "    \n",
    "    for i in range(1,len(h1)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h1[j-1]<h1[j]:\n",
    "                index=j\n",
    "                var=h1[j]\n",
    "                h1[j]=h1[j-1]\n",
    "                h1[j-1]=var\n",
    "\n",
    "                var2=key1[j]\n",
    "                key1[j]=key1[j-1]\n",
    "                key1[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "\n",
    "    for i in range(1,len(h2)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h2[j-1]<h2[j]:\n",
    "                index=j\n",
    "                var=h2[j]\n",
    "                h2[j]=h2[j-1]\n",
    "                h2[j-1]=var\n",
    "\n",
    "                var2=key2[j]\n",
    "                key2[j]=key2[j-1]\n",
    "                key2[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "    for i in range(1,len(h3)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h3[j-1]<h3[j]:\n",
    "                index=j\n",
    "                var=h3[j]\n",
    "                h3[j]=h3[j-1]\n",
    "                h3[j-1]=var\n",
    "\n",
    "                var2=key3[j]\n",
    "                key3[j]=key3[j-1]\n",
    "                key3[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "    for i in range(1,len(h4)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h4[j-1]<h4[j]:\n",
    "                index=j\n",
    "                var=h4[j]\n",
    "                h4[j]=h4[j-1]\n",
    "                h4[j-1]=var\n",
    "\n",
    "                var2=key4[j]\n",
    "                key4[j]=key4[j-1]\n",
    "                key4[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "    for i in range(1,len(h5)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h3[j-1]<h5[j]:\n",
    "                index=j\n",
    "                var=h5[j]\n",
    "                h5[j]=h5[j-1]\n",
    "                h5[j-1]=var\n",
    "\n",
    "                var2=key5[j]\n",
    "                key5[j]=key5[j-1]\n",
    "                key5[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "                \n",
    "                \n",
    "    for i in range(1,len(h6)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h6[j-1]<h6[j]:\n",
    "                index=j\n",
    "                var=h6[j]\n",
    "                h6[j]=h6[j-1]\n",
    "                h6[j-1]=var\n",
    "\n",
    "                var2=key6[j]\n",
    "                key6[j]=key6[j-1]\n",
    "                key6[j-1]=var2\n",
    "            else:\n",
    "                break        \n",
    "                \n",
    "\n",
    "    for i in range(1,len(h7)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h7[j-1]<h7[j]:\n",
    "                index=j\n",
    "                var=h7[j]\n",
    "                h7[j]=h7[j-1]\n",
    "                h7[j-1]=var\n",
    "\n",
    "                var2=key7[j]\n",
    "                key7[j]=key7[j-1]\n",
    "                key7[j-1]=var2\n",
    "            else:\n",
    "                break \n",
    "    '''            \n",
    "    \n",
    "    for j in range(len(key1)):    \n",
    "        if h1[j]==h1[j-1] and j>=1:\n",
    "            data2[0][key1[j]]=data2[0][key1[j-1]]\n",
    "        else:    \n",
    "            data2[0][key1[j]]=j+1\n",
    "    for j in range(len(key2)):\n",
    "        if h2[j]==h2[j-1] and j>=1:\n",
    "            data2[1][key2[j]]=data2[0][key2[j-1]]\n",
    "        else:    \n",
    "            data2[1][key2[j]]=j+1\n",
    "    for j in range(len(key3)):\n",
    "        if h3[j]==h3[j-1] and j>=1:\n",
    "            data2[2][key3[j]]=data2[2][key3[j-1]]\n",
    "        else:    \n",
    "            data2[2][key3[j]]=j+1\n",
    "    for j in range(len(key4)):\n",
    "        if h4[j]==h4[j-1] and j>=1:\n",
    "            data2[3][key4[j]]=data2[3][key4[j-1]]\n",
    "        else:    \n",
    "            data2[3][key4[j]]=j+1\n",
    "    for j in range(len(key5)):\n",
    "        if h5[j]==h5[j-1] and j>=1:\n",
    "            data2[4][key5[j]]=data2[4][key5[j-1]]\n",
    "        else:    \n",
    "            data2[4][key5[j]]=j+1\n",
    "    for j in range(len(key6)):\n",
    "        if h6[j]==h6[j-1] and j>=1:\n",
    "            data2[5][key6[j]]=data2[5][key6[j-1]]\n",
    "        else:    \n",
    "            data2[5][key6[j]]=j+1\n",
    "    for j in range(len(key7)):\n",
    "        if h7[j]==h7[j-1] and j>=1:\n",
    "            data2[6][key7[j]]=data2[6][key7[j-1]]\n",
    "        else:    \n",
    "            data2[6][key7[j]]=j+1 \n",
    "    '''\n",
    "    \n",
    "  ###############################1#################################  \n",
    "    #2nd approach\n",
    "    '''\n",
    "    for j in range(len(key1)):    \n",
    "        #data2[0][key1[j]]=((j+1)/((beta[0]*len(key1))*((beta[0]*len(key1))+1)/2)*alpha[0])\n",
    "         \n",
    "        data2[0][key1[j]]=(j+1)*alpha[0]\n",
    "    for j in range(len(key2)):\n",
    "        data2[1][key2[j]]=(j+1)*alpha[1]\n",
    "    for j in range(len(key3)):\n",
    "        if data1[2][key3[j]]==1 and data1[0][key3[j]]==1: \n",
    "            data2[2][key3[j]]=(j+1)*(len(key1)/len(key3))*alpha[2]\n",
    "        else:\n",
    "            data2[2][key3[j]]=(j+1)*(len(key2)/len(key3))*alpha[2]                  \n",
    "        \n",
    "    for j in range(len(key4)):\n",
    "        if data1[3][key4[j]]==1 and data1[0][key4[j]]==1:                   \n",
    "            data2[3][key4[j]]=(j+1)*(len(key1)/len(key4))*alpha[3]\n",
    "        else :                     \n",
    "            data2[3][key4[j]]=(j+1)*(len(key2)/len(key4))*alpha[3]\n",
    "                             \n",
    "    for j in range(len(key5)):\n",
    "        if data1[4][key5[j]]==1 and data1[0][key5[j]]==1:                  \n",
    "            data2[4][key5[j]]=(j+1)*(len(key1)/len(key5))*alpha[4]\n",
    "        else:      \n",
    "            data2[4][key5[j]]=(j+1)*(len(key2)/len(key5))*alpha[4]\n",
    "    for j in range(len(key6)):\n",
    "        if data1[5][key6[j]]==1 and data1[0][key6[j]]==1:                    \n",
    "            data2[5][key6[j]]=(j+1)*(len(key1)/len(key6))*alpha[5]\n",
    "        else:                    \n",
    "             data2[5][key6[j]]=(j+1)*(len(key2)/len(key6))*alpha[5]               \n",
    "    for j in range(len(key7)):\n",
    "        if data1[6][key7[j]]==1 and data1[0][key7[j]]==1:\n",
    "            data2[6][key7[j]]=(j+1)*(len(key1)/len(key7))*alpha[6]\n",
    "        else:\n",
    "             data2[6][key7[j]]=(j+1)*(len(key2)/len(key7))*alpha[6]\n",
    "\n",
    "    '''\n",
    "    \n",
    "    for j in range(len(key1)): \n",
    "        if y[key1[j]]==1:\n",
    "            data2[0][key1[j]]=1\n",
    "        else:\n",
    "            data2[0][key1[j]]=2\n",
    "    for j in range(len(key2)):\n",
    "        if y[key2[j]]==1:\n",
    "            data2[1][key2[j]]=1\n",
    "        else:    \n",
    "            data2[1][key2[j]]=2\n",
    "    for j in range(len(key3)):\n",
    "        if y[key3[j]]==1:\n",
    "            data2[2][key3[j]]=1\n",
    "        else:\n",
    "            data2[2][key3[j]]=2\n",
    "    for j in range(len(key4)):\n",
    "        if y[key4[j]]==1:\n",
    "            data2[3][key4[j]]=1\n",
    "        else:\n",
    "            data2[3][key4[j]]=2\n",
    "    for j in range(len(key5)):\n",
    "        if y[key5[j]]==1:\n",
    "            data2[4][key5[j]]=1\n",
    "        else:\n",
    "            data2[4][key5[j]]=2\n",
    "    for j in range(len(key6)):\n",
    "        if y[key6[j]]==1:\n",
    "            data2[5][key6[j]]=1 \n",
    "        else:\n",
    "            data2[5][key6[j]]=2\n",
    "    for j in range(len(key7)):\n",
    "        if y[key7[j]]==1:\n",
    "            data2[6][key7[j]]=1\n",
    "        else:\n",
    "            data2[6][key7[j]]=2\n",
    "        '''\n",
    "    \n",
    "    #1st approach\n",
    "    for j in range(len(key1)):    \n",
    "        #data2[0][key1[j]]=((j+1)/((beta[0]*len(key1))*((beta[0]*len(key1))+1)/2)*alpha[0])\n",
    "         \n",
    "        data2[0][key1[j]]=(j+1)*alpha[0]\n",
    "    for j in range(len(key2)):\n",
    "        data2[1][key2[j]]=(j+1)*alpha[1]\n",
    "    for j in range(len(key3)):\n",
    "        data2[2][key3[j]]=(j+1)*alpha[2]              \n",
    "        \n",
    "    for j in range(len(key4)):\n",
    "        data2[3][key4[j]]=(j+1)*alpha[3]\n",
    "        \n",
    "                             \n",
    "    for j in range(len(key5)):               \n",
    "        data2[4][key5[j]]=(j+1)*alpha[4]\n",
    "       \n",
    "    for j in range(len(key6)):\n",
    "        data2[5][key6[j]]=(j+1)*alpha[5]\n",
    "                    \n",
    "    for j in range(len(key7)):\n",
    "        data2[6][key7[j]]=(j+1)*alpha[6]\n",
    "    '''   \n",
    "    \n",
    "    #######################################################################    \n",
    "    \n",
    "    ####################################################################### \n",
    "   \n",
    "\n",
    "    for j in range(n):\n",
    "        summ=0\n",
    "        for i in range(m):\n",
    "       \n",
    "            summ=summ+data2[i][j] \n",
    "        cost[j]=summ\n",
    "        \n",
    "        \n",
    "    ################\n",
    "    \n",
    "    \n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "   \n",
    "    \n",
    "#     X=np.zeros(n+1,dtype=p.LpVariable)\n",
    "    X=np.zeros(n+m+1,dtype=p.LpVariable)\n",
    "    sizes=np.zeros(m,dtype=int)\n",
    "#     report_index(index,data1,e):  \n",
    "    max_size=0\n",
    "    for i in range(m):\n",
    "        count=0\n",
    "        for j in range(n):\n",
    "            if data1[i][j]==1:\n",
    "                count=count+1 \n",
    "        if count>max_size:\n",
    "            max_size=count\n",
    "        sizes[i]=count\n",
    "    print(sizes)    \n",
    "    #############################33\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ###############################\n",
    "        \n",
    "        \n",
    "        \n",
    "  \n",
    "    select_sizes=np.zeros(m,dtype=int)\n",
    "   \n",
    "    size_final=np.zeros(m,dtype=int)\n",
    "\n",
    "    \n",
    "    for i in range(n):\n",
    "        var1=str(i)       \n",
    "        X[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Integer')\n",
    "   \n",
    "    X[n]=p.LpVariable(str(n),lowBound=0,upBound=1,cat='Continuous')  \n",
    "\n",
    "    Lp_prob+= p.lpSum([(X[j])*cost[j] for j in range(n)]) \n",
    "    #Lp_prob+=1  \n",
    "    \n",
    "\n",
    "    ##############constraint#################\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "\n",
    "            Lp_prob += p.lpSum([(X[j])*(data1[i][j]) for j in range(n)]) >= math.floor(beta[i]*sizes[i])\n",
    "            Lp_prob += p.lpSum([(X[j])*(data1[i][j]) for j in range(n)]) <= math.ceil((beta[i]+eps)*sizes[i])\n",
    "           # Lp_prob += p.lpSum([(X[j])*(data1[i][j])*(sizes[i]-report_index(j,i,data1,e)+1) for j in range(n)]) <= X[n+i+1]\n",
    "\n",
    "    Lp_prob+= p.lpSum([(X[j])*cost[j] for j in range(n)])>=100\n",
    "        \n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status]) \n",
    "    print(\"objective is:\")        \n",
    "    print(p.value(Lp_prob.objective))\n",
    "    print(\"discripency is:\") \n",
    "    print(p.value(X[n]))\n",
    "    x=np.zeros(n,dtype=float)\n",
    "\n",
    "   # The solution status \n",
    "    Synth1={}\n",
    "    Synth2={}\n",
    "    # # Printing the final solution \n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])==1):\n",
    "            Synth1[i]=1 \n",
    "            Synth2[i]=-1\n",
    "#             if(data1[2][i]==1):\n",
    "#                 print(\"no\")\n",
    "        else:\n",
    "            Synth1[i]=-1\n",
    "            Synth2[i]=1\n",
    "    Synthu1=Synth1  \n",
    "    Synthu2=Synth2  \n",
    "    \n",
    "              \n",
    "    return Synthu1,Synthu2   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['random', 'randint', 'choice', 'triangular', 'seed', 'sample', 'uniform', 'shuffle']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "#SVM \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "from random import *\n",
    "from subprocess import check_output\n",
    "def adult_svm(X,Y):\n",
    "    #Split data into training and test datasets (training will be based on 70% of data)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0,shuffle=True) \n",
    "    #test_size: if integer, number of examples into test dataset; if between 0.0 and 1.0, means proportion\n",
    "    print('There are {} samples in the training set and {} samples in the test set'.format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "    \n",
    "    #Scaling data\n",
    "    #from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    #sc = StandardScaler(with_mean=False)\n",
    "    \n",
    "    \n",
    "    #sc.fit(X_train)\n",
    "    #X_train_std = sc.transform(X_train)\n",
    "    #X_test_std = sc.transform(X_test)\n",
    "\n",
    "    #X_train_std and X_test_std are the scaled datasets to be used in algorithms\n",
    "\n",
    "    #Applying SVC (Support Vector Classification)\n",
    "    from sklearn.svm import SVC\n",
    "    svm = SVC(kernel='rbf', random_state=0, gamma=.1, C=10.0,probability=True)\n",
    "    \n",
    "    print(Y_train.dtypes)\n",
    "    Y_train=Y_train.astype('int')\n",
    "    print(Y_train.dtypes)\n",
    "    \n",
    "    print(Y_test.dtypes)\n",
    "    Y_test=Y_test.astype('int')\n",
    "    print(Y_test.dtypes)\n",
    "    \n",
    "    \n",
    "    svm.fit(X_train, Y_train)\n",
    "    print('The accuracy of the SVM classifier on training data is {:.2f}'.format(svm.score(X_train, Y_train)))\n",
    "    print('The accuracy of the SVM classifier on test data is {:.2f}'.format(svm.score(X_test, Y_test)))\n",
    "    print('####Train prediction Label###############################################')\n",
    "    Y_train_pred=svm.predict(X_train)\n",
    "    #print(y_1)\n",
    "    Y_test_pred=svm.predict(X_test)\n",
    "\n",
    "    print('####Actual Train Label###############################################')\n",
    "\n",
    "\n",
    "    print('####Change to colors###############################################')\n",
    "        \n",
    "    e=svm.predict_proba(X_test)\n",
    "    print(e)\n",
    "    return X_test,Y_test_pred,Y_test,e\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without accuracy ---> 2\n",
    "def main(datax, y_test, y_test_pred,e): \n",
    "        \n",
    "    n=datax.shape[1]\n",
    "    s=datax.shape[0]    \n",
    "    data = np.zeros((s, n), dtype = int)\n",
    "    \n",
    "    r = np.zeros(n, dtype = int) \n",
    "    \n",
    "    for i in range(n):\n",
    "        if int(y_test.iloc[i])==1 :\n",
    "            r[i]=1\n",
    "        else :\n",
    "            r[i]= -1  \n",
    "    \n",
    "    r2 = np.zeros(n, dtype = int) \n",
    "    for i in range(n):\n",
    "        if int(y_test_pred[i])==1 :\n",
    "            r2[i]=1\n",
    "        else :\n",
    "            r2[i]= -1          \n",
    "    ar=[]\n",
    "    \n",
    "    for j in range(s):\n",
    "        print(\"sensitive attribute \",(j+1)) \n",
    "        a=0\n",
    "        b=0\n",
    "        acc1=0\n",
    "        acc2=0\n",
    "        for i in range(n):\n",
    "                data[j][i]= datax.iloc[j,i]\n",
    "                if data[j][i]== 1 :\n",
    "                    a=a+1\n",
    "                    if r[i]==1:\n",
    "                         acc1=acc1+1 \n",
    "\n",
    "        print(\"ACTUAL----------total ,accepted, aceeptance rate:\")             \n",
    "        a1=float(acc1/a)\n",
    "        print(a)\n",
    "        \n",
    "        print(acc1)\n",
    "        print(a1)\n",
    "        ar.append(a1)\n",
    "        \n",
    "    maxi= max(ar)\n",
    "    mini= min(ar)\n",
    "    DP=float(maxi-mini)\n",
    "    print(\"data acceptance rates\")\n",
    "    print(ar)\n",
    "    print(\"data DP\")\n",
    "    print(DP)\n",
    "    \n",
    "    ar=[]\n",
    "    \n",
    "    for j in range(s):\n",
    "        print(\"sensitive attribute \",(j+1)) \n",
    "        a=0\n",
    "        b=0\n",
    "        acc1=0\n",
    "        acc2=0\n",
    "        prec=0\n",
    "        reca=0\n",
    "        accur=0\n",
    "        FP=0\n",
    "        FN=0\n",
    "        TP=0\n",
    "        TN=0\n",
    "        for i in range(n):\n",
    "             if data[j][i]== 1 :\n",
    "                    a=a+1\n",
    "                    if r2[i]==1:\n",
    "                        acc1=acc1+1 \n",
    "                        if r[i]==1:\n",
    "                            TP=TP+1\n",
    "                        else:\n",
    "                             FP=FP+1                \n",
    "                    else:\n",
    "                        if r[i]==1:\n",
    "                            FN=FN+1\n",
    "                        else:\n",
    "                            TN=TN+1    \n",
    "        \n",
    "        print(\"prec reca accuracy for each sens\") \n",
    "        prec= float(TP/(TP+FP))\n",
    "        reca= float(TP/(TP+FN))\n",
    "        accur= float((TP+TN)/a)\n",
    "        print(prec,reca,accur)\n",
    "        \n",
    "        print(\"SVM----------total , accepted, aceeptance rate:\")             \n",
    "        \n",
    "        a1=float(acc1/a)\n",
    "        print(a)\n",
    "        \n",
    "        print(acc1)\n",
    "        print(a1)\n",
    "        ar.append(a1)\n",
    "        \n",
    "    maxi= max(ar)\n",
    "    mini= min(ar)\n",
    "    DP=float(maxi-mini)\n",
    "    print(\"data acceptance rates\")\n",
    "    print(ar)\n",
    "    print(\"data DP\")\n",
    "    print(DP) \n",
    "    \n",
    "    print(\"SVM accuracy--------------------------\")\n",
    "    prec=0\n",
    "    reca=0\n",
    "    accur=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    TP=0\n",
    "    TN=0\n",
    "    for i in range(n):\n",
    "            if r2[i]==1:\n",
    "                acc1=acc1+1 \n",
    "                if r[i]==1:\n",
    "                    TP=TP+1\n",
    "                else:\n",
    "                     FP=FP+1                \n",
    "            else:\n",
    "                if r[i]==1:\n",
    "                     FN=FN+1\n",
    "                else:\n",
    "                     TN=TN+1    \n",
    "\n",
    "        \n",
    "    prec= float(TP/(TP+FP))\n",
    "    reca= float(TP/(TP+FN))\n",
    "    accur= float((TP+TN)/n)\n",
    "    print(prec,reca,accur)\n",
    "    \n",
    "    \n",
    "#     delta1=[.70,.75,.80,.85,.90,.95]\n",
    "    #gamma=.05,.06,.07\n",
    "    #delta1=[.80,.85,.90,.95]\n",
    "# (for reproducibility)  \n",
    "\n",
    "# delta1=[.8], gama=[.1], epsilon=[.05]  \n",
    "# delta1=[.8], gama=[.15], epsilon=[.01]\n",
    " \n",
    "#     delta1=np.arange(1,.79,-.01)\n",
    "    \n",
    "#     gama=[.05,.1,.15,.2,.25]\n",
    "#     epsilon=[.01,.02,.05,.1,.15,.20,.25,.30,.35,.40,.50]\n",
    "\n",
    "#ADULT ZAFAR =? epsilon=[0.088 ,0.1656, 0.168,  0.211, 0.251 ] \n",
    " \n",
    "#agarwal=> epsilon=[ 0.071, 0.1271, 0.2437, 0.27 ]\n",
    " \n",
    "\n",
    "    #gama=[0.0869, 0.0521,0.0782, 0.0608,0.0434, 0.1,0.069,0.0434,0.034]\n",
    "    epsilon=[.01]\n",
    "    fi= np.zeros(n,dtype=int) \n",
    "#     for delta in delta1:\n",
    "    #4 gamma=[0.175442,    0.142103, 0.166039,    0.164754,  0.153465,    0.14,  0.104348   ]\n",
    "\n",
    "    #1 gamma=[0.259147,   0.0730028, 0.210139, 0.0893443, 0.306931, 0.0933333,  0.0347826]\n",
    "    #gamma=[0.196178,0.126722,   0.179654, 0.140164,     0.153465,   0.133333,  0.0695652]\n",
    "    '''\n",
    "    #agarwal\n",
    "    gamma2=  [[0.175442, 0.196178, 0.255673, 0.259147],\n",
    "      [0.142103 ,0.126722 ,0.0766758 ,0.0730028],\n",
    "      [ 0.166039 , 0.179654,  0.208084,  0.210139],\n",
    "      [0.164754 , 0.140164 , 0.101639 , 0.0893443],\n",
    "      [0.153465 , 0.153465,  0.287129 , 0.306931],\n",
    "      [0.14, 0.133333  ,0.0933333 , 0.0933333],\n",
    "      [0.104348, 0.0695652,0.0434783,0.0347826]]\n",
    "\n",
    "    '''\n",
    "    \n",
    "    #agar\n",
    "    # gamma2=[[0.175442], [0.142103],[0.166039],[0.164754],[0.153465],[0.14],[0.104348]]\n",
    "    \n",
    "    #gamma2=[[0.175442], [0.142103],[0.166039],[0.164754],[0.153465],[0.14],[0.104348]]\n",
    "    \n",
    "    \n",
    "    #bilal\n",
    "   # gamma2=[[.109868],[.15679],[.124507],[.111475],[.185643],[.140],[.0782608]]\n",
    "\n",
    "    \n",
    "    '''\n",
    "    \n",
    "     #bilal\n",
    "    gamma2=[[ 7.73645546,  8.12672176,  8.99908173, 10.30762167, 11.98347107, 13.08539945,\n",
    "     13.86593205, 14.09550046, 14.02662994, 15.22038567, 15.6795225 ]\n",
    "    ,[26.09922918, 25.51297362 ,24.15590055, 22.42970362 ,20.56237108 ,19.45499946\n",
    "     ,17.92422104 ,16.13288459, 14.07013354, 12.202801,   10.98686353]\n",
    "    ,[ 9.33333333,  9.33333333  ,8.66666667,  8.0      ,   9.33333333 , 9.33333333\n",
    "      ,9.33333333 , 9.33333333 ,13.33333333 ,11.33333333 ,14.0        ]\n",
    "    ,[29.7029703  ,29.45544554 ,27.97029703 ,27.47524752 ,27.22772277 ,25.24752475\n",
    "     ,24.25742574 ,24.25742574 ,21.78217822 ,19.30693069, 18.56435644]\n",
    "    ,[ 9.42622951 , 9.50819672 ,10.08196721 ,10.24590164  ,9.91803279, 10.08196721\n",
    "     ,10.40983607 ,10.98360656 ,11.39344262, 11.39344262 ,11.14754098]\n",
    "    ,[6.08695652 ,4.34782609 ,4.34782609 ,5.2173913,  6.08695652 ,7.82608696\n",
    "     ,8.69565217 ,6.08695652 ,5.2173913  ,6.95652174 ,7.82608696]\n",
    "    ,[21.27932865 ,20.9796198  ,20.23462922 ,19.36119198 ,18.5305703,  18.1024148\n",
    "     ,17.1775989 , 15.81606439, 14.16338414, 13.23000514 ,12.45076212]]\n",
    "    \n",
    "    gamma2=[[.07736455,.1198347107,.138659,.140266,.15679],\n",
    "[.26099,.2056237108,.179242,.140701,.109868],\n",
    "[.09333,.0933333,.093333,.13333,.140], \n",
    "[.297029,.27227,.2425742,.217821,.185643],\n",
    "[.097029,.099180,.104098,.11393,.111475],\n",
    "[.0608695652,.0608695,.086956,.052173,.0782608],\n",
    "[.21212793,0.185220071930125,.17177,.14163,.124507]\n",
    "]\n",
    "    gamma=np.transpose(gamma2)\n",
    "    '''\n",
    "\n",
    "#     gamma=[[0.30355010313755293, 0.10743801652892562, 0.252269224182223, 0.13278688524590163, 0.3118811881188119, 0.1, 0.13043478260869565]\n",
    "# ]\n",
    "    '''\n",
    "    alpha=[[1,1,1,1,1,1,1],[.1,1,1,1,1,1,1], [.01,1,1,1,1,1,1],[.001,1,1,1,1,1,1],\n",
    "           [1,.1,1,1,1,1,1], [1,.01,1,1,1,1,1],[1,.001,1,1,1,1,1],\n",
    "           [1,1,.1,1,1,1,1], [1,1,.01,1,1,1,1],[1,1,.001,1,1,1,1],\n",
    "           [1,1,1,.1,1,1,1], [1,1,1,.01,1,1,1],[1,1,1,.001,1,1,1],\n",
    "           [1,1,1,1,.1,1,1], [1,1,1,1,.01,1,1,],[1,1,1,1,.001,1,1],\n",
    "           [1,1,1,1,1,.1,1], [1,1,1,1,1,.01,1],[1,1,1,1,1,.001,1],\n",
    "           [1,1,1,1,1,1,.1], [1,1,1,1,1,1,.01],[1,1,1,1,1,1,.001],\n",
    "        [.1,.1,1,1,1,1,1],[.01,.01,1,1,1,1,1], [.001,.001,1,1,1,1,1],[.001,.01,1,1,1,1,1],[.001,.1,1,1,1,1,1],\n",
    "         [.01,.1,1,1,1,1,1] ]\n",
    "    '''  \n",
    "    #alpha=[[1,1,1,1,1,1,1], [1,1,1,1,.1,1,1], [1,1,1,1,.01,1,1,],[1,1,1,1,.001,1,1] ]         \n",
    "    #alpha=[[1,1,1,1,1,1,1], [1,1,1,1,.01,1,1], [.1,1,1,1,.01,1,1,],[1,.1,1,1,.01,1,1],[1,1,.01,1,.01,1,1], [1,1,.1,1,.1,1,1], [.1,1,.01,1,.01,1,1], [.01,1,.1,1,.1,1,1] ]        \n",
    "    alpha=[[1,1,1,1,1,1,1]]\n",
    "           #alpha=[90,40,100,10,4,1,10]\n",
    "    #alpha=[ 9211,  4356, 11678,  1220,   404,   150 ,  115]\n",
    "    a=0\n",
    "    print(alpha)\n",
    "    \n",
    "\n",
    "    #agarwal\n",
    "    '''\n",
    "    gamma2=    [[0.175442, 0.196178, 0.255673, 0.259147],\n",
    "                [0.142103,0.126722,0.0766758,0.0730028],\n",
    "                [0.166039,0.179654,0.208084,0.210139],\n",
    "                [0.164754,0.140164,0.101639,0.0893443],\n",
    "                [0.153465,0.153465,0.287129,0.306931],\n",
    "                [0.14,0.133333,0.0933333,0.0933333],\n",
    "                [0.104348,0.0695652,0.0434783,0.0347826]]\n",
    "                \n",
    "    gamma=np.transpose(gamma2)\n",
    "    '''\n",
    "    gamma= [[0.2591466724568451, 0.07392102846648302, 0.21013872238396986, 0.08934426229508197, 0.3069306930693069, 0.09333333333333334, 0.06956521739130435],\n",
    "[0.24025621539463685, 0.09182736455463728, 0.20106182565507794, 0.10491803278688525, 0.27970297029702973, 0.11333333333333333, 0.06086956521739131],\n",
    "[0.2213657583324286, 0.10996326905417815, 0.191984928926186, 0.11967213114754098, 0.25, 0.12666666666666668, 0.08695652173913043],\n",
    "[0.2024753012702204, 0.1283287419651056, 0.18282240109607809, 0.13524590163934427, 0.22277227722772278, 0.14, 0.11304347826086956],\n",
    "[0.18358484420801216, 0.14646464646464646, 0.17374550436718617, 0.15, 0.19306930693069307, 0.15333333333333332, 0.1391304347826087],\n",
    "[0.16469438714580392, 0.16483011937557393, 0.16466860763829422, 0.16475409836065574, 0.16584158415841585, 0.16666666666666666, 0.16521739130434782]]\n",
    "\n",
    "\n",
    "    \n",
    "    #for t in range(gamma.shape[0]):\n",
    "    #for t in range(28):\n",
    "    for new in range(6):\n",
    "        for t in range(1):\n",
    "            for eps in epsilon:\n",
    "                u1,u2=min_sum_lpcna(data,gamma[new],eps,e,alpha[t],r2)\n",
    "                #######################Disp_impact#######################  \n",
    "                print(\"gamma-epsilon-delta\",gamma[new],eps)\n",
    "                accu_all=[]\n",
    "                DP_all=[]\n",
    "                precision_all=[]\n",
    "                recall_all=[]\n",
    "                ar_all=[]\n",
    "                acceptance_rate=np.zeros((7,28),dtype=float)\n",
    "                count=0\n",
    "                print(\"<--------------------------------------->\")\n",
    "                print(\"iteration t\",t)\n",
    "        #                 for alpha in np.arange(0,1.05,0.05):\n",
    "        #                     print(\"alpha: \",alpha)\n",
    "        #                     for i in range(n):\n",
    "\n",
    "        #                         z=random()\n",
    "        #                         if z < alpha:\n",
    "        #                                fi[i]= u1[i] \n",
    "\n",
    "        #                         else:\n",
    "        #                                fi[i]= r2[i]\n",
    "\n",
    "                for i in range(n):\n",
    "                     fi[i] = u1[i]\n",
    "\n",
    "\n",
    "                for j in range(s):\n",
    "                    print(\"sensitive attribute \",(j+1)) \n",
    "\n",
    "                    TP=0\n",
    "                    FP=0\n",
    "                    FN=0\n",
    "                    TN=0\n",
    "                    precision=0\n",
    "                    recall=0\n",
    "                    for i in range(n):\n",
    "                         if data[j][i]== 1 :                        \n",
    "                            if fi[i]==1 and r[i]==1:\n",
    "                                TP=TP+1\n",
    "                            if fi[i]==1 and r[i]==-1:\n",
    "                                FP=FP+1 \n",
    "                            if fi[i]==-1 and r[i]==1:\n",
    "                                FN=FN+1\n",
    "                            if fi[i]==-1 and r[i]==-1:\n",
    "                                TN=TN+1    \n",
    "                    if TP+FP !=0:\n",
    "                        precision=float(TP/(TP+FP))\n",
    "                    #print(\"precision\",precision)\n",
    "                    if TP+FN !=0:    \n",
    "                        recall=float(TP/(TP+FN))\n",
    "                    #print(\"recall\",recall)\n",
    "\n",
    "                    precision_all.append(precision)\n",
    "                    recall_all.append(recall)\n",
    "                    #print(\"TP,FP,TN,FN\")\n",
    "                    #print(TP,FP,TN,FN)\n",
    "\n",
    "                    a=0\n",
    "                    b=0\n",
    "                    acc1=0\n",
    "                    acc2=0\n",
    "                    for i in range(n):\n",
    "                            if data[j][i]== 1 :\n",
    "                                a=a+1\n",
    "                                if fi[i]==1:\n",
    "                                     acc1=acc1+1 \n",
    "\n",
    "        #                         print(\"total ,fair accepted, aceeptance rate:\")             \n",
    "                    a1=float(acc1/a)\n",
    "\n",
    "\n",
    "\n",
    "        #                         print(a)\n",
    "        #                         print(acc1)\n",
    "        #                         print(a1)\n",
    "                    ar_all.append(a1)\n",
    "\n",
    "                count = count+1\n",
    "                maxi=max(ar_all)\n",
    "                mini= min(ar_all)\n",
    "                DP=float(maxi-mini)\n",
    "                print(\"individual acceptance rates\")\n",
    "                print(ar_all)\n",
    "                print(\"individul precision\")\n",
    "                print(precision_all)\n",
    "                print(\"individual recall\")\n",
    "                print(recall_all)\n",
    "                print(\"DP all\")\n",
    "                print(DP)\n",
    "                f_acc=0\n",
    "                for i in range(n):\n",
    "                     if fi[i] == r[i]:\n",
    "                            f_acc=f_acc+1\n",
    "                f_acc_l=float((f_acc*100)/n) \n",
    "\n",
    "        #######################################################################33   \n",
    "\n",
    "        #                         print(\"sensitive attribute \",(j+1)) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                TP=0\n",
    "                FP=0\n",
    "                FN=0\n",
    "                TN=0\n",
    "                precision=0\n",
    "                recall=0\n",
    "                accu=0\n",
    "                for i in range(n):\n",
    "                        if fi[i]==1 and r[i]==1:\n",
    "                            TP=TP+1\n",
    "                        if fi[i]==1 and r[i]==-1:\n",
    "                            FP=FP+1 \n",
    "                        if fi[i]==-1 and r[i]==1:\n",
    "                            FN=FN+1\n",
    "                        if fi[i]==-1 and r[i]==-1:\n",
    "                            TN=TN+1    \n",
    "\n",
    "                if TP+FP!=0:\n",
    "                    precision=float(TP/(TP+FP))\n",
    "                print(\"precision all\",precision)\n",
    "                if TP+FN!=0:\n",
    "                    recall=float(TP/(TP+FN))\n",
    "\n",
    "\n",
    "                print(\"recall all\",recall)\n",
    "                accu=float((TP+TN)/(TP+FN+TN+FP))\n",
    "\n",
    "\n",
    "                print(\"accuracy all\",accu)\n",
    "\n",
    "\n",
    "\n",
    "                print(\"TP,FP,TN,FN\")\n",
    "                print(TP,FP,TN,FN)\n",
    "        #                         print(\"total ,fair accepted, aceeptance rate:\")             \n",
    "                a1=float(acc1/a)\n",
    "\n",
    "\n",
    "    print(\"<--------------------------------------->\")\n",
    "    alpha_weight=np.arange(0,1.05,.05)        \n",
    "    return accu_all,DP_all,acceptance_rate,alpha_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "private             0.738877\n",
      "self-emp-not-inc    0.082853\n",
      "local-gov           0.068530\n",
      "state-gov           0.042404\n",
      "self-emp-inc        0.035608\n",
      "federal-gov         0.031265\n",
      "without-pay         0.000464\n",
      "Name: workclass, dtype: float64 \n",
      "\n",
      "hs-grad         0.326238\n",
      "some-college    0.221404\n",
      "bachelors       0.167230\n",
      "masters         0.053942\n",
      "assoc-voc       0.043333\n",
      "11th            0.034746\n",
      "assoc-acdm      0.033420\n",
      "10th            0.027187\n",
      "7th-8th         0.018467\n",
      "prof-school     0.017970\n",
      "9th             0.015085\n",
      "12th            0.012499\n",
      "doctorate       0.012433\n",
      "5th-6th         0.009548\n",
      "1st-4th         0.005006\n",
      "preschool       0.001492\n",
      "Name: education, dtype: float64 \n",
      "\n",
      "married-civ-spouse       0.466315\n",
      "never-married            0.322459\n",
      "divorced                 0.139712\n",
      "separated                0.031132\n",
      "widowed                  0.027419\n",
      "married-spouse-absent    0.012267\n",
      "married-af-spouse        0.000696\n",
      "Name: marital-status, dtype: float64 \n",
      "\n",
      "prof-specialty       0.133877\n",
      "craft-repair         0.133612\n",
      "exec-managerial      0.132352\n",
      "adm-clerical         0.123367\n",
      "sales                0.118825\n",
      "other-service        0.106492\n",
      "machine-op-inspct    0.065181\n",
      "transport-moving     0.052119\n",
      "handlers-cleaners    0.044758\n",
      "farming-fishing      0.032790\n",
      "tech-support         0.030237\n",
      "protective-serv      0.021351\n",
      "priv-house-serv      0.004741\n",
      "armed-forces         0.000298\n",
      "Name: occupation, dtype: float64 \n",
      "\n",
      "husband           0.413202\n",
      "not-in-family     0.256150\n",
      "own-child         0.148067\n",
      "unmarried         0.106492\n",
      "wife              0.046615\n",
      "other-relative    0.029474\n",
      "Name: relationship, dtype: float64 \n",
      "\n",
      "white                 0.859790\n",
      "black                 0.093396\n",
      "asian-pac-islander    0.029673\n",
      "amer-indian-eskimo    0.009482\n",
      "other                 0.007659\n",
      "Name: race, dtype: float64 \n",
      "\n",
      "male      0.675685\n",
      "female    0.324315\n",
      "Name: sex, dtype: float64 \n",
      "\n",
      "united-states                 0.911876\n",
      "mexico                        0.020224\n",
      "philippines                   0.006233\n",
      "germany                       0.004244\n",
      "puerto-rico                   0.003614\n",
      "canada                        0.003548\n",
      "el-salvador                   0.003315\n",
      "india                         0.003315\n",
      "cuba                          0.003050\n",
      "england                       0.002851\n",
      "jamaica                       0.002652\n",
      "south                         0.002354\n",
      "china                         0.002254\n",
      "italy                         0.002254\n",
      "dominican-republic            0.002221\n",
      "vietnam                       0.002122\n",
      "guatemala                     0.002089\n",
      "japan                         0.001956\n",
      "poland                        0.001857\n",
      "columbia                      0.001857\n",
      "iran                          0.001392\n",
      "taiwan                        0.001392\n",
      "haiti                         0.001392\n",
      "portugal                      0.001127\n",
      "nicaragua                     0.001094\n",
      "peru                          0.000995\n",
      "greece                        0.000961\n",
      "france                        0.000895\n",
      "ecuador                       0.000895\n",
      "ireland                       0.000796\n",
      "hong                          0.000630\n",
      "trinadad&tobago               0.000597\n",
      "cambodia                      0.000597\n",
      "laos                          0.000564\n",
      "thailand                      0.000564\n",
      "yugoslavia                    0.000530\n",
      "outlying-us(guam-usvi-etc)    0.000464\n",
      "hungary                       0.000431\n",
      "honduras                      0.000398\n",
      "scotland                      0.000365\n",
      "holand-netherlands            0.000033\n",
      "Name: native-country, dtype: float64 \n",
      "\n",
      "<=50k    0.751078\n",
      ">50k     0.248922\n",
      "Name: income, dtype: float64 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>state-gov</td>\n",
       "      <td>bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>never-married</td>\n",
       "      <td>adm-clerical</td>\n",
       "      <td>not-in-family</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.02174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>united-states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>self-emp-not-inc</td>\n",
       "      <td>bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>married-civ-spouse</td>\n",
       "      <td>exec-managerial</td>\n",
       "      <td>husband</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>united-states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>private</td>\n",
       "      <td>hs-grad</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>divorced</td>\n",
       "      <td>handlers-cleaners</td>\n",
       "      <td>not-in-family</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>united-states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>private</td>\n",
       "      <td>high-school</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>married-civ-spouse</td>\n",
       "      <td>handlers-cleaners</td>\n",
       "      <td>husband</td>\n",
       "      <td>black</td>\n",
       "      <td>male</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>united-states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>private</td>\n",
       "      <td>bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>married-civ-spouse</td>\n",
       "      <td>prof-specialty</td>\n",
       "      <td>wife</td>\n",
       "      <td>black</td>\n",
       "      <td>female</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>non-united-stated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age         workclass    education  education-num      marital-status  \\\n",
       "0  0.301370         state-gov    bachelors       0.800000       never-married   \n",
       "1  0.452055  self-emp-not-inc    bachelors       0.800000  married-civ-spouse   \n",
       "2  0.287671           private      hs-grad       0.533333            divorced   \n",
       "3  0.493151           private  high-school       0.400000  married-civ-spouse   \n",
       "4  0.150685           private    bachelors       0.800000  married-civ-spouse   \n",
       "\n",
       "          occupation   relationship   race     sex  capital-gain  \\\n",
       "0       adm-clerical  not-in-family  white    male       0.02174   \n",
       "1    exec-managerial        husband  white    male       0.00000   \n",
       "2  handlers-cleaners  not-in-family  white    male       0.00000   \n",
       "3  handlers-cleaners        husband  black    male       0.00000   \n",
       "4     prof-specialty           wife  black  female       0.00000   \n",
       "\n",
       "   capital-loss  hours-per-week     native-country  \n",
       "0           0.0        0.397959      united-states  \n",
       "1           0.0        0.122449      united-states  \n",
       "2           0.0        0.397959      united-states  \n",
       "3           0.0        0.397959      united-states  \n",
       "4           0.0        0.397959  non-united-stated  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            age  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
      "0      0.301370       0.800000      0.021740           0.0        0.397959   \n",
      "1      0.452055       0.800000      0.000000           0.0        0.122449   \n",
      "2      0.287671       0.533333      0.000000           0.0        0.397959   \n",
      "3      0.493151       0.400000      0.000000           0.0        0.397959   \n",
      "4      0.150685       0.800000      0.000000           0.0        0.397959   \n",
      "...         ...            ...           ...           ...             ...   \n",
      "45216  0.219178       0.800000      0.000000           0.0        0.397959   \n",
      "45217  0.301370       0.800000      0.000000           0.0        0.357143   \n",
      "45218  0.287671       0.800000      0.000000           0.0        0.500000   \n",
      "45219  0.369863       0.800000      0.054551           0.0        0.397959   \n",
      "45220  0.246575       0.800000      0.000000           0.0        0.602041   \n",
      "\n",
      "       s_female  s_male  r_amer-indian-eskimo  r_asian-pac-islander  r_black  \\\n",
      "0             0       1                     0                     0        0   \n",
      "1             0       1                     0                     0        0   \n",
      "2             0       1                     0                     0        0   \n",
      "3             0       1                     0                     0        1   \n",
      "4             1       0                     0                     0        1   \n",
      "...         ...     ...                   ...                   ...      ...   \n",
      "45216         0       1                     0                     0        0   \n",
      "45217         1       0                     0                     0        0   \n",
      "45218         0       1                     0                     0        0   \n",
      "45219         0       1                     0                     1        0   \n",
      "45220         0       1                     0                     0        0   \n",
      "\n",
      "       ...  occ_tech-support  occ_transport-moving  rls_husband  \\\n",
      "0      ...                 0                     0            0   \n",
      "1      ...                 0                     0            1   \n",
      "2      ...                 0                     0            0   \n",
      "3      ...                 0                     0            1   \n",
      "4      ...                 0                     0            0   \n",
      "...    ...               ...                   ...          ...   \n",
      "45216  ...                 0                     0            0   \n",
      "45217  ...                 0                     0            0   \n",
      "45218  ...                 0                     0            1   \n",
      "45219  ...                 0                     0            0   \n",
      "45220  ...                 0                     0            1   \n",
      "\n",
      "       rls_not-in-family  rls_other-relative  rls_own-child  rls_unmarried  \\\n",
      "0                      1                   0              0              0   \n",
      "1                      0                   0              0              0   \n",
      "2                      1                   0              0              0   \n",
      "3                      0                   0              0              0   \n",
      "4                      0                   0              0              0   \n",
      "...                  ...                 ...            ...            ...   \n",
      "45216                  0                   0              1              0   \n",
      "45217                  1                   0              0              0   \n",
      "45218                  0                   0              0              0   \n",
      "45219                  0                   0              1              0   \n",
      "45220                  0                   0              0              0   \n",
      "\n",
      "       rls_wife  nc_non-united-stated  nc_united-states  \n",
      "0             0                     0                 1  \n",
      "1             0                     0                 1  \n",
      "2             0                     0                 1  \n",
      "3             0                     0                 1  \n",
      "4             1                     1                 0  \n",
      "...         ...                   ...               ...  \n",
      "45216         0                     0                 1  \n",
      "45217         0                     0                 1  \n",
      "45218         0                     0                 1  \n",
      "45219         0                     0                 1  \n",
      "45220         0                     0                 1  \n",
      "\n",
      "[45221 rows x 59 columns]\n",
      "0    34013\n",
      "1    11208\n",
      "Name: income, dtype: int64\n",
      "There are 31654 samples in the training set and 13567 samples in the test set\n",
      "object\n",
      "int64\n",
      "object\n",
      "int64\n",
      "The accuracy of the SVM classifier on training data is 0.86\n",
      "The accuracy of the SVM classifier on test data is 0.85\n",
      "####Train prediction Label###############################################\n",
      "####Actual Train Label###############################################\n",
      "####Change to colors###############################################\n",
      "[[0.90610717 0.09389283]\n",
      " [0.96819087 0.03180913]\n",
      " [0.90842991 0.09157009]\n",
      " ...\n",
      " [0.87194343 0.12805657]\n",
      " [0.95868157 0.04131843]\n",
      " [0.95806118 0.04193882]]\n"
     ]
    }
   ],
   "source": [
    "# without accuracy\n",
    "import time\n",
    "# import pulp as p \n",
    "# from random import *\n",
    "\n",
    "# Add column names to data set\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', \n",
    "           'relationship', 'race','sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "\n",
    "# Read in train data\n",
    "adult_train = pd.read_csv('data/adult_actual/adult_train_data.csv', header=None, names=columns, skipinitialspace=True)\n",
    "\n",
    "# Drop the fnlwgt column which is useless for later analysis\n",
    "adult_train = adult_train.drop('fnlwgt', axis=1)\n",
    "\n",
    "# Read in test data\n",
    "adult_test = pd.read_csv('data/adult_actual/adult_test_data.csv', header=None, skiprows=1, names=columns, skipinitialspace=True)\n",
    "\n",
    "# Drop the fnlwgt column which is useless for later analysis\n",
    "adult_test = adult_test.drop('fnlwgt', axis=1)\n",
    "\n",
    "# Remove '.' in income column\n",
    "adult_test['income'] = adult_test['income'].apply(lambda x: '>50k' if x=='>50k.'  else '<=50k')\n",
    "\n",
    "\n",
    "# Convert '?' to NaNs and remove the entries with NaN value\n",
    "# Check missing value code and convert to NaNs\n",
    "object_col = adult_train.select_dtypes(include=object).columns.tolist()\n",
    "for col in object_col:\n",
    "    adult_train.loc[adult_train[col]=='?', col] = np.nan\n",
    "    adult_test.loc[adult_test[col]=='?', col] = np.nan\n",
    "\n",
    "# Perform an mssing assessment in each column of the dataset.\n",
    "col_missing_pct = adult_train.isna().sum()/adult_train.shape[0]\n",
    "col_missing_pct.sort_values(ascending=False)\n",
    "\n",
    "# Remove data entries with missing value\n",
    "adult_train = adult_train.dropna(axis=0, how='any')\n",
    "adult_test = adult_test.dropna(axis=0, how='any')\n",
    "\n",
    "# Show the results of the split\n",
    "# print(\"After removing the missing value:\")\n",
    "# print(\"Training set has {} samples.\".format(adult_train.shape[0]))\n",
    "# print(\"Testing set has {} samples.\".format(adult_test.shape[0]))\n",
    "for col in object_col:\n",
    "    print(adult_train[col].value_counts(dropna=False)/adult_train.shape[0],'\\n')\n",
    "# print(adult_train.head())\n",
    "# print(adult_test.head())    \n",
    "\n",
    "adult_train.reset_index(drop=True, inplace=True)\n",
    "adult_test.reset_index(drop=True, inplace=True)\n",
    "p=adult_train.shape[0]\n",
    "q =adult_test.shape[0]\n",
    "# reducing dimensionality of some very sparse features\n",
    "for i in range(0,p):\n",
    "    if adult_train.loc[i,'native-country'] not in [\"united-states\"] :\n",
    "               adult_train.loc[i,\"native-country\"] = \"non-united-stated\"        \n",
    "    if adult_train.loc[i,\"education\"] in [\"Preschool\", \"1st-4th\", \"5th-6th\", \"7th-8th\"]:\n",
    "               adult_train.loc[i,\"education\"] = \"prim-middle-school\"\n",
    "    elif adult_train.loc[i,\"education\"] in [\"9th\", \"10th\", \"11th\", \"12th\"]:\n",
    "               adult_train.loc[i,\"education\"] = \"high-school\"   \n",
    "    if adult_train.loc[i,'income'] in [\">50k\"] :\n",
    "               adult_train.loc[i,\"income\"] = 1 \n",
    "    else: \n",
    "               adult_train.loc[i,\"income\"] = 0         \n",
    "#reducing dimensionality of some very sparse features\n",
    "for i in range(0,q):                \n",
    "    if adult_test.loc[i,'native-country'] not in [\"united-states\"]:\n",
    "               adult_test.loc[i,'native-country'] = \"non-united-stated\"\n",
    "    if adult_test.loc[i,'education'] in [\"Preschool\", \"1st-4th\", \"5th-6th\", \"7th-8th\"]:\n",
    "               adult_test.loc[i,'education'] = \"prim-middle-school\"\n",
    "    elif adult_test.loc[i,'education'] in [\"9th\", \"10th\", \"11th\", \"12th\"]:\n",
    "               adult_test.loc[i,'education'] = \"high-school\"   \n",
    "    if adult_test.loc[i,'income'] in [\">50k\",\">50k.\"] :\n",
    "               adult_test.loc[i,\"income\"] = 1 \n",
    "    else: \n",
    "               adult_test.loc[i,\"income\"] = 0            \n",
    "# print(adult_train.head())\n",
    "# print(adult_test.head())\n",
    "DATA=pd.concat([adult_train,adult_test],ignore_index=True)\n",
    "# print(DATA.tail())\n",
    "m=DATA.shape[1]\n",
    "\n",
    "dat=DATA.iloc[:,0:m-1]\n",
    "\n",
    "\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "num_col = dat.dtypes[dat.dtypes != 'object'].index\n",
    "features_log_minmax_transform = pd.DataFrame(data = dat)\n",
    "features_log_minmax_transform[num_col] = scaler.fit_transform(features_log_minmax_transform[num_col])\n",
    "\n",
    "display(features_log_minmax_transform.head())\n",
    "\n",
    "# sens=DATA[['sex','race']]\n",
    "\n",
    "Data_c = pd.get_dummies(features_log_minmax_transform, columns=['sex','race','workclass','education','marital-status','occupation','relationship','native-country'], prefix =['s','r','work','edu','ms','occ','rls','nc'])\n",
    "r=DATA.iloc[:,m-1]\n",
    "print(Data_c)\n",
    "print(DATA['income'].value_counts())\n",
    "#marital\n",
    "#U=80, M=24928, S=11568, D=4612\n",
    "# m_3, m_0, m_1, m_2\n",
    "#age\n",
    "#>60 and <25= a_1\n",
    "#>=25and <=60 =a_2\n",
    "# print(data.head())\n",
    "# print(data.shape[0],data.shape[1])\n",
    "\n",
    "#sensitive columns name 0='age',2='marital'\n",
    "\n",
    "\n",
    "X_test,Y_test_pred,Y_test,e = adult_svm(Data_c , r)\n",
    "\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "# Y_test_pred.reset_index()\n",
    "Y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print(X_test)\n",
    "# print(Y_test_pred)\n",
    "# print(Y_test)\n",
    "sens=X_test[['s_male', 's_female'  ,'r_white', 'r_black', 'r_asian-pac-islander','r_amer-indian-eskimo','r_other']]\n",
    "# print(sens)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "     \n",
    "# for i in range(0,p):  \n",
    "#     if r.loc[i,'y'] == 1 :\n",
    "#                r.loc[i,\"y\"] = 1 \n",
    "#     else: \n",
    "#                r.loc[i,\"y\"] = 0 \n",
    "            \n",
    " \n",
    "            \n",
    "\n",
    "# print(sens.head())\n",
    "sensitive = sens.T\n",
    "\n",
    "# print(sensitive)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e)\n",
    "\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitive attribute  1\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "9211\n",
      "2796\n",
      "0.30355010313755293\n",
      "sensitive attribute  2\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "4356\n",
      "468\n",
      "0.10743801652892562\n",
      "sensitive attribute  3\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "11678\n",
      "2946\n",
      "0.252269224182223\n",
      "sensitive attribute  4\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "1220\n",
      "162\n",
      "0.13278688524590163\n",
      "sensitive attribute  5\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "404\n",
      "126\n",
      "0.3118811881188119\n",
      "sensitive attribute  6\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "150\n",
      "15\n",
      "0.1\n",
      "sensitive attribute  7\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "115\n",
      "15\n",
      "0.13043478260869565\n",
      "data acceptance rates\n",
      "[0.30355010313755293, 0.10743801652892562, 0.252269224182223, 0.13278688524590163, 0.3118811881188119, 0.1, 0.13043478260869565]\n",
      "data DP\n",
      "0.21188118811881188\n",
      "sensitive attribute  1\n",
      "prec reca accuracy for each sens\n",
      "0.7297863426895685 0.623032904148784 0.815546629030507\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "9211\n",
      "2387\n",
      "0.2591466724568451\n",
      "sensitive attribute  2\n",
      "prec reca accuracy for each sens\n",
      "0.7484276729559748 0.5085470085470085 0.9288337924701561\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "4356\n",
      "318\n",
      "0.07300275482093664\n",
      "sensitive attribute  3\n",
      "prec reca accuracy for each sens\n",
      "0.7330888345558272 0.6106585200271555 0.8456927556088372\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "11678\n",
      "2454\n",
      "0.21013872238396986\n",
      "sensitive attribute  4\n",
      "prec reca accuracy for each sens\n",
      "0.7339449541284404 0.49382716049382713 0.909016393442623\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "1220\n",
      "109\n",
      "0.08934426229508197\n",
      "sensitive attribute  5\n",
      "prec reca accuracy for each sens\n",
      "0.7338709677419355 0.7222222222222222 0.8316831683168316\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "404\n",
      "124\n",
      "0.3069306930693069\n",
      "sensitive attribute  6\n",
      "prec reca accuracy for each sens\n",
      "0.5 0.4666666666666667 0.9\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "150\n",
      "14\n",
      "0.09333333333333334\n",
      "sensitive attribute  7\n",
      "prec reca accuracy for each sens\n",
      "0.75 0.2 0.8869565217391304\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "115\n",
      "4\n",
      "0.034782608695652174\n",
      "data acceptance rates\n",
      "[0.2591466724568451, 0.07300275482093664, 0.21013872238396986, 0.08934426229508197, 0.3069306930693069, 0.09333333333333334, 0.034782608695652174]\n",
      "data DP\n",
      "0.27214808437365473\n",
      "SVM accuracy--------------------------\n",
      "0.7319778188539742 0.6066176470588235 0.8519201002432373\n",
      "[[1, 1, 1, 1, 1, 1, 1]]\n",
      "[0.2591466724568451, 0.07392102846648302, 0.21013872238396986, 0.08934426229508197, 0.3069306930693069, 0.09333333333333334, 0.06956521739130435]\n",
      "dimension of data\n",
      "7 13567\n",
      "[ 9211  4356 11678  1220   404   150   115]\n",
      "Optimal\n",
      "objective is:\n",
      "5426.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2591466724568451, 0.07392102846648302, 0.21013872238396986, 0.08934426229508197, 0.3069306930693069, 0.09333333333333334, 0.06956521739130435] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "sensitive attribute  7\n",
      "individual acceptance rates\n",
      "[0.2591466724568451, 0.07392102846648302, 0.21013872238396986, 0.08934426229508197, 0.3069306930693069, 0.09333333333333334, 0.06956521739130435]\n",
      "individul precision\n",
      "[0.7297863426895685, 0.7422360248447205, 0.7330888345558272, 0.7339449541284404, 0.7338709677419355, 0.5, 0.5]\n",
      "individual recall\n",
      "[0.623032904148784, 0.5106837606837606, 0.6106585200271555, 0.49382716049382713, 0.7222222222222222, 0.4666666666666667, 0.26666666666666666]\n",
      "DP all\n",
      "0.2373654756780026\n",
      "precision all 0.7312661498708011\n",
      "recall all 0.6069240196078431\n",
      "accuracy all 0.8517726837178448\n",
      "TP,FP,TN,FN\n",
      "1981 728 9575 1283\n",
      "[0.24025621539463685, 0.09182736455463728, 0.20106182565507794, 0.10491803278688525, 0.27970297029702973, 0.11333333333333333, 0.06086956521739131]\n",
      "dimension of data\n",
      "7 13567\n",
      "[ 9211  4356 11678  1220   404   150   115]\n",
      "Optimal\n",
      "objective is:\n",
      "5388.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.24025621539463685, 0.09182736455463728, 0.20106182565507794, 0.10491803278688525, 0.27970297029702973, 0.11333333333333333, 0.06086956521739131] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "sensitive attribute  7\n",
      "individual acceptance rates\n",
      "[0.24036478123982194, 0.09159779614325068, 0.20106182565507794, 0.10491803278688525, 0.27970297029702973, 0.11333333333333333, 0.06086956521739131]\n",
      "individul precision\n",
      "[0.7299006323396567, 0.6040100250626567, 0.7163543441226575, 0.6328125, 0.7345132743362832, 0.4117647058823529, 0.5714285714285714]\n",
      "individual recall\n",
      "[0.5779685264663805, 0.5149572649572649, 0.5709436524100475, 0.5, 0.6587301587301587, 0.4666666666666667, 0.26666666666666666]\n",
      "DP all\n",
      "0.21883340507963842\n",
      "precision all 0.7106773823191733\n",
      "recall all 0.5689338235294118\n",
      "accuracy all 0.840569027788015\n",
      "TP,FP,TN,FN\n",
      "1857 756 9547 1407\n",
      "[0.2213657583324286, 0.10996326905417815, 0.191984928926186, 0.11967213114754098, 0.25, 0.12666666666666668, 0.08695652173913043]\n",
      "dimension of data\n",
      "7 13567\n",
      "[ 9211  4356 11678  1220   404   150   115]\n",
      "Optimal\n",
      "objective is:\n",
      "5358.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2213657583324286, 0.10996326905417815, 0.191984928926186, 0.11967213114754098, 0.25, 0.12666666666666668, 0.08695652173913043] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "sensitive attribute  7\n",
      "individual acceptance rates\n",
      "[0.2213657583324286, 0.10996326905417815, 0.191984928926186, 0.11967213114754098, 0.25, 0.12666666666666668, 0.08695652173913043]\n",
      "individul precision\n",
      "[0.7292790583619422, 0.5093945720250522, 0.6971454058876003, 0.5684931506849316, 0.7326732673267327, 0.3684210526315789, 0.4]\n",
      "individual recall\n",
      "[0.5318311874105865, 0.5213675213675214, 0.5305498981670062, 0.5123456790123457, 0.5873015873015873, 0.4666666666666667, 0.26666666666666666]\n",
      "DP all\n",
      "0.16304347826086957\n",
      "precision all 0.687450357426529\n",
      "recall all 0.5303308823529411\n",
      "accuracy all 0.8289968305447041\n",
      "TP,FP,TN,FN\n",
      "1731 787 9516 1533\n",
      "[0.2024753012702204, 0.1283287419651056, 0.18282240109607809, 0.13524590163934427, 0.22277227722772278, 0.14, 0.11304347826086956]\n",
      "dimension of data\n",
      "7 13567\n",
      "[ 9211  4356 11678  1220   404   150   115]\n",
      "Optimal\n",
      "objective is:\n",
      "5330.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2024753012702204, 0.1283287419651056, 0.18282240109607809, 0.13524590163934427, 0.22277227722772278, 0.14, 0.11304347826086956] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "sensitive attribute  7\n",
      "individual acceptance rates\n",
      "[0.2024753012702204, 0.1283287419651056, 0.18282240109607809, 0.13524590163934427, 0.22277227722772278, 0.14, 0.11304347826086956]\n",
      "individul precision\n",
      "[0.7265415549597856, 0.4400715563506261, 0.6758782201405152, 0.503030303030303, 0.7111111111111111, 0.3333333333333333, 0.3076923076923077]\n",
      "individual recall\n",
      "[0.484620886981402, 0.5256410256410257, 0.48981670061099797, 0.5123456790123457, 0.5079365079365079, 0.4666666666666667, 0.26666666666666666]\n",
      "DP all\n",
      "0.10972879896685321\n",
      "precision all 0.6604785478547854\n",
      "recall all 0.49050245098039214\n",
      "accuracy all 0.8167612589371268\n",
      "TP,FP,TN,FN\n",
      "1601 823 9480 1663\n",
      "[0.18358484420801216, 0.14646464646464646, 0.17374550436718617, 0.15, 0.19306930693069307, 0.15333333333333332, 0.1391304347826087]\n",
      "dimension of data\n",
      "7 13567\n",
      "[ 9211  4356 11678  1220   404   150   115]\n",
      "Optimal\n",
      "objective is:\n",
      "5298.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.18358484420801216, 0.14646464646464646, 0.17374550436718617, 0.15, 0.19306930693069307, 0.15333333333333332, 0.1391304347826087] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "sensitive attribute  7\n",
      "individual acceptance rates\n",
      "[0.18358484420801216, 0.14646464646464646, 0.17374550436718617, 0.15, 0.19306930693069307, 0.15333333333333332, 0.1391304347826087]\n",
      "individul precision\n",
      "[0.7261975162625666, 0.3949843260188088, 0.6554953178905865, 0.4644808743169399, 0.6923076923076923, 0.30434782608695654, 0.25]\n",
      "individual recall\n",
      "[0.43919885550786836, 0.5384615384615384, 0.451459606245757, 0.5246913580246914, 0.42857142857142855, 0.4666666666666667, 0.26666666666666666]\n",
      "DP all\n",
      "0.05393887214808438\n",
      "precision all 0.635465865178188\n",
      "recall all 0.4534313725490196\n",
      "accuracy all 0.8059261443207784\n",
      "TP,FP,TN,FN\n",
      "1480 849 9454 1784\n",
      "[0.16469438714580392, 0.16483011937557393, 0.16466860763829422, 0.16475409836065574, 0.16584158415841585, 0.16666666666666666, 0.16521739130434782]\n",
      "dimension of data\n",
      "7 13567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9211  4356 11678  1220   404   150   115]\n",
      "Optimal\n",
      "objective is:\n",
      "5270.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.16469438714580392, 0.16483011937557393, 0.16466860763829422, 0.16475409836065574, 0.16584158415841585, 0.16666666666666666, 0.16521739130434782] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "sensitive attribute  7\n",
      "individual acceptance rates\n",
      "[0.16469438714580392, 0.16483011937557393, 0.16458297653707826, 0.16475409836065574, 0.16831683168316833, 0.16666666666666666, 0.16521739130434782]\n",
      "individul precision\n",
      "[0.7251153592617007, 0.3565459610027855, 0.6311134235171696, 0.42786069651741293, 0.6764705882352942, 0.28, 0.21052631578947367]\n",
      "individual recall\n",
      "[0.39341917024320455, 0.5470085470085471, 0.411744738628649, 0.5308641975308642, 0.36507936507936506, 0.4666666666666667, 0.26666666666666666]\n",
      "DP all\n",
      "0.003733855146090065\n",
      "precision all 0.6067114093959731\n",
      "recall all 0.41544117647058826\n",
      "accuracy all 0.7945750718655561\n",
      "TP,FP,TN,FN\n",
      "1356 879 9424 1908\n",
      "<--------------------------------------->\n"
     ]
    }
   ],
   "source": [
    "#result without cv value\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7316750708413239, 0.727116925783148, 0.7219846093071023, 0.7161041640956276, 0.7102390064027228, 0.7039721196974433] [0.5012282595458991, 0.5034664249981262, 0.5066655307291423, 0.5090618386286935, 0.5129275597574403, 0.5167819323500428] [0.8517, 0.8405, 0.8289, 0.8167, 0.8059, 0.7945]\n"
     ]
    }
   ],
   "source": [
    "accu=[0.8517, 0.8405, 0.8289, 0.8167,0.8059, 0.7945]\n",
    "acc_rate=[[0.2591466724568451, 0.07392102846648302, 0.21013872238396986, 0.08934426229508197, 0.3069306930693069, 0.09333333333333334, 0.06956521739130435],\n",
    "[0.24036478123982194, 0.09159779614325068, 0.20106182565507794, 0.10491803278688525, 0.27970297029702973, 0.11333333333333333, 0.06086956521739131],\n",
    "[0.2213657583324286, 0.10996326905417815, 0.191984928926186, 0.11967213114754098, 0.25, 0.12666666666666668, 0.08695652173913043],\n",
    "[0.2024753012702204, 0.1283287419651056, 0.18282240109607809, 0.13524590163934427, 0.22277227722772278, 0.14, 0.11304347826086956],\n",
    "[0.18358484420801216, 0.14646464646464646, 0.17374550436718617, 0.15, 0.19306930693069307, 0.15333333333333332, 0.1391304347826087],\n",
    "[0.16469438714580392, 0.16483011937557393, 0.16458297653707826, 0.16475409836065574, 0.16831683168316833, 0.16666666666666666, 0.16521739130434782]]\n",
    "\n",
    "prec=[[0.7297863426895685, 0.7422360248447205, 0.7330888345558272, 0.7339449541284404, 0.7338709677419355, 0.5, 0.5],\n",
    "[0.7299006323396567, 0.6040100250626567, 0.7163543441226575, 0.6328125, 0.7345132743362832, 0.4117647058823529, 0.5714285714285714],\n",
    "[0.7292790583619422, 0.5093945720250522, 0.6971454058876003, 0.5684931506849316, 0.7326732673267327, 0.3684210526315789, 0.4],\n",
    "[0.7265415549597856, 0.4400715563506261, 0.6758782201405152, 0.503030303030303, 0.7111111111111111, 0.3333333333333333, 0.3076923076923077],\n",
    "[0.7261975162625666, 0.3949843260188088, 0.6554953178905865, 0.4644808743169399, 0.6923076923076923, 0.30434782608695654, 0.25],\n",
    "[0.7251153592617007, 0.3565459610027855, 0.6311134235171696, 0.42786069651741293, 0.6764705882352942, 0.28, 0.21052631578947367]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rec=[[0.623032904148784, 0.5106837606837606, 0.6106585200271555, 0.49382716049382713, 0.7222222222222222, 0.4666666666666667, 0.26666666666666666],\n",
    "[0.5779685264663805, 0.5149572649572649, 0.5709436524100475, 0.5, 0.6587301587301587, 0.4666666666666667, 0.26666666666666666],\n",
    "[0.5318311874105865, 0.5213675213675214, 0.5305498981670062, 0.5123456790123457, 0.5873015873015873, 0.4666666666666667, 0.26666666666666666],\n",
    "[0.484620886981402, 0.5256410256410257, 0.48981670061099797, 0.5123456790123457, 0.5079365079365079, 0.4666666666666667, 0.26666666666666666],\n",
    "[0.43919885550786836, 0.5384615384615384, 0.451459606245757, 0.5246913580246914, 0.42857142857142855, 0.4666666666666667, 0.26666666666666666],\n",
    "[0.39341917024320455, 0.5470085470085471, 0.411744738628649, 0.5308641975308642, 0.36507936507936506, 0.4666666666666667, 0.26666666666666666]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "weighted_precision=[]\n",
    "weighted_recall=[]\n",
    "p=[0,2,4]\n",
    "r=[1,3,5,6]\n",
    "\n",
    "weight_prec=0\n",
    "weight_p=0\n",
    "weight_rec=0\n",
    "weight_r=0\n",
    "sizes=[9211, 4356, 11678,1220, 404, 150,115]\n",
    "for i in range(6):\n",
    "    for j in range(7):\n",
    "        if j in p:\n",
    "            weight_prec=weight_prec+sizes[j]*prec[i][j]\n",
    "            weight_p=weight_p+sizes[j]\n",
    "        if j in r:    \n",
    "            weight_rec=weight_rec+sizes[j]*rec[i][j]\n",
    "            weight_r=weight_r+sizes[j]\n",
    "            \n",
    "    wp=weight_prec/weight_p\n",
    "    wr=weight_rec/weight_r\n",
    "    weighted_precision.append(wp)\n",
    "    weighted_recall.append(wr)\n",
    "print(weighted_precision, weighted_recall,accu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
