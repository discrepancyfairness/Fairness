{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "from time import time\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Import the three supervised learning models from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA    \n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['time']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "#SVM \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "from random import *\n",
    "from subprocess import check_output\n",
    "def Bank_svm(X,Y):\n",
    "    #Split data into training and test datasets (training will be based on 70% of data)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0,shuffle=True) \n",
    "    #test_size: if integer, number of examples into test dataset; if between 0.0 and 1.0, means proportion\n",
    "    print('There are {} samples in the training set and {} samples in the test set'.format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "    \n",
    "    #Scaling data\n",
    "    #from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    #sc = StandardScaler(with_mean=False)\n",
    "    \n",
    "    \n",
    "    #sc.fit(X_train)\n",
    "    #X_train_std = sc.transform(X_train)\n",
    "    #X_test_std = sc.transform(X_test)\n",
    "\n",
    "    #X_train_std and X_test_std are the scaled datasets to be used in algorithms\n",
    "\n",
    "    #Applying SVC (Support Vector Classification)\n",
    "    from sklearn.svm import SVC\n",
    "    svm = SVC(kernel='rbf', random_state=0, gamma=.001, C=1.0,probability=True)\n",
    "    svm.fit(X_train, Y_train)\n",
    "    print('The accuracy of the SVM classifier on training data is {:.2f}'.format(svm.score(X_train, Y_train)))\n",
    "    print('The accuracy of the SVM classifier on test data is {:.2f}'.format(svm.score(X_test, Y_test)))\n",
    "    print('####Train prediction Label###############################################')\n",
    "    Y_train_pred=svm.predict(X_train)\n",
    "    #print(y_1)\n",
    "    Y_test_pred=svm.predict(X_test)\n",
    "\n",
    "    print('####Actual Train Label###############################################')\n",
    "    e=svm.predict_proba(X_test)\n",
    "\n",
    "    print(e)\n",
    "    print(Y_test_pred)\n",
    "    print('####Change to colors###############################################')\n",
    "        \n",
    "    \n",
    "    return X_test,Y_test_pred,Y_test,e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without accuracy ---> 2\n",
    "def main(datax, y_test, y_test_pred,e): \n",
    "        \n",
    "    n=datax.shape[1]\n",
    "    s=datax.shape[0]    \n",
    "    data = np.zeros((s, n), dtype = int)\n",
    "    \n",
    "    r = np.zeros(n, dtype = int) \n",
    "    \n",
    "    for i in range(n):\n",
    "        if int(y_test.iloc[i])==1 :\n",
    "            r[i]=1\n",
    "        else :\n",
    "            r[i]= -1  \n",
    "    \n",
    "    r2 = np.zeros(n, dtype = int) \n",
    "    for i in range(n):\n",
    "        if int(y_test_pred[i])==1 :\n",
    "            r2[i]=1\n",
    "        else :\n",
    "            r2[i]= -1          \n",
    "    ar=[]\n",
    "    \n",
    "    for j in range(s):\n",
    "        print(\"sensitive attribute \",(j+1)) \n",
    "        a=0\n",
    "        b=0\n",
    "        acc1=0\n",
    "        acc2=0\n",
    "        for i in range(n):\n",
    "                data[j][i]= datax.iloc[j,i]\n",
    "                if data[j][i]== 1 :\n",
    "                    a=a+1\n",
    "                    if r[i]==1:\n",
    "                         acc1=acc1+1 \n",
    "\n",
    "        print(\"ACTUAL----------total ,accepted, aceeptance rate:\")             \n",
    "        a1=float(acc1/a)\n",
    "        print(a)\n",
    "        \n",
    "        print(acc1)\n",
    "        print(a1)\n",
    "        ar.append(a1)\n",
    "        \n",
    "    maxi= max(ar)\n",
    "    mini= min(ar)\n",
    "    DP=float(maxi-mini)\n",
    "    print(\"data acceptance rates\")\n",
    "    print(ar)\n",
    "    print(\"data DP\")\n",
    "    print(DP)\n",
    "    \n",
    "    ar=[]\n",
    "    \n",
    "    for j in range(s):\n",
    "        print(\"sensitive attribute \",(j+1)) \n",
    "        a=0\n",
    "        b=0\n",
    "        acc1=0\n",
    "        acc2=0\n",
    "        prec=0\n",
    "        reca=0\n",
    "        accur=0\n",
    "        FP=0\n",
    "        FN=0\n",
    "        TP=0\n",
    "        TN=0\n",
    "        for i in range(n):\n",
    "             if data[j][i]== 1 :\n",
    "                    a=a+1\n",
    "                    if r2[i]==1:\n",
    "                        acc1=acc1+1 \n",
    "                        if r[i]==1:\n",
    "                            TP=TP+1\n",
    "                        else:\n",
    "                             FP=FP+1                \n",
    "                    else:\n",
    "                        if r[i]==1:\n",
    "                            FN=FN+1\n",
    "                        else:\n",
    "                            TN=TN+1    \n",
    "        \n",
    "        print(\"prec reca accuracy for each sens\") \n",
    "        prec= float(TP/(TP+FP))\n",
    "        reca= float(TP/(TP+FN))\n",
    "        accur= float((TP+TN)/a)\n",
    "        print(prec,reca,accur)\n",
    "        \n",
    "        \n",
    "        print(\"SVM----------total , accepted, aceeptance rate:\")             \n",
    "        \n",
    "        a1=float(acc1/a)\n",
    "        print(a)\n",
    "        \n",
    "        print(acc1)\n",
    "        print(a1)\n",
    "        ar.append(a1)\n",
    "        \n",
    "    maxi= max(ar)\n",
    "    mini= min(ar)\n",
    "    DP=float(maxi-mini)\n",
    "    print(\"data acceptance rates\")\n",
    "    print(ar)\n",
    "    print(\"data DP\")\n",
    "    print(DP) \n",
    "    \n",
    "    print(\"SVM accuracy--------------------------\")\n",
    "    prec=0\n",
    "    reca=0\n",
    "    accur=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    TP=0\n",
    "    TN=0\n",
    "    for i in range(n):\n",
    "            if r2[i]==1:\n",
    "                acc1=acc1+1 \n",
    "                if r[i]==1:\n",
    "                    TP=TP+1\n",
    "                else:\n",
    "                     FP=FP+1                \n",
    "            else:\n",
    "                if r[i]==1:\n",
    "                     FN=FN+1\n",
    "                else:\n",
    "                     TN=TN+1    \n",
    "\n",
    "        \n",
    "    prec= float(TP/(TP+FP))\n",
    "    reca= float(TP/(TP+FN))\n",
    "    accur= float((TP+TN)/n)\n",
    "    print(prec,reca,accur)\n",
    "    \n",
    "    epsilon=[.01]\n",
    "    fi= np.zeros(n,dtype=int) \n",
    "\n",
    "    \n",
    "    #alpha=[[1,.1,1,1,1,1],[1,1,1,1,.01,1],[1,1,1,1,1,.001]] \n",
    "    alpha=[[1,1,1,1,1,1]]\n",
    "    gamma=[[0.2970639032815199, 0.06707420614705382, 0.07105054247155332, 0.10202881505439576, 0.056, 0.043478260869565216],\n",
    "[0.25734024179620035, 0.06911190354898965, 0.0723736438211167, 0.09732431637753602, 0.06036363636363636, 0.08695652173913043],\n",
    "[0.21243523316062177, 0.07123450500933945, 0.07369674517068008, 0.09232578653337253, 0.06472727272727273, 0.08695652173913043],\n",
    "[0.16753022452504318, 0.07327220241127526, 0.07488753638528711, 0.08732725668920906, 0.06909090909090909, 0.08695652173913043],\n",
    "[0.12435233160621761, 0.07539480387162506, 0.07621063773485048, 0.0826227580123493, 0.07345454545454545, 0.08695652173913043],\n",
    "[0.08635578583765112, 0.07751740533197486, 0.07753373908441387, 0.07880035283740076, 0.07781818181818181, 0.08695652173913043]]\n",
    "\n",
    "    '''\n",
    "    gamma2=[[0.2970639033,0.2158894646,.127806563,.0967184801,.1070811744],\n",
    "[0.05815928,0.0556970623,0.0562913907,0.0560366786,.0578196638],\n",
    "[0.0631119344,0.0599364911,0.0571579783,0.0553056364,.0571579783],\n",
    "[0.0911496619,0.0782122905,0.072037636,0.0682152308,.0743898853],\n",
    "[0.0501818182,.0443636364 ,.0429090909,.0472727273,.0414545455],\n",
    "[0.0434782609,0.0434782609,0.0434782609,.0434782609,.0434782609]]\n",
    "\n",
    "\n",
    "    gamma=np.transpose(gamma2)\n",
    "    \n",
    "\n",
    "    \n",
    "    alpha=[[1,1,1,1,1,1],[.1,1,1,1,1,1], [.01,1,1,1,1,1],[.001,1,1,1,1,1],\n",
    "           [1,.1,1,1,1,1], [1,.01,1,1,1,1],[1,.001,1,1,1,1],\n",
    "           [1,1,.1,1,1,1], [1,1,.01,1,1,1],[1,1,.001,1,1,1],\n",
    "           [1,1,1,.1,1,1], [1,1,1,.01,1,1],[1,1,1,.001,1,1],\n",
    "           [1,1,1,1,.1,1], [1,1,1,1,.01,1],[1,1,1,1,.001,1],\n",
    "           [1,1,1,1,1,.1], [1,1,1,1,1,.01],[1,1,1,1,1,.001],\n",
    "        [.1,.1,1,1,1,1],[.01,.01,1,1,1,1], [.001,.001,1,1,1,1],[.001,.01,1,1,1,1],[.001,.1,1,1,1,1],\n",
    "         [.01,.1,1,1,1,1] ]\n",
    "    '''\n",
    "         \n",
    "    a=0\n",
    "    print(alpha)\n",
    "    \n",
    "    '''\n",
    "    #agarwal 1 15 25\n",
    "     alpha=[[1,1,1,1,1,1],[1,1,1,1,.01,1],  [.01,.1,1,1,1,1] ] \n",
    "    gamma2=   [[ 0.074266,0.0725389,0.0794473,0.0777202,0.0673575],\n",
    "[0.051367,0.051367,0.0517915,0.0524707,0.0533197],\n",
    "[0.0497486,0.0497486,0.0493517,0.0501455,0.0504102],\n",
    "[0.0629227,0.0649809,0.0729197,0.0738018,0.0743899],\n",
    "[0.0407273,0.0349091,0.0254545,0.024,0.024],\n",
    "[0.0869565,0.0869565,0,0,0]]\n",
    "    \n",
    "                \n",
    "    gamma=np.transpose(gamma2)\n",
    "    '''\n",
    "\n",
    "    for new in range(6):\n",
    "        for t in range(1):\n",
    "            for eps in epsilon:\n",
    "                u1,u2=min_sum_lpca(data,gamma[new],eps,e,alpha[t],r2)\n",
    "                #######################Disp_impact#######################  \n",
    "                print(\"gamma-epsilon-delta\",gamma[new],eps)\n",
    "                accu_all=[]\n",
    "                DP_all=[]\n",
    "                precision_all=[]\n",
    "                recall_all=[]\n",
    "                ar_all=[]\n",
    "                acceptance_rate=np.zeros((7,28),dtype=float)\n",
    "                count=0\n",
    "                print(\"<--------------------------------------->\")\n",
    "                print(\"iteration t\",t)\n",
    "\n",
    "\n",
    "                for i in range(n):\n",
    "                     fi[i] = u1[i]\n",
    "\n",
    "\n",
    "                for j in range(s):\n",
    "                    print(\"sensitive attribute \",(j+1)) \n",
    "\n",
    "                    TP=0\n",
    "                    FP=0\n",
    "                    FN=0\n",
    "                    TN=0\n",
    "                    precision=0\n",
    "                    recall=0\n",
    "                    for i in range(n):\n",
    "                         if data[j][i]== 1 :                        \n",
    "                            if fi[i]==1 and r[i]==1:\n",
    "                                TP=TP+1\n",
    "                            if fi[i]==1 and r[i]==-1:\n",
    "                                FP=FP+1 \n",
    "                            if fi[i]==-1 and r[i]==1:\n",
    "                                FN=FN+1\n",
    "                            if fi[i]==-1 and r[i]==-1:\n",
    "                                TN=TN+1    \n",
    "                    if TP+FP !=0:\n",
    "                        precision=float(TP/(TP+FP))\n",
    "                    #print(\"precision\",precision)\n",
    "                    if TP+FN !=0:    \n",
    "                        recall=float(TP/(TP+FN))\n",
    "                    #print(\"recall\",recall)\n",
    "\n",
    "                    precision_all.append(precision)\n",
    "                    recall_all.append(recall)\n",
    "                    #print(\"TP,FP,TN,FN\")\n",
    "                    #print(TP,FP,TN,FN)\n",
    "\n",
    "                    a=0\n",
    "                    b=0\n",
    "                    acc1=0\n",
    "                    acc2=0\n",
    "                    for i in range(n):\n",
    "                            if data[j][i]== 1 :\n",
    "                                a=a+1\n",
    "                                if fi[i]==1:\n",
    "                                     acc1=acc1+1 \n",
    "\n",
    "        #                         print(\"total ,fair accepted, aceeptance rate:\")             \n",
    "                    a1=float(acc1/a)\n",
    "\n",
    "\n",
    "\n",
    "        #                         print(a)\n",
    "        #                         print(acc1)\n",
    "        #                         print(a1)\n",
    "                    ar_all.append(a1)\n",
    "\n",
    "                count = count+1\n",
    "                maxi=max(ar_all)\n",
    "                mini= min(ar_all)\n",
    "                DP=float(maxi-mini)\n",
    "                print(\"individual acceptance rates\")\n",
    "                print(ar_all)\n",
    "                print(\"individul precision\")\n",
    "                print(precision_all)\n",
    "                print(\"individual recall\")\n",
    "                print(recall_all)\n",
    "                print(\"DP all\")\n",
    "                print(DP)\n",
    "                f_acc=0\n",
    "                for i in range(n):\n",
    "                     if fi[i] == r[i]:\n",
    "                            f_acc=f_acc+1\n",
    "                f_acc_l=float((f_acc*100)/n) \n",
    "\n",
    "        #######################################################################33   \n",
    "\n",
    "        #                         print(\"sensitive attribute \",(j+1)) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                TP=0\n",
    "                FP=0\n",
    "                FN=0\n",
    "                TN=0\n",
    "                precision=0\n",
    "                recall=0\n",
    "                accu=0\n",
    "                for i in range(n):\n",
    "                        if fi[i]==1 and r[i]==1:\n",
    "                            TP=TP+1\n",
    "                        if fi[i]==1 and r[i]==-1:\n",
    "                            FP=FP+1 \n",
    "                        if fi[i]==-1 and r[i]==1:\n",
    "                            FN=FN+1\n",
    "                        if fi[i]==-1 and r[i]==-1:\n",
    "                            TN=TN+1    \n",
    "\n",
    "                if TP+FP!=0:\n",
    "                    precision=float(TP/(TP+FP))\n",
    "                print(\"precision all\",precision)\n",
    "                if TP+FN!=0:\n",
    "                    recall=float(TP/(TP+FN))\n",
    "\n",
    "\n",
    "                print(\"recall all\",recall)\n",
    "                accu=float((TP+TN)/(TP+FN+TN+FP))\n",
    "\n",
    "\n",
    "                print(\"accuracy all\",accu)\n",
    "\n",
    "\n",
    "\n",
    "                print(\"TP,FP,TN,FN\")\n",
    "                print(TP,FP,TN,FN)\n",
    "        #                         print(\"total ,fair accepted, aceeptance rate:\")             \n",
    "                a1=float(acc1/a)\n",
    "\n",
    "\n",
    "    print(\"<--------------------------------------->\")\n",
    "    alpha_weight=np.arange(0,1.05,.05)        \n",
    "    return accu_all,DP_all,acceptance_rate,alpha_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#NG\n",
    "import time\n",
    "import pulp as p \n",
    "def min_sum_lpca(data1,beta,eps,e,alpha,y):\n",
    "    import pulp as p \n",
    "    import math\n",
    "    \n",
    "    m=data1.shape[0]\n",
    "    n=data1.shape[1]\n",
    "    print('dimension of data')\n",
    "    print(m,n)\n",
    "    \n",
    "    ################ sorted result\n",
    "    h1=[]\n",
    "    h2=[]\n",
    "    h3=[]\n",
    "    h4=[]\n",
    "    h5=[]\n",
    "    h6=[]\n",
    "   \n",
    "    key1=[]\n",
    "    key2=[]\n",
    "    key3=[]\n",
    "    key4=[]\n",
    "    key5=[]\n",
    "    key6=[]\n",
    "   \n",
    "    cost=np.zeros(n,dtype=int)\n",
    "    data2=np.zeros((m,n),dtype=int)\n",
    "    for i in range(n):\n",
    "        if data1[0][i]==1:            \n",
    "\n",
    "            h1.append(e[i][1])\n",
    "            key1.append(i)\n",
    "\n",
    "        elif data1[1][i]==1:\n",
    "            h2.append(e[i][1])\n",
    "            key2.append(i)\n",
    "            \n",
    "        if data1[2][i]==1:\n",
    "            h3.append(e[i][1])\n",
    "            key3.append(i)\n",
    "            \n",
    "        elif data1[3][i]==1:\n",
    "            h4.append(e[i][1])\n",
    "            key4.append(i)\n",
    "        elif data1[4][i]==1:\n",
    "            h5.append(e[i][1])\n",
    "            key5.append(i)\n",
    "        elif data1[5][i]==1:\n",
    "            h6.append(e[i][1])\n",
    "            key6.append(i)\n",
    "        elif data1[6][i]==1:\n",
    "            h7.append(e[i][1])\n",
    "            key7.append(i)\n",
    "#print(hc)\n",
    "#     print(key1)\n",
    "    \n",
    "    for i in range(1,len(h1)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h1[j-1]<h1[j]:\n",
    "                index=j\n",
    "                var=h1[j]\n",
    "                h1[j]=h1[j-1]\n",
    "                h1[j-1]=var\n",
    "\n",
    "                var2=key1[j]\n",
    "                key1[j]=key1[j-1]\n",
    "                key1[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "\n",
    "    for i in range(1,len(h2)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h2[j-1]<h2[j]:\n",
    "                index=j\n",
    "                var=h2[j]\n",
    "                h2[j]=h2[j-1]\n",
    "                h2[j-1]=var\n",
    "\n",
    "                var2=key2[j]\n",
    "                key2[j]=key2[j-1]\n",
    "                key2[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "    for i in range(1,len(h3)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h3[j-1]<h3[j]:\n",
    "                index=j\n",
    "                var=h3[j]\n",
    "                h3[j]=h3[j-1]\n",
    "                h3[j-1]=var\n",
    "\n",
    "                var2=key3[j]\n",
    "                key3[j]=key3[j-1]\n",
    "                key3[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "    for i in range(1,len(h4)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h4[j-1]<h4[j]:\n",
    "                index=j\n",
    "                var=h4[j]\n",
    "                h4[j]=h4[j-1]\n",
    "                h4[j-1]=var\n",
    "\n",
    "                var2=key4[j]\n",
    "                key4[j]=key4[j-1]\n",
    "                key4[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "    for i in range(1,len(h5)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h3[j-1]<h5[j]:\n",
    "                index=j\n",
    "                var=h5[j]\n",
    "                h5[j]=h5[j-1]\n",
    "                h5[j-1]=var\n",
    "\n",
    "                var2=key5[j]\n",
    "                key5[j]=key5[j-1]\n",
    "                key5[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "                \n",
    "                \n",
    "    for i in range(1,len(h6)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h6[j-1]<h6[j]:\n",
    "                index=j\n",
    "                var=h6[j]\n",
    "                h6[j]=h6[j-1]\n",
    "                h6[j-1]=var\n",
    "\n",
    "                var2=key6[j]\n",
    "                key6[j]=key6[j-1]\n",
    "                key6[j-1]=var2\n",
    "            else:\n",
    "                break        \n",
    "                \n",
    "    '''       \n",
    "    #basic1\n",
    "    for j in range(len(key1)):    \n",
    "        #data2[0][key1[j]]=((j+1)/((beta[0]*len(key1))*((beta[0]*len(key1))+1)/2)*alpha[0])\n",
    "         \n",
    "        data2[0][key1[j]]=(j+1)*alpha[0]\n",
    "    for j in range(len(key2)):\n",
    "        data2[1][key2[j]]=(j+1)*alpha[1]\n",
    "    for j in range(len(key3)):\n",
    "        data2[2][key3[j]]=(j+1)*alpha[2]              \n",
    "        \n",
    "    for j in range(len(key4)):\n",
    "        data2[3][key4[j]]=(j+1)*alpha[3]\n",
    "        \n",
    "                             \n",
    "    for j in range(len(key5)):               \n",
    "        data2[4][key5[j]]=(j+1)*alpha[4]\n",
    "       \n",
    "    for j in range(len(key6)):\n",
    "        data2[5][key6[j]]=(j+1)*alpha[5]\n",
    "    \n",
    "    #basic2\n",
    "            \n",
    "    '''\n",
    "    alpha2=[1,1,1,1,1,1]\n",
    "    for j in range(len(key1)):    \n",
    "        #data2[0][key1[j]]=((j+1)/((beta[0]*len(key1))*((beta[0]*len(key1))+1)/2)*alpha[0])\n",
    "         \n",
    "        data2[0][key1[j]]=(j+1)*alpha2[0]\n",
    "    for j in range(len(key2)):\n",
    "        data2[1][key2[j]]=(j+1)*alpha2[1]\n",
    "    for j in range(len(key3)):\n",
    "        if data1[2][key3[j]]==1 and data1[0][key3[j]]==1: \n",
    "            data2[2][key3[j]]=(j+1)*(len(key1)/len(key3))*alpha2[2]\n",
    "        else:\n",
    "            data2[2][key3[j]]=(j+1)*(len(key2)/len(key3))*alpha2[2]                  \n",
    "        \n",
    "    for j in range(len(key4)):\n",
    "        if data1[3][key4[j]]==1 and data1[0][key4[j]]==1:                   \n",
    "            data2[3][key4[j]]=(j+1)*(len(key1)/len(key4))*alpha2[3]\n",
    "        else :                     \n",
    "            data2[3][key4[j]]=(j+1)*(len(key2)/len(key4))*alpha2[3]\n",
    "                             \n",
    "    for j in range(len(key5)):\n",
    "        if data1[4][key5[j]]==1 and data1[0][key5[j]]==1:                  \n",
    "            data2[4][key5[j]]=(j+1)*(len(key1)/len(key5))*alpha2[4]\n",
    "        else:      \n",
    "            data2[4][key5[j]]=(j+1)*(len(key2)/len(key5))*alpha2[4]\n",
    "    for j in range(len(key6)):\n",
    "        if data1[5][key6[j]]==1 and data1[0][key6[j]]==1:                    \n",
    "            data2[5][key6[j]]=(j+1)*(len(key1)/len(key6))*alpha2[5]\n",
    "        else:                    \n",
    "             data2[5][key6[j]]=(j+1)*(len(key2)/len(key6))*alpha2[5] \n",
    "          \n",
    "    \n",
    "    \n",
    "    \n",
    "      \n",
    "            \n",
    "    for j in range(n):\n",
    "        sum=0\n",
    "        for i in range(m):\n",
    "       \n",
    "            sum=sum+data2[i][j] \n",
    "        cost[j]=sum\n",
    "        \n",
    "        \n",
    "    ################\n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "   \n",
    "    \n",
    "#     X=np.zeros(n+1,dtype=p.LpVariable)\n",
    "    X=np.zeros(n+m+1,dtype=p.LpVariable)\n",
    "    sizes=np.zeros(m,dtype=int)\n",
    "#     report_index(index,data1,e):  \n",
    "    max_size=0\n",
    "    for i in range(m):\n",
    "        count=0\n",
    "        for j in range(n):\n",
    "            if data1[i][j]==1:\n",
    "                count=count+1 \n",
    "        if count>max_size:\n",
    "            max_size=count\n",
    "        sizes[i]=count\n",
    "        \n",
    "    #############################33\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ###############################\n",
    "        \n",
    "        \n",
    "        \n",
    "  \n",
    "    select_sizes=np.zeros(m,dtype=int)\n",
    "   \n",
    "    size_final=np.zeros(m,dtype=int)\n",
    "\n",
    "    \n",
    "    for i in range(n):\n",
    "        var1=str(i)       \n",
    "        X[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Integer')\n",
    "   \n",
    "    X[n]=p.LpVariable(str(n),lowBound=0,upBound=1,cat='Continuous')  \n",
    "\n",
    "    Lp_prob+= p.lpSum([(X[j])*cost[j] for j in range(n)]) \n",
    "  \n",
    "    \n",
    "\n",
    "    ##############constraint#################\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "\n",
    "            Lp_prob += p.lpSum([(X[j])*(data1[i][j]) for j in range(n)]) >= math.floor(beta[i]*sizes[i])\n",
    "            Lp_prob += p.lpSum([(X[j])*(data1[i][j]) for j in range(n)]) <= math.ceil((beta[i]+eps)*sizes[i])\n",
    "           \n",
    "        \n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status]) \n",
    "    print(\"objective is:\")        \n",
    "    print(p.value(Lp_prob.objective))\n",
    "    print(\"discripency is:\") \n",
    "    print(p.value(X[n]))\n",
    "    x=np.zeros(n,dtype=float)\n",
    "\n",
    "   # The solution status \n",
    "    Synth1={}\n",
    "    Synth2={}\n",
    "    # # Printing the final solution \n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])==1):\n",
    "            Synth1[i]=1 \n",
    "            Synth2[i]=-1\n",
    "#             if(data1[2][i]==1):\n",
    "#                 print(\"no\")\n",
    "        else:\n",
    "            Synth1[i]=-1\n",
    "            Synth2[i]=1\n",
    "    Synthu1=Synth1  \n",
    "    Synthu2=Synth2  \n",
    "    \n",
    "              \n",
    "    return Synthu1,Synthu2   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    24928\n",
      "1    11568\n",
      "2     4612\n",
      "3       80\n",
      "Name: marital, dtype: int64\n",
      "There are 28831 samples in the training set and 12357 samples in the test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the SVM classifier on training data is 0.92\n",
      "The accuracy of the SVM classifier on test data is 0.91\n",
      "####Train prediction Label###############################################\n",
      "####Actual Train Label###############################################\n",
      "[[0.93664901 0.06335099]\n",
      " [0.93204958 0.06795042]\n",
      " [0.9399619  0.0600381 ]\n",
      " ...\n",
      " [0.93542819 0.06457181]\n",
      " [0.93341507 0.06658493]\n",
      " [0.79605492 0.20394508]]\n",
      "[0 0 0 ... 0 0 0]\n",
      "####Change to colors###############################################\n",
      "       age  job  marital  education  default  housing  loan  contact  month  \\\n",
      "0       39    3        0          3        0        1     0        1      2   \n",
      "1       55    3        0          0        0        1     0        1      8   \n",
      "2       39    3        0          3        1        0     0        0      1   \n",
      "3       56    8        0          3        0        1     0        1      3   \n",
      "4       49    3        0          3        0        1     0        1      5   \n",
      "...    ...  ...      ...        ...      ...      ...   ...      ...    ...   \n",
      "12352   35    4        0          4        0        0     0        1      3   \n",
      "12353   39    4        1          4        0        0     0        1      2   \n",
      "12354   43    1        0          2        0        1     0        1      0   \n",
      "12355   39    0        0          6        0        0     0        0      0   \n",
      "12356   46    2        0          1        0        0     1        1      3   \n",
      "\n",
      "       day_of_week  duration  campaign  pdays  previous  poutcome  \\\n",
      "0                4       635         3    999         0         0   \n",
      "1                4       248         2    999         0         0   \n",
      "2                3       207         1    999         0         0   \n",
      "3                3       176         7    999         0         0   \n",
      "4                4       271         1    999         0         0   \n",
      "...            ...       ...       ...    ...       ...       ...   \n",
      "12352            3        38         1    999         0         0   \n",
      "12353            0       617         2    999         0         0   \n",
      "12354            4        68         1    999         0         0   \n",
      "12355            2       174         1    999         0         0   \n",
      "12356            2       871         2    999         0         0   \n",
      "\n",
      "       emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed  \n",
      "0               1.4          93.918          -42.7      4.957       5228.1  \n",
      "1              -1.8          93.075          -47.1      1.405       5099.1  \n",
      "2               1.4          94.465          -41.8      4.961       5228.1  \n",
      "3               1.4          93.444          -36.1      4.963       5228.1  \n",
      "4              -0.1          93.200          -42.0      4.021       5195.8  \n",
      "...             ...             ...            ...        ...          ...  \n",
      "12352           1.4          93.444          -36.1      4.964       5228.1  \n",
      "12353           1.4          93.918          -42.7      4.960       5228.1  \n",
      "12354          -1.8          92.893          -46.2      1.250       5099.1  \n",
      "12355           1.1          93.994          -36.4      4.858       5191.0  \n",
      "12356           1.4          93.444          -36.1      4.965       5228.1  \n",
      "\n",
      "[12357 rows x 20 columns]\n",
      "[0 0 0 ... 0 0 0]\n",
      "       y\n",
      "0      1\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "...   ..\n",
      "12352  0\n",
      "12353  1\n",
      "12354  0\n",
      "12355  0\n",
      "12356  1\n",
      "\n",
      "[12357 rows x 1 columns]\n",
      "       age  marital\n",
      "0       39        0\n",
      "1       55        0\n",
      "2       39        0\n",
      "3       56        0\n",
      "4       49        0\n",
      "...    ...      ...\n",
      "12352   35        0\n",
      "12353   39        1\n",
      "12354   43        0\n",
      "12355   39        0\n",
      "12356   46        0\n",
      "\n",
      "[12357 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/home/subham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/subham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a_1  a_2  m_0  m_1  m_2  m_3\n",
      "0    0    1    1    0    0    0\n",
      "1    0    1    1    0    0    0\n",
      "2    0    1    1    0    0    0\n",
      "3    0    1    1    0    0    0\n",
      "4    0    1    1    0    0    0\n",
      "     0      1      2      3      4      5      6      7      8      9      \\\n",
      "a_1      0      0      0      0      0      0      0      0      1      0   \n",
      "a_2      1      1      1      1      1      1      1      1      0      1   \n",
      "m_0      1      1      1      1      1      1      1      0      0      1   \n",
      "m_1      0      0      0      0      0      0      0      1      1      0   \n",
      "m_2      0      0      0      0      0      0      0      0      0      0   \n",
      "m_3      0      0      0      0      0      0      0      0      0      0   \n",
      "\n",
      "     ...  12347  12348  12349  12350  12351  12352  12353  12354  12355  12356  \n",
      "a_1  ...      0      0      0      0      0      0      0      0      0      0  \n",
      "a_2  ...      1      1      1      1      1      1      1      1      1      1  \n",
      "m_0  ...      0      1      0      1      1      1      0      1      1      1  \n",
      "m_1  ...      1      0      1      0      0      0      1      0      0      0  \n",
      "m_2  ...      0      0      0      0      0      0      0      0      0      0  \n",
      "m_3  ...      0      0      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[6 rows x 12357 columns]\n"
     ]
    }
   ],
   "source": [
    "# without accuracy\n",
    "import time\n",
    "# import pulp as p \n",
    "# from random import *\n",
    "data= pd.read_csv('data/bank_train.csv',skipinitialspace=True)\n",
    "\n",
    "print(data['marital'].value_counts())\n",
    "#marital\n",
    "#U=80, M=24928, S=11568, D=4612\n",
    "# m_3, m_0, m_1, m_2\n",
    "#age\n",
    "#>60 and <25= a_1\n",
    "#>=25and <=60 =a_2\n",
    "# print(data.head())\n",
    "# print(data.shape[0],data.shape[1])\n",
    "\n",
    "#sensitive columns name 0='age',2='marital'\n",
    "\n",
    "data_c = data.drop(columns=['age_group','y'])\n",
    "# print(sens)\n",
    "r=data[['y']]\n",
    "\n",
    "X_test,Y_test_pred,Y_test,e = Bank_svm(data_c , r)\n",
    "\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "# Y_test_pred.reset_index()\n",
    "Y_test.reset_index(drop=True, inplace=True)\n",
    "print(X_test)\n",
    "print(Y_test_pred)\n",
    "print(Y_test)\n",
    "sens=X_test[['age','marital']]\n",
    "print(sens)\n",
    "p=sens.shape[0]\n",
    "\n",
    "# for i in range(0,p):  \n",
    "#     if r.loc[i,'y'] == 1 :\n",
    "#                r.loc[i,\"y\"] = 1 \n",
    "#     else: \n",
    "#                r.loc[i,\"y\"] = 0 \n",
    "            \n",
    "for i in range(0,p):\n",
    "    if sens.loc[i,'age'] > 60 or sens.loc[i,'age'] < 25 :\n",
    "               sens.loc[i,'age'] = 1 \n",
    "    else :\n",
    "               sens.loc[i,'age'] = 2  \n",
    "            \n",
    "sens1 = pd.get_dummies(sens, columns=['age','marital'], prefix =['a','m'])\n",
    "print(sens1.head())\n",
    "sensitive = sens1.T\n",
    "\n",
    "print(sensitive)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitive attribute  1\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "579\n",
      "213\n",
      "0.36787564766839376\n",
      "sensitive attribute  2\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "11778\n",
      "1175\n",
      "0.09976226863644082\n",
      "sensitive attribute  3\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "7558\n",
      "748\n",
      "0.09896798094734056\n",
      "sensitive attribute  4\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "3401\n",
      "497\n",
      "0.14613349014995589\n",
      "sensitive attribute  5\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "1375\n",
      "140\n",
      "0.10181818181818182\n",
      "sensitive attribute  6\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "23\n",
      "3\n",
      "0.13043478260869565\n",
      "data acceptance rates\n",
      "[0.36787564766839376, 0.09976226863644082, 0.09896798094734056, 0.14613349014995589, 0.10181818181818182, 0.13043478260869565]\n",
      "data DP\n",
      "0.2689076667210532\n",
      "sensitive attribute  1\n",
      "prec reca accuracy for each sens\n",
      "0.7142857142857143 0.5633802816901409 0.7564766839378239\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "579\n",
      "168\n",
      "0.29015544041450775\n",
      "sensitive attribute  2\n",
      "prec reca accuracy for each sens\n",
      "0.6625 0.451063829787234 0.9223127865511972\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "11778\n",
      "800\n",
      "0.06792324673119375\n",
      "sensitive attribute  3\n",
      "prec reca accuracy for each sens\n",
      "0.6734317343173432 0.4879679144385027 0.9259063244244509\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "7558\n",
      "542\n",
      "0.071712093146335\n",
      "sensitive attribute  4\n",
      "prec reca accuracy for each sens\n",
      "0.659942363112392 0.4607645875251509 0.8865039694207586\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "3401\n",
      "347\n",
      "0.10202881505439576\n",
      "sensitive attribute  5\n",
      "prec reca accuracy for each sens\n",
      "0.717948717948718 0.4 0.9229090909090909\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "1375\n",
      "78\n",
      "0.05672727272727273\n",
      "sensitive attribute  6\n",
      "prec reca accuracy for each sens\n",
      "0.0 0.0 0.8260869565217391\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "23\n",
      "1\n",
      "0.043478260869565216\n",
      "data acceptance rates\n",
      "[0.29015544041450775, 0.06792324673119375, 0.071712093146335, 0.10202881505439576, 0.05672727272727273, 0.043478260869565216]\n",
      "data DP\n",
      "0.24667717954494253\n",
      "SVM accuracy--------------------------\n",
      "0.6714876033057852 0.46829971181556196 0.9145423646516144\n",
      "[[1, 1, 1, 1, 1, 1]]\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "744454.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639032815199, 0.06707420614705382, 0.07105054247155332, 0.10202881505439576, 0.056, 0.043478260869565216] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.2970639032815199, 0.06707420614705382, 0.07105054247155332, 0.10202881505439576, 0.056, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.6511627906976745, 0.6455696202531646, 0.6685288640595903, 0.654178674351585, 0.4675324675324675, 0.0]\n",
      "individual recall\n",
      "[0.5258215962441315, 0.4340425531914894, 0.4799465240641711, 0.4567404426559356, 0.2571428571428571, 0.0]\n",
      "DP all\n",
      "0.2535856424119547\n",
      "precision all 0.6465696465696466\n",
      "recall all 0.44812680115273773\n",
      "accuracy all 0.9104960750991341\n",
      "TP,FP,TN,FN\n",
      "622 340 10629 766\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "785349.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.25734024179620035, 0.06911190354898965, 0.0723736438211167, 0.09732431637753602, 0.06036363636363636, 0.08695652173913043] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.25734024179620035, 0.06911190354898965, 0.0723736438211167, 0.09732431637753602, 0.06036363636363636, 0.08695652173913043]\n",
      "individul precision\n",
      "[0.6644295302013423, 0.6388206388206388, 0.6581352833638026, 0.6646525679758308, 0.46987951807228917, 0.0]\n",
      "individual recall\n",
      "[0.4647887323943662, 0.4425531914893617, 0.48128342245989303, 0.4426559356136821, 0.2785714285714286, 0.0]\n",
      "DP all\n",
      "0.19697660543256398\n",
      "precision all 0.6427829698857737\n",
      "recall all 0.44596541786743515\n",
      "accuracy all 0.9099295945617868\n",
      "TP,FP,TN,FN\n",
      "619 344 10625 769\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "831085.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.21243523316062177, 0.07123450500933945, 0.07369674517068008, 0.09232578653337253, 0.06472727272727273, 0.08695652173913043] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.21243523316062177, 0.07123450500933945, 0.07369674517068008, 0.09232578653337253, 0.06472727272727273, 0.08695652173913043]\n",
      "individul precision\n",
      "[0.6666666666666666, 0.6328963051251489, 0.6499102333931778, 0.6687898089171974, 0.4606741573033708, 0.0]\n",
      "individual recall\n",
      "[0.38497652582159625, 0.45191489361702125, 0.4839572192513369, 0.4225352112676056, 0.29285714285714287, 0.0]\n",
      "DP all\n",
      "0.14770796043334905\n",
      "precision all 0.6372141372141372\n",
      "recall all 0.44164265129682995\n",
      "accuracy all 0.9090394108602412\n",
      "TP,FP,TN,FN\n",
      "613 349 10620 775\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "878273.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.16753022452504318, 0.07327220241127526, 0.07488753638528711, 0.08732725668920906, 0.06909090909090909, 0.08695652173913043] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.16753022452504318, 0.07327220241127526, 0.07488753638528711, 0.08732725668920906, 0.06909090909090909, 0.08695652173913043]\n",
      "individul precision\n",
      "[0.5979381443298969, 0.6315179606025493, 0.6413427561837456, 0.6565656565656566, 0.47368421052631576, 0.0]\n",
      "individual recall\n",
      "[0.27230046948356806, 0.46382978723404256, 0.4852941176470588, 0.39235412474849096, 0.32142857142857145, 0.0]\n",
      "DP all\n",
      "0.09843931543413409\n",
      "precision all 0.628125\n",
      "recall all 0.43443804034582134\n",
      "accuracy all 0.9075827466213482\n",
      "TP,FP,TN,FN\n",
      "603 357 10612 785\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "930980.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.12435233160621761, 0.07539480387162506, 0.07621063773485048, 0.0826227580123493, 0.07345454545454545, 0.08695652173913043] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.12435233160621761, 0.07539480387162506, 0.07621063773485048, 0.0826227580123493, 0.07345454545454545, 0.08695652173913043]\n",
      "individul precision\n",
      "[0.5416666666666666, 0.6261261261261262, 0.6336805555555556, 0.6441281138790036, 0.48514851485148514, 0.0]\n",
      "individual recall\n",
      "[0.18309859154929578, 0.47319148936170213, 0.4879679144385027, 0.3641851106639839, 0.35, 0.0]\n",
      "DP all\n",
      "0.05089778615167216\n",
      "precision all 0.6197916666666666\n",
      "recall all 0.42867435158501443\n",
      "accuracy all 0.9062879339645545\n",
      "TP,FP,TN,FN\n",
      "595 365 10604 793\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "985328.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.08635578583765112, 0.07751740533197486, 0.07753373908441387, 0.07880035283740076, 0.07781818181818181, 0.08695652173913043] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.09671848013816926, 0.07743250127356088, 0.07753373908441387, 0.08027050867391944, 0.07781818181818181, 0.08695652173913043]\n",
      "individul precision\n",
      "[0.48214285714285715, 0.6162280701754386, 0.6177474402730375, 0.6446886446886447, 0.4766355140186916, 0.0]\n",
      "individual recall\n",
      "[0.1267605633802817, 0.47829787234042553, 0.4839572192513369, 0.35412474849094566, 0.36428571428571427, 0.0]\n",
      "DP all\n",
      "0.01928597886460838\n",
      "precision all 0.6084710743801653\n",
      "recall all 0.4243515850144092\n",
      "accuracy all 0.9046694181435624\n",
      "TP,FP,TN,FN\n",
      "589 379 10590 799\n",
      "<--------------------------------------->\n"
     ]
    }
   ],
   "source": [
    "#with cv values\n",
    "\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2970639  0.25734024 0.21243523 0.16753022 0.12435233 0.08635579]\n",
      " [0.06707421 0.0691119  0.07123451 0.0732722  0.0753948  0.07751741]\n",
      " [0.07105054 0.07237364 0.07369675 0.07488754 0.07621064 0.07753374]\n",
      " [0.10202882 0.09732432 0.09232579 0.08732726 0.08262276 0.07880035]\n",
      " [0.056      0.06036364 0.06472727 0.06909091 0.07345455 0.07781818]\n",
      " [0.04347826 0.08695652 0.08695652 0.08695652 0.08695652 0.08695652]]\n",
      "[0.658889519139158, 0.6604969746586907, 0.6618952361880452, 0.6585529501976722, 0.6551073505907278, 0.6544419389611392] [0.456289490696973, 0.4587152461586899, 0.45838417292153605, 0.4576078275701365, 0.456167833848038, 0.45398912350810755] [0.914, 0.9128, 0.91, 0.9067, 0.9035, 0.9005] [0.2410639032815199, 0.19697660543256398, 0.14770796043334905, 0.09843931543413409, 0.05089778615167216, 0.008838380505676258]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "acc_rate=[[0.2970639032815199, 0.06707420614705382, 0.07105054247155332, 0.10202881505439576, 0.056, 0.043478260869565216],\n",
    "[0.25734024179620035, 0.06911190354898965, 0.0723736438211167, 0.09732431637753602, 0.06036363636363636, 0.08695652173913043],\n",
    "[0.21243523316062177, 0.07123450500933945, 0.07369674517068008, 0.09232578653337253, 0.06472727272727273, 0.08695652173913043],\n",
    "[0.16753022452504318, 0.07327220241127526, 0.07488753638528711, 0.08732725668920906, 0.06909090909090909, 0.08695652173913043],\n",
    "[0.12435233160621761, 0.07539480387162506, 0.07621063773485048, 0.0826227580123493, 0.07345454545454545, 0.08695652173913043],\n",
    "[0.08635578583765112, 0.07751740533197486, 0.07753373908441387, 0.07880035283740076, 0.07781818181818181, 0.08695652173913043]]\n",
    "\n",
    "prec=[[0.7034883720930233, 0.6620253164556962, 0.6741154562383612, 0.6512968299711815, 0.7272727272727273, 0.0],\n",
    "[0.7181208053691275, 0.6511056511056511, 0.6672760511882998, 0.6525679758308157, 0.6746987951807228, 0.0],\n",
    "[0.7154471544715447, 0.6328963051251489, 0.6409335727109515, 0.6560509554140127, 0.6292134831460674, 0.0],\n",
    "[0.6804123711340206, 0.6164542294322132, 0.6201413427561837, 0.6430976430976431, 0.5894736842105263, 0.0],\n",
    "[0.6666666666666666, 0.5968468468468469, 0.5954861111111112, 0.6370106761565836, 0.5544554455445545, 0.0],\n",
    "[0.7058823529411765, 0.5756578947368421, 0.5665529010238908, 0.6417910447761194, 0.5327102803738317, 0.0]]\n",
    "\n",
    "rec=[[0.568075117370892, 0.4451063829787234, 0.4839572192513369, 0.45472837022132795, 0.4, 0.0],\n",
    "[0.5023474178403756, 0.451063829787234, 0.4879679144385027, 0.4346076458752515, 0.4, 0.0],\n",
    "[0.4131455399061033, 0.45191489361702125, 0.4772727272727273, 0.41448692152917505, 0.4, 0.0],\n",
    "[0.30985915492957744, 0.45276595744680853, 0.4692513368983957, 0.3843058350100604, 0.4, 0.0],\n",
    "[0.22535211267605634, 0.451063829787234, 0.4585561497326203, 0.36016096579476864, 0.4, 0.0],\n",
    "[0.16901408450704225, 0.44680851063829785, 0.44385026737967914, 0.3460764587525151, 0.40714285714285714, 0.0]]\n",
    "\n",
    "accu=[0.9140,0.9128,0.9100,0.9067, 0.9035, 0.9005]\n",
    "weighted_precision=[]\n",
    "weighted_recall=[]\n",
    "p=[0,3]\n",
    "r=[1,2,4]\n",
    "print(np.transpose(acc_rate))\n",
    "weight_prec=0\n",
    "weight_p=0\n",
    "weight_rec=0\n",
    "weight_r=0\n",
    "dp_list=[]\n",
    "     \n",
    "sizes=[579, 11778, 7558, 3401,1375]\n",
    "for i in range(6):\n",
    "    acc_list=[]\n",
    "    for j in range(5):\n",
    "        #print(j)\n",
    "        if j in p:\n",
    "            weight_prec=weight_prec+sizes[j]*prec[i][j]\n",
    "            weight_p=weight_p+sizes[j]\n",
    "            #print(j)\n",
    "        if j in r:    \n",
    "            weight_rec=weight_rec+sizes[j]*rec[i][j]\n",
    "            weight_r=weight_r+sizes[j]\n",
    "        #print(acc_rate[i][j])    \n",
    "        acc_list.append(acc_rate[i][j])\n",
    "    #print(acc_list)\n",
    "    dp=max(acc_list)-min(acc_list)   \n",
    "    dp_list.append(dp)     \n",
    "    wp=weight_prec/weight_p\n",
    "    wr=weight_rec/weight_r\n",
    "    weighted_precision.append(wp)\n",
    "    weighted_recall.append(wr)\n",
    "print(weighted_precision, weighted_recall,accu,dp_list)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitive attribute  1\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "579\n",
      "213\n",
      "0.36787564766839376\n",
      "sensitive attribute  2\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "11778\n",
      "1175\n",
      "0.09976226863644082\n",
      "sensitive attribute  3\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "7558\n",
      "748\n",
      "0.09896798094734056\n",
      "sensitive attribute  4\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "3401\n",
      "497\n",
      "0.14613349014995589\n",
      "sensitive attribute  5\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "1375\n",
      "140\n",
      "0.10181818181818182\n",
      "sensitive attribute  6\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "23\n",
      "3\n",
      "0.13043478260869565\n",
      "data acceptance rates\n",
      "[0.36787564766839376, 0.09976226863644082, 0.09896798094734056, 0.14613349014995589, 0.10181818181818182, 0.13043478260869565]\n",
      "data DP\n",
      "0.2689076667210532\n",
      "sensitive attribute  1\n",
      "prec reca accuracy for each sens\n",
      "0.7142857142857143 0.5633802816901409 0.7564766839378239\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "579\n",
      "168\n",
      "0.29015544041450775\n",
      "sensitive attribute  2\n",
      "prec reca accuracy for each sens\n",
      "0.6625 0.451063829787234 0.9223127865511972\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "11778\n",
      "800\n",
      "0.06792324673119375\n",
      "sensitive attribute  3\n",
      "prec reca accuracy for each sens\n",
      "0.6734317343173432 0.4879679144385027 0.9259063244244509\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "7558\n",
      "542\n",
      "0.071712093146335\n",
      "sensitive attribute  4\n",
      "prec reca accuracy for each sens\n",
      "0.659942363112392 0.4607645875251509 0.8865039694207586\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "3401\n",
      "347\n",
      "0.10202881505439576\n",
      "sensitive attribute  5\n",
      "prec reca accuracy for each sens\n",
      "0.717948717948718 0.4 0.9229090909090909\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "1375\n",
      "78\n",
      "0.05672727272727273\n",
      "sensitive attribute  6\n",
      "prec reca accuracy for each sens\n",
      "0.0 0.0 0.8260869565217391\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "23\n",
      "1\n",
      "0.043478260869565216\n",
      "data acceptance rates\n",
      "[0.29015544041450775, 0.06792324673119375, 0.071712093146335, 0.10202881505439576, 0.05672727272727273, 0.043478260869565216]\n",
      "data DP\n",
      "0.24667717954494253\n",
      "SVM accuracy--------------------------\n",
      "0.6714876033057852 0.46829971181556196 0.9145423646516144\n",
      "[[1, 1, 1, 1, 1, 1]]\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "1932.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639032815199, 0.06707420614705382, 0.07105054247155332, 0.10202881505439576, 0.056, 0.043478260869565216] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.2970639032815199, 0.06707420614705382, 0.07105054247155332, 0.10202881505439576, 0.056, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7034883720930233, 0.6620253164556962, 0.6722532588454376, 0.654178674351585, 0.7272727272727273, 0.0]\n",
      "individual recall\n",
      "[0.568075117370892, 0.4451063829787234, 0.48262032085561496, 0.4567404426559356, 0.4, 0.0]\n",
      "DP all\n",
      "0.2535856424119547\n",
      "precision all 0.6694386694386695\n",
      "recall all 0.46397694524495675\n",
      "accuracy all 0.9140568099053168\n",
      "TP,FP,TN,FN\n",
      "644 318 10651 744\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "1954.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.25734024179620035, 0.06911190354898965, 0.0723736438211167, 0.09732431637753602, 0.06036363636363636, 0.08695652173913043] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.25734024179620035, 0.06911190354898965, 0.0723736438211167, 0.09732431637753602, 0.06036363636363636, 0.08695652173913043]\n",
      "individul precision\n",
      "[0.7181208053691275, 0.6511056511056511, 0.6672760511882998, 0.6525679758308157, 0.6746987951807228, 0.0]\n",
      "individual recall\n",
      "[0.5023474178403756, 0.451063829787234, 0.4879679144385027, 0.4346076458752515, 0.4, 0.0]\n",
      "DP all\n",
      "0.19697660543256398\n",
      "precision all 0.6614745586708204\n",
      "recall all 0.4589337175792507\n",
      "accuracy all 0.9128429230395727\n",
      "TP,FP,TN,FN\n",
      "637 326 10643 751\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "2002.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.21243523316062177, 0.07123450500933945, 0.07369674517068008, 0.09232578653337253, 0.06472727272727273, 0.08695652173913043] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.21243523316062177, 0.07123450500933945, 0.07369674517068008, 0.09232578653337253, 0.06472727272727273, 0.08695652173913043]\n",
      "individul precision\n",
      "[0.7154471544715447, 0.6328963051251489, 0.6409335727109515, 0.6560509554140127, 0.6292134831460674, 0.0]\n",
      "individual recall\n",
      "[0.4131455399061033, 0.45191489361702125, 0.4772727272727273, 0.41448692152917505, 0.4, 0.0]\n",
      "DP all\n",
      "0.14770796043334905\n",
      "precision all 0.6434511434511434\n",
      "recall all 0.44596541786743515\n",
      "accuracy all 0.9100105203528365\n",
      "TP,FP,TN,FN\n",
      "619 343 10626 769\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "2046.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.16753022452504318, 0.07327220241127526, 0.07488753638528711, 0.08732725668920906, 0.06909090909090909, 0.08695652173913043] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.16753022452504318, 0.07327220241127526, 0.07488753638528711, 0.08732725668920906, 0.06909090909090909, 0.08695652173913043]\n",
      "individul precision\n",
      "[0.6804123711340206, 0.6164542294322132, 0.6201413427561837, 0.6430976430976431, 0.5894736842105263, 0.0]\n",
      "individual recall\n",
      "[0.30985915492957744, 0.45276595744680853, 0.4692513368983957, 0.3843058350100604, 0.4, 0.0]\n",
      "DP all\n",
      "0.09843931543413409\n",
      "precision all 0.6229166666666667\n",
      "recall all 0.430835734870317\n",
      "accuracy all 0.9067734887108522\n",
      "TP,FP,TN,FN\n",
      "598 362 10607 790\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "2104.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.12435233160621761, 0.07539480387162506, 0.07621063773485048, 0.0826227580123493, 0.07345454545454545, 0.08695652173913043] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.12435233160621761, 0.07539480387162506, 0.07621063773485048, 0.0826227580123493, 0.07345454545454545, 0.08695652173913043]\n",
      "individul precision\n",
      "[0.6666666666666666, 0.5968468468468469, 0.5954861111111112, 0.6370106761565836, 0.5544554455445545, 0.0]\n",
      "individual recall\n",
      "[0.22535211267605634, 0.451063829787234, 0.4585561497326203, 0.36016096579476864, 0.4, 0.0]\n",
      "DP all\n",
      "0.05089778615167216\n",
      "precision all 0.6020833333333333\n",
      "recall all 0.4164265129682997\n",
      "accuracy all 0.9035364570688679\n",
      "TP,FP,TN,FN\n",
      "578 382 10587 810\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "2186.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.08635578583765112, 0.07751740533197486, 0.07753373908441387, 0.07880035283740076, 0.07781818181818181, 0.08695652173913043] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.08635578583765112, 0.07751740533197486, 0.07753373908441387, 0.07880035283740076, 0.07781818181818181, 0.08695652173913043]\n",
      "individul precision\n",
      "[0.7, 0.5750273822562979, 0.5648464163822525, 0.6417910447761194, 0.5327102803738317, 0.0]\n",
      "individual recall\n",
      "[0.1643192488262911, 0.44680851063829785, 0.4425133689839572, 0.3460764587525151, 0.40714285714285714, 0.0]\n",
      "DP all\n",
      "0.00943911640715557\n",
      "precision all 0.5815160955347871\n",
      "recall all 0.4034582132564842\n",
      "accuracy all 0.9003803512179331\n",
      "TP,FP,TN,FN\n",
      "560 403 10566 828\n",
      "<--------------------------------------->\n"
     ]
    }
   ],
   "source": [
    "#without cv values--part 2\n",
    "\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitive attribute  1\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "579\n",
      "213\n",
      "0.36787564766839376\n",
      "sensitive attribute  2\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "11778\n",
      "1175\n",
      "0.09976226863644082\n",
      "sensitive attribute  3\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "7558\n",
      "748\n",
      "0.09896798094734056\n",
      "sensitive attribute  4\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "3401\n",
      "497\n",
      "0.14613349014995589\n",
      "sensitive attribute  5\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "1375\n",
      "140\n",
      "0.10181818181818182\n",
      "sensitive attribute  6\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "23\n",
      "3\n",
      "0.13043478260869565\n",
      "data acceptance rates\n",
      "[0.36787564766839376, 0.09976226863644082, 0.09896798094734056, 0.14613349014995589, 0.10181818181818182, 0.13043478260869565]\n",
      "data DP\n",
      "0.2689076667210532\n",
      "sensitive attribute  1\n",
      "prec reca accuracy for each sens\n",
      "0.7142857142857143 0.5633802816901409 0.7564766839378239\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "579\n",
      "168\n",
      "0.29015544041450775\n",
      "sensitive attribute  2\n",
      "prec reca accuracy for each sens\n",
      "0.6625 0.451063829787234 0.9223127865511972\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "11778\n",
      "800\n",
      "0.06792324673119375\n",
      "sensitive attribute  3\n",
      "prec reca accuracy for each sens\n",
      "0.6734317343173432 0.4879679144385027 0.9259063244244509\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "7558\n",
      "542\n",
      "0.071712093146335\n",
      "sensitive attribute  4\n",
      "prec reca accuracy for each sens\n",
      "0.659942363112392 0.4607645875251509 0.8865039694207586\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "3401\n",
      "347\n",
      "0.10202881505439576\n",
      "sensitive attribute  5\n",
      "prec reca accuracy for each sens\n",
      "0.717948717948718 0.4 0.9229090909090909\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "1375\n",
      "78\n",
      "0.05672727272727273\n",
      "sensitive attribute  6\n",
      "prec reca accuracy for each sens\n",
      "0.0 0.0 0.8260869565217391\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "23\n",
      "1\n",
      "0.043478260869565216\n",
      "data acceptance rates\n",
      "[0.29015544041450775, 0.06792324673119375, 0.071712093146335, 0.10202881505439576, 0.05672727272727273, 0.043478260869565216]\n",
      "data DP\n",
      "0.24667717954494253\n",
      "SVM accuracy--------------------------\n",
      "0.6714876033057852 0.46829971181556196 0.9145423646516144\n",
      "[[1, 0.1, 1, 1, 1, 1], [1, 1, 1, 1, 0.01, 1], [1, 1, 1, 1, 1, 0.001]]\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "329059.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.2987910189982729, 0.058074375955170655, 0.06311193437417306, 0.0911496618641576, 0.05018181818181818, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.6994219653179191, 0.6388888888888888, 0.6918238993710691, 0.6483870967741936, 0.391304347826087, 0.0]\n",
      "individual recall\n",
      "[0.568075117370892, 0.3719148936170213, 0.4411764705882353, 0.4044265593561368, 0.19285714285714287, 0.0]\n",
      "DP all\n",
      "0.2553127581287077\n",
      "precision all 0.6511085180863477\n",
      "recall all 0.4020172910662824\n",
      "accuracy all 0.9086347819049931\n",
      "TP,FP,TN,FN\n",
      "558 299 10670 830\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "503874.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 1\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.307426597582038, 0.058074375955170655, 0.06311193437417306, 0.0911496618641576, 0.05381818181818182, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.6573033707865169, 0.6812865497076024, 0.6918238993710691, 0.6483870967741936, 0.7027027027027027, 0.0]\n",
      "individual recall\n",
      "[0.5492957746478874, 0.39659574468085107, 0.4411764705882353, 0.4044265593561368, 0.37142857142857144, 0.0]\n",
      "DP all\n",
      "0.26394833671247275\n",
      "precision all 0.6763341067285383\n",
      "recall all 0.420028818443804\n",
      "accuracy all 0.9122764425022255\n",
      "TP,FP,TN,FN\n",
      "583 279 10690 805\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "562793.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 2\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.3005181347150259, 0.058074375955170655, 0.06311193437417306, 0.0911496618641576, 0.05018181818181818, 0.08695652173913043]\n",
      "individul precision\n",
      "[0.6494252873563219, 0.6549707602339181, 0.6876310272536688, 0.6451612903225806, 0.4782608695652174, 0.0]\n",
      "individual recall\n",
      "[0.5305164319248826, 0.38127659574468087, 0.4385026737967914, 0.4024144869215292, 0.2357142857142857, 0.0]\n",
      "DP all\n",
      "0.25033631653320776\n",
      "precision all 0.6538461538461539\n",
      "recall all 0.404178674351585\n",
      "accuracy all 0.9090394108602412\n",
      "TP,FP,TN,FN\n",
      "561 297 10672 827\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "291284.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.21588946 0.05569706 0.05993649 0.07821229 0.04436364 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.2158894645941278, 0.05561215826116488, 0.05993649113522096, 0.07791825933548956, 0.04436363636363636, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.744, 0.648854961832061, 0.6909492273730684, 0.6943396226415094, 0.3442622950819672, 0.0]\n",
      "individual recall\n",
      "[0.43661971830985913, 0.3617021276595745, 0.4184491978609626, 0.3702213279678068, 0.15, 0.0]\n",
      "DP all\n",
      "0.1724112037245626\n",
      "precision all 0.6641025641025641\n",
      "recall all 0.37319884726224783\n",
      "accuracy all 0.9083920045318443\n",
      "TP,FP,TN,FN\n",
      "518 262 10707 870\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "452755.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.21588946 0.05569706 0.05993649 0.07821229 0.04436364 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 1\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.22625215889464595, 0.05561215826116488, 0.05980418100026462, 0.07791825933548956, 0.04945454545454545, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.732824427480916, 0.6870229007633588, 0.6946902654867256, 0.6943396226415094, 0.7058823529411765, 0.0]\n",
      "individual recall\n",
      "[0.4507042253521127, 0.3829787234042553, 0.4197860962566845, 0.3702213279678068, 0.34285714285714286, 0.0]\n",
      "DP all\n",
      "0.18277389802508073\n",
      "precision all 0.6946564885496184\n",
      "recall all 0.39337175792507206\n",
      "accuracy all 0.9124382940843246\n",
      "TP,FP,TN,FN\n",
      "546 240 10729 842\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "505744.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.21588946 0.05569706 0.05993649 0.07821229 0.04436364 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 2\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.2158894645941278, 0.05561215826116488, 0.05980418100026462, 0.07791825933548956, 0.04436363636363636, 0.08695652173913043]\n",
      "individul precision\n",
      "[0.712, 0.665648854961832, 0.6836283185840708, 0.690566037735849, 0.5409836065573771, 0.0]\n",
      "individual recall\n",
      "[0.41784037558685444, 0.37106382978723407, 0.41310160427807485, 0.3682092555331992, 0.2357142857142857, 0.0]\n",
      "DP all\n",
      "0.17152582823049145\n",
      "precision all 0.6730769230769231\n",
      "recall all 0.37824207492795386\n",
      "accuracy all 0.9095249656065388\n",
      "TP,FP,TN,FN\n",
      "525 255 10714 863\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "289851.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.12780656 0.05629139 0.05715798 0.07203764 0.04290909 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.12607944732297063, 0.05620648667006283, 0.05702566816618153, 0.07203763598941487, 0.04218181818181818, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7808219178082192, 0.648036253776435, 0.6867749419953596, 0.7061224489795919, 0.29310344827586204, 0.0]\n",
      "individual recall\n",
      "[0.2676056338028169, 0.3651063829787234, 0.39572192513368987, 0.34808853118712274, 0.12142857142857143, 0.0]\n",
      "DP all\n",
      "0.08389762914115245\n",
      "precision all 0.6612244897959184\n",
      "recall all 0.35014409221902015\n",
      "accuracy all 0.9068544145019017\n",
      "TP,FP,TN,FN\n",
      "486 249 10720 902\n",
      "dimension of data\n",
      "6 12357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal\n",
      "objective is:\n",
      "455959.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.12780656 0.05629139 0.05715798 0.07203764 0.04290909 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 1\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.1381692573402418, 0.05620648667006283, 0.05702566816618153, 0.07203763598941487, 0.04727272727272727, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7625, 0.6888217522658611, 0.6890951276102089, 0.7061224489795919, 0.7230769230769231, 0.0]\n",
      "individual recall\n",
      "[0.2863849765258216, 0.3880851063829787, 0.39705882352941174, 0.34808853118712274, 0.3357142857142857, 0.0]\n",
      "DP all\n",
      "0.09469099647067658\n",
      "precision all 0.6967654986522911\n",
      "recall all 0.37247838616714696\n",
      "accuracy all 0.9113053330096301\n",
      "TP,FP,TN,FN\n",
      "517 225 10744 871\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "509580.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.12780656 0.05629139 0.05715798 0.07203764 0.04290909 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 2\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.12780656303972365, 0.05620648667006283, 0.05702566816618153, 0.07203763598941487, 0.04218181818181818, 0.08695652173913043]\n",
      "individul precision\n",
      "[0.7162162162162162, 0.6616314199395771, 0.679814385150812, 0.6775510204081633, 0.5517241379310345, 0.0]\n",
      "individual recall\n",
      "[0.24882629107981222, 0.3727659574468085, 0.3917112299465241, 0.33400402414486924, 0.22857142857142856, 0.0]\n",
      "DP all\n",
      "0.08562474485790547\n",
      "precision all 0.6671195652173914\n",
      "recall all 0.3537463976945245\n",
      "accuracy all 0.9075827466213482\n",
      "TP,FP,TN,FN\n",
      "491 245 10724 897\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "287085.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.09671848 0.05603668 0.05530564 0.06821523 0.04727273 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.09499136442141623, 0.056036678553234846, 0.05530563641174914, 0.0679211996471626, 0.04727272727272727, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7636363636363637, 0.6454545454545455, 0.6818181818181818, 0.7056277056277056, 0.3076923076923077, 0.0]\n",
      "individual recall\n",
      "[0.19718309859154928, 0.3625531914893617, 0.3810160427807487, 0.32796780684104626, 0.14285714285714285, 0.0]\n",
      "DP all\n",
      "0.051513103551851014\n",
      "precision all 0.6545454545454545\n",
      "recall all 0.3371757925072046\n",
      "accuracy all 0.9055596018451081\n",
      "TP,FP,TN,FN\n",
      "468 247 10722 920\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "447208.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.09671848 0.05603668 0.05530564 0.06821523 0.04727273 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 1\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.1070811744386874, 0.056036678553234846, 0.055173326276792806, 0.0679211996471626, 0.05309090909090909, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7419354838709677, 0.6878787878787879, 0.6858513189448441, 0.7056277056277056, 0.6986301369863014, 0.0]\n",
      "individual recall\n",
      "[0.215962441314554, 0.38638297872340427, 0.38235294117647056, 0.32796780684104626, 0.36428571428571427, 0.0]\n",
      "DP all\n",
      "0.06360291356912218\n",
      "precision all 0.6925207756232687\n",
      "recall all 0.36023054755043227\n",
      "accuracy all 0.9101723719349356\n",
      "TP,FP,TN,FN\n",
      "500 222 10747 888\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "508155.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.09671848 0.05603668 0.05530564 0.06821523 0.04727273 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 2\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.09499136442141623, 0.056036678553234846, 0.055173326276792806, 0.0679211996471626, 0.04727272727272727, 0.08695652173913043]\n",
      "individul precision\n",
      "[0.6545454545454545, 0.6621212121212121, 0.6786570743405276, 0.6796536796536796, 0.5076923076923077, 0.0]\n",
      "individual recall\n",
      "[0.16901408450704225, 0.3719148936170213, 0.3783422459893048, 0.3158953722334004, 0.2357142857142857, 0.0]\n",
      "DP all\n",
      "0.04771863714868896\n",
      "precision all 0.6615384615384615\n",
      "recall all 0.3407780979827089\n",
      "accuracy all 0.9063688597556041\n",
      "TP,FP,TN,FN\n",
      "473 242 10727 915\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "305644.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.10708117 0.05781966 0.05715798 0.07438989 0.04145455 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.10535405872193437, 0.05781966377992868, 0.05715797830113787, 0.07409585416054101, 0.04145454545454545, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7868852459016393, 0.6417033773861968, 0.6782407407407407, 0.6944444444444444, 0.2982456140350877, 0.0]\n",
      "individual recall\n",
      "[0.22535211267605634, 0.3719148936170213, 0.3917112299465241, 0.352112676056338, 0.12142857142857143, 0.0]\n",
      "DP all\n",
      "0.06389951326738892\n",
      "precision all 0.6536388140161725\n",
      "recall all 0.34942363112391933\n",
      "accuracy all 0.9061260823824553\n",
      "TP,FP,TN,FN\n",
      "485 257 10712 903\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "482295.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.10708117 0.05781966 0.05715798 0.07438989 0.04145455 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 1\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.11744386873920552, 0.05781966377992868, 0.05702566816618153, 0.07409585416054101, 0.04727272727272727, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.75, 0.684287812041116, 0.6844547563805105, 0.6944444444444444, 0.7230769230769231, 0.0]\n",
      "individual recall\n",
      "[0.23943661971830985, 0.39659574468085107, 0.39438502673796794, 0.352112676056338, 0.3357142857142857, 0.0]\n",
      "DP all\n",
      "0.0739656078696403\n",
      "precision all 0.6902536715620827\n",
      "recall all 0.37247838616714696\n",
      "accuracy all 0.9107388524722829\n",
      "TP,FP,TN,FN\n",
      "517 232 10737 871\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "537702.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.10708117 0.05781966 0.05715798 0.07438989 0.04145455 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 2\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.10535405872193437, 0.05781966377992868, 0.05702566816618153, 0.07409585416054101, 0.04145454545454545, 0.08695652173913043]\n",
      "individul precision\n",
      "[0.7049180327868853, 0.6593245227606461, 0.6774941995359629, 0.6706349206349206, 0.543859649122807, 0.0]\n",
      "individual recall\n",
      "[0.20187793427230047, 0.3821276595744681, 0.39037433155080214, 0.34004024144869216, 0.22142857142857142, 0.0]\n",
      "DP all\n",
      "0.06389951326738892\n",
      "precision all 0.6630727762803235\n",
      "recall all 0.35446685878962536\n",
      "accuracy all 0.9072590434571498\n",
      "TP,FP,TN,FN\n",
      "492 250 10719 896\n",
      "<--------------------------------------->\n"
     ]
    }
   ],
   "source": [
    "#bilal final( 3 iteration for each->)\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitive attribute  1\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "579\n",
      "213\n",
      "0.36787564766839376\n",
      "sensitive attribute  2\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "11778\n",
      "1175\n",
      "0.09976226863644082\n",
      "sensitive attribute  3\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "7558\n",
      "748\n",
      "0.09896798094734056\n",
      "sensitive attribute  4\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "3401\n",
      "497\n",
      "0.14613349014995589\n",
      "sensitive attribute  5\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "1375\n",
      "140\n",
      "0.10181818181818182\n",
      "sensitive attribute  6\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "23\n",
      "3\n",
      "0.13043478260869565\n",
      "data acceptance rates\n",
      "[0.36787564766839376, 0.09976226863644082, 0.09896798094734056, 0.14613349014995589, 0.10181818181818182, 0.13043478260869565]\n",
      "data DP\n",
      "0.2689076667210532\n",
      "sensitive attribute  1\n",
      "prec reca accuracy for each sens\n",
      "0.7142857142857143 0.5633802816901409 0.7564766839378239\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "579\n",
      "168\n",
      "0.29015544041450775\n",
      "sensitive attribute  2\n",
      "prec reca accuracy for each sens\n",
      "0.6625 0.451063829787234 0.9223127865511972\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "11778\n",
      "800\n",
      "0.06792324673119375\n",
      "sensitive attribute  3\n",
      "prec reca accuracy for each sens\n",
      "0.6734317343173432 0.4879679144385027 0.9259063244244509\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "7558\n",
      "542\n",
      "0.071712093146335\n",
      "sensitive attribute  4\n",
      "prec reca accuracy for each sens\n",
      "0.659942363112392 0.4607645875251509 0.8865039694207586\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "3401\n",
      "347\n",
      "0.10202881505439576\n",
      "sensitive attribute  5\n",
      "prec reca accuracy for each sens\n",
      "0.717948717948718 0.4 0.9229090909090909\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "1375\n",
      "78\n",
      "0.05672727272727273\n",
      "sensitive attribute  6\n",
      "prec reca accuracy for each sens\n",
      "0.0 0.0 0.8260869565217391\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "23\n",
      "1\n",
      "0.043478260869565216\n",
      "data acceptance rates\n",
      "[0.29015544041450775, 0.06792324673119375, 0.071712093146335, 0.10202881505439576, 0.05672727272727273, 0.043478260869565216]\n",
      "data DP\n",
      "0.24667717954494253\n",
      "SVM accuracy--------------------------\n",
      "0.6714876033057852 0.46829971181556196 0.9145423646516144\n",
      "[[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 0.01, 1], [0.01, 0.1, 1, 1, 1, 1]]\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "426561.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.08117443868739206, 0.05136695534046527, 0.050410161418364643, 0.06292266980299911, 0.04072727272727273, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7021276595744681, 0.6776859504132231, 0.6902887139107612, 0.6915887850467289, 0.5714285714285714, 0.0]\n",
      "individual recall\n",
      "[0.15492957746478872, 0.34893617021276596, 0.3516042780748663, 0.2977867203219316, 0.22857142857142856, 0.0]\n",
      "DP all\n",
      "0.04044716596011933\n",
      "precision all 0.6794478527607362\n",
      "recall all 0.319164265129683\n",
      "accuracy all 0.9066116371287529\n",
      "TP,FP,TN,FN\n",
      "443 209 10760 945\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "376195.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 1\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.0846286701208981, 0.05136695534046527, 0.04961630060862662, 0.06292266980299911, 0.04654545454545454, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7551020408163265, 0.6859504132231405, 0.6826666666666666, 0.7009345794392523, 0.71875, 0.0]\n",
      "individual recall\n",
      "[0.17370892018779344, 0.35319148936170214, 0.3422459893048128, 0.30181086519114686, 0.32857142857142857, 0.0]\n",
      "DP all\n",
      "0.041150409251332884\n",
      "precision all 0.691131498470948\n",
      "recall all 0.3256484149855908\n",
      "accuracy all 0.9079064497855467\n",
      "TP,FP,TN,FN\n",
      "452 202 10767 936\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "238570.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 2\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.08290155440414508, 0.05136695534046527, 0.050542471553320985, 0.06292266980299911, 0.04072727272727273, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.8125, 0.6528925619834711, 0.6884816753926701, 0.7149532710280374, 0.32142857142857145, 0.0]\n",
      "individual recall\n",
      "[0.18309859154929578, 0.33617021276595743, 0.3516042780748663, 0.30784708249496984, 0.12857142857142856, 0.0]\n",
      "DP all\n",
      "0.04217428167687235\n",
      "precision all 0.664624808575804\n",
      "recall all 0.3126801152737752\n",
      "accuracy all 0.9050740470988103\n",
      "TP,FP,TN,FN\n",
      "434 219 10750 954\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "423884.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.0725389 0.051367  0.0497486 0.0649809 0.0349091 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.07772020725388601, 0.05136695534046527, 0.05027785128340831, 0.06498088797412525, 0.03490909090909091, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7555555555555555, 0.6776859504132231, 0.6894736842105263, 0.6968325791855203, 0.5833333333333334, 0.0]\n",
      "individual recall\n",
      "[0.1596244131455399, 0.34893617021276596, 0.3502673796791444, 0.30985915492957744, 0.2, 0.0]\n",
      "DP all\n",
      "0.0428111163447951\n",
      "precision all 0.683076923076923\n",
      "recall all 0.31988472622478387\n",
      "accuracy all 0.9069353402929513\n",
      "TP,FP,TN,FN\n",
      "444 206 10763 944\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "379941.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.0725389 0.051367  0.0497486 0.0649809 0.0349091 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 1\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.08290155440414508, 0.05136695534046527, 0.04961630060862662, 0.06498088797412525, 0.04072727272727273, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.75, 0.6809917355371901, 0.6773333333333333, 0.6968325791855203, 0.7142857142857143, 0.0]\n",
      "individual recall\n",
      "[0.16901408450704225, 0.3506382978723404, 0.339572192513369, 0.30985915492957744, 0.2857142857142857, 0.0]\n",
      "DP all\n",
      "0.04217428167687235\n",
      "precision all 0.6860643185298622\n",
      "recall all 0.3227665706051873\n",
      "accuracy all 0.9073399692481994\n",
      "TP,FP,TN,FN\n",
      "448 205 10764 940\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "238268.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.0725389 0.051367  0.0497486 0.0649809 0.0349091 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 2\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.08290155440414508, 0.05136695534046527, 0.05067478168827732, 0.06498088797412525, 0.03490909090909091, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.8333333333333334, 0.6528925619834711, 0.6866840731070496, 0.7058823529411765, 0.3333333333333333, 0.0]\n",
      "individual recall\n",
      "[0.18779342723004694, 0.33617021276595743, 0.3516042780748663, 0.31388329979879276, 0.11428571428571428, 0.0]\n",
      "DP all\n",
      "0.04799246349505417\n",
      "precision all 0.666156202143951\n",
      "recall all 0.3134005763688761\n",
      "accuracy all 0.9052358986809096\n",
      "TP,FP,TN,FN\n",
      "435 218 10751 953\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "429601.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.0794473 0.0517915 0.0493517 0.0729197 0.0254545 0.       ] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.08808290155440414, 0.051791475632535236, 0.050145541148451975, 0.07262569832402235, 0.024727272727272726, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.8235294117647058, 0.6721311475409836, 0.6886543535620053, 0.6923076923076923, 0.5882352941176471, 0.0]\n",
      "individual recall\n",
      "[0.19718309859154928, 0.34893617021276596, 0.34893048128342247, 0.3440643863179074, 0.14285714285714285, 0.0]\n",
      "DP all\n",
      "0.06335562882713142\n",
      "precision all 0.6838124054462935\n",
      "recall all 0.3256484149855908\n",
      "accuracy all 0.9073399692481994\n",
      "TP,FP,TN,FN\n",
      "452 209 10760 936\n",
      "dimension of data\n",
      "6 12357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal\n",
      "objective is:\n",
      "397021.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.0794473 0.0517915 0.0493517 0.0729197 0.0254545 0.       ] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 1\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.08981001727115717, 0.051791475632535236, 0.04935168033871395, 0.07262569832402235, 0.030545454545454546, 0.0]\n",
      "individul precision\n",
      "[0.7692307692307693, 0.6836065573770492, 0.67828418230563, 0.708502024291498, 0.6904761904761905, 0]\n",
      "individual recall\n",
      "[0.18779342723004694, 0.3548936170212766, 0.3382352941176471, 0.352112676056338, 0.20714285714285716, 0.0]\n",
      "DP all\n",
      "0.08981001727115717\n",
      "precision all 0.6903323262839879\n",
      "recall all 0.3292507204610951\n",
      "accuracy all 0.9080683013676458\n",
      "TP,FP,TN,FN\n",
      "457 205 10764 931\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "243640.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.0794473 0.0517915 0.0493517 0.0729197 0.0254545 0.       ] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 2\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.08981001727115717, 0.051791475632535236, 0.0498809208785393, 0.07262569832402235, 0.02690909090909091, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7884615384615384, 0.659016393442623, 0.6870026525198939, 0.7044534412955465, 0.2702702702702703, 0.0]\n",
      "individual recall\n",
      "[0.19248826291079812, 0.3421276595744681, 0.3462566844919786, 0.3501006036217304, 0.07142857142857142, 0.0]\n",
      "DP all\n",
      "0.06290092636206626\n",
      "precision all 0.6691842900302115\n",
      "recall all 0.319164265129683\n",
      "accuracy all 0.9058023792182569\n",
      "TP,FP,TN,FN\n",
      "443 219 10750 945\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "439271.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.0777202 0.0524707 0.0501455 0.0738018 0.024     0.       ] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.08635578583765112, 0.05238580404143318, 0.05067478168827732, 0.07350779182593355, 0.024, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.82, 0.6709886547811994, 0.6866840731070496, 0.692, 0.5757575757575758, 0.0]\n",
      "individual recall\n",
      "[0.19248826291079812, 0.3523404255319149, 0.3516042780748663, 0.34808853118712274, 0.1357142857142857, 0.0]\n",
      "DP all\n",
      "0.06235578583765112\n",
      "precision all 0.6821589205397302\n",
      "recall all 0.32780979827089335\n",
      "accuracy all 0.9073399692481994\n",
      "TP,FP,TN,FN\n",
      "455 212 10757 933\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "407872.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.0777202 0.0524707 0.0501455 0.0738018 0.024     0.       ] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 1\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.08808290155440414, 0.05238580404143318, 0.05001323101349563, 0.07350779182593355, 0.02909090909090909, 0.0]\n",
      "individul precision\n",
      "[0.7647058823529411, 0.6839546191247974, 0.6825396825396826, 0.704, 0.675, 0]\n",
      "individual recall\n",
      "[0.18309859154929578, 0.35914893617021276, 0.3449197860962567, 0.35412474849094566, 0.19285714285714287, 0.0]\n",
      "DP all\n",
      "0.08808290155440414\n",
      "precision all 0.6901197604790419\n",
      "recall all 0.33213256484149856\n",
      "accuracy all 0.9082301529497451\n",
      "TP,FP,TN,FN\n",
      "461 207 10762 927\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "249479.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.0777202 0.0524707 0.0501455 0.0738018 0.024     0.       ] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 2\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.08808290155440414, 0.05238580404143318, 0.05027785128340831, 0.07350779182593355, 0.02690909090909091, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7843137254901961, 0.6628849270664505, 0.6894736842105263, 0.708, 0.2702702702702703, 0.0]\n",
      "individual recall\n",
      "[0.18779342723004694, 0.34808510638297874, 0.3502673796791444, 0.3561368209255533, 0.07142857142857142, 0.0]\n",
      "DP all\n",
      "0.06117381064531323\n",
      "precision all 0.6721556886227545\n",
      "recall all 0.3234870317002882\n",
      "accuracy all 0.9062879339645545\n",
      "TP,FP,TN,FN\n",
      "449 219 10750 939\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "453593.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.0673575 0.0533197 0.0504102 0.0743899 0.024     0.       ] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.07772020725388601, 0.053234844625573104, 0.050939401958189995, 0.07438988532784475, 0.024, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.8222222222222222, 0.6666666666666666, 0.6857142857142857, 0.6837944664031621, 0.5454545454545454, 0.0]\n",
      "individual recall\n",
      "[0.17370892018779344, 0.3557446808510638, 0.35294117647058826, 0.34808853118712274, 0.12857142857142856, 0.0]\n",
      "DP all\n",
      "0.05372020725388601\n",
      "precision all 0.6770833333333334\n",
      "recall all 0.32780979827089335\n",
      "accuracy all 0.9069353402929513\n",
      "TP,FP,TN,FN\n",
      "455 217 10752 933\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "422930.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.0673575 0.0533197 0.0504102 0.0743899 0.024     0.       ] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 1\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.07772020725388601, 0.053234844625573104, 0.050410161418364643, 0.07438988532784475, 0.027636363636363636, 0.0]\n",
      "individul precision\n",
      "[0.8, 0.682615629984051, 0.6876640419947506, 0.6956521739130435, 0.6842105263157895, 0]\n",
      "individual recall\n",
      "[0.16901408450704225, 0.36425531914893616, 0.3502673796791444, 0.35412474849094566, 0.18571428571428572, 0.0]\n",
      "DP all\n",
      "0.07772020725388601\n",
      "precision all 0.6904761904761905\n",
      "recall all 0.33429394812680113\n",
      "accuracy all 0.9083920045318443\n",
      "TP,FP,TN,FN\n",
      "464 208 10761 924\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "258294.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.0673575 0.0533197 0.0504102 0.0743899 0.024     0.       ] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 2\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.07772020725388601, 0.053234844625573104, 0.050410161418364643, 0.07438988532784475, 0.02690909090909091, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.8222222222222222, 0.6586921850079744, 0.6902887139107612, 0.6996047430830039, 0.2702702702702703, 0.0]\n",
      "individual recall\n",
      "[0.17370892018779344, 0.35148936170212763, 0.3516042780748663, 0.3561368209255533, 0.07142857142857142, 0.0]\n",
      "DP all\n",
      "0.0508111163447951\n",
      "precision all 0.6696428571428571\n",
      "recall all 0.3242074927953891\n",
      "accuracy all 0.9061260823824553\n",
      "TP,FP,TN,FN\n",
      "450 222 10747 938\n",
      "<--------------------------------------->\n"
     ]
    }
   ],
   "source": [
    "#agarwal final\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitive attribute  1\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "579\n",
      "213\n",
      "0.36787564766839376\n",
      "sensitive attribute  2\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "11778\n",
      "1175\n",
      "0.09976226863644082\n",
      "sensitive attribute  3\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "7558\n",
      "748\n",
      "0.09896798094734056\n",
      "sensitive attribute  4\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "3401\n",
      "497\n",
      "0.14613349014995589\n",
      "sensitive attribute  5\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "1375\n",
      "140\n",
      "0.10181818181818182\n",
      "sensitive attribute  6\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "23\n",
      "3\n",
      "0.13043478260869565\n",
      "data acceptance rates\n",
      "[0.36787564766839376, 0.09976226863644082, 0.09896798094734056, 0.14613349014995589, 0.10181818181818182, 0.13043478260869565]\n",
      "data DP\n",
      "0.2689076667210532\n",
      "sensitive attribute  1\n",
      "prec reca accuracy for each sens\n",
      "0.7142857142857143 0.5633802816901409 0.7564766839378239\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "579\n",
      "168\n",
      "0.29015544041450775\n",
      "sensitive attribute  2\n",
      "prec reca accuracy for each sens\n",
      "0.6625 0.451063829787234 0.9223127865511972\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "11778\n",
      "800\n",
      "0.06792324673119375\n",
      "sensitive attribute  3\n",
      "prec reca accuracy for each sens\n",
      "0.6734317343173432 0.4879679144385027 0.9259063244244509\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "7558\n",
      "542\n",
      "0.071712093146335\n",
      "sensitive attribute  4\n",
      "prec reca accuracy for each sens\n",
      "0.659942363112392 0.4607645875251509 0.8865039694207586\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "3401\n",
      "347\n",
      "0.10202881505439576\n",
      "sensitive attribute  5\n",
      "prec reca accuracy for each sens\n",
      "0.717948717948718 0.4 0.9229090909090909\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "1375\n",
      "78\n",
      "0.05672727272727273\n",
      "sensitive attribute  6\n",
      "prec reca accuracy for each sens\n",
      "0.0 0.0 0.8260869565217391\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "23\n",
      "1\n",
      "0.043478260869565216\n",
      "data acceptance rates\n",
      "[0.29015544041450775, 0.06792324673119375, 0.071712093146335, 0.10202881505439576, 0.05672727272727273, 0.043478260869565216]\n",
      "data DP\n",
      "0.24667717954494253\n",
      "SVM accuracy--------------------------\n",
      "0.6714876033057852 0.46829971181556196 0.9145423646516144\n",
      "[[1, 1, 1, 1, 1, 1], [0.1, 1, 1, 1, 1, 1], [0.01, 1, 1, 1, 1, 1], [0.001, 1, 1, 1, 1, 1], [1, 0.1, 1, 1, 1, 1], [1, 0.01, 1, 1, 1, 1], [1, 0.001, 1, 1, 1, 1], [1, 1, 0.1, 1, 1, 1], [1, 1, 0.01, 1, 1, 1], [1, 1, 0.001, 1, 1, 1], [1, 1, 1, 0.1, 1, 1], [1, 1, 1, 0.01, 1, 1], [1, 1, 1, 0.001, 1, 1], [1, 1, 1, 1, 0.1, 1], [1, 1, 1, 1, 0.01, 1], [1, 1, 1, 1, 0.001, 1], [1, 1, 1, 1, 1, 0.1], [1, 1, 1, 1, 1, 0.01], [1, 1, 1, 1, 1, 0.001], [0.1, 0.1, 1, 1, 1, 1], [0.01, 0.01, 1, 1, 1, 1], [0.001, 0.001, 1, 1, 1, 1], [0.001, 0.01, 1, 1, 1, 1], [0.001, 0.1, 1, 1, 1, 1], [0.01, 0.1, 1, 1, 1, 1]]\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "538777.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.10535405872193437, 0.05781966377992868, 0.05715797830113787, 0.07409585416054101, 0.04145454545454545, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.6885245901639344, 0.6593245227606461, 0.6759259259259259, 0.6706349206349206, 0.5263157894736842, 0.0]\n",
      "individual recall\n",
      "[0.19718309859154928, 0.3821276595744681, 0.39037433155080214, 0.34004024144869216, 0.21428571428571427, 0.0]\n",
      "DP all\n",
      "0.06389951326738892\n",
      "precision all 0.6617250673854448\n",
      "recall all 0.3537463976945245\n",
      "accuracy all 0.9070971918750506\n",
      "TP,FP,TN,FN\n",
      "491 251 10718 897\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "534336.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 1\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.10535405872193437, 0.05781966377992868, 0.05715797830113787, 0.07409585416054101, 0.04145454545454545, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7049180327868853, 0.6593245227606461, 0.6736111111111112, 0.6746031746031746, 0.543859649122807, 0.0]\n",
      "individual recall\n",
      "[0.20187793427230047, 0.3821276595744681, 0.3890374331550802, 0.3420523138832998, 0.22142857142857142, 0.0]\n",
      "DP all\n",
      "0.06389951326738892\n",
      "precision all 0.6630727762803235\n",
      "recall all 0.35446685878962536\n",
      "accuracy all 0.9072590434571498\n",
      "TP,FP,TN,FN\n",
      "492 250 10719 896\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "533795.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 2\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.1070811744386874, 0.05781966377992868, 0.057290288436094204, 0.07409585416054101, 0.04145454545454545, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7096774193548387, 0.6607929515418502, 0.674364896073903, 0.6785714285714286, 0.543859649122807, 0.0]\n",
      "individual recall\n",
      "[0.20657276995305165, 0.3829787234042553, 0.39037433155080214, 0.3440643863179074, 0.22142857142857142, 0.0]\n",
      "DP all\n",
      "0.06562662898414194\n",
      "precision all 0.6648721399730821\n",
      "recall all 0.3559077809798271\n",
      "accuracy all 0.9075018208302986\n",
      "TP,FP,TN,FN\n",
      "494 249 10720 894\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "533763.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 3\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.1070811744386874, 0.05781966377992868, 0.057290288436094204, 0.07409585416054101, 0.04145454545454545, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7096774193548387, 0.6607929515418502, 0.674364896073903, 0.6785714285714286, 0.543859649122807, 0.0]\n",
      "individual recall\n",
      "[0.20657276995305165, 0.3829787234042553, 0.39037433155080214, 0.3440643863179074, 0.22142857142857142, 0.0]\n",
      "DP all\n",
      "0.06562662898414194\n",
      "precision all 0.6648721399730821\n",
      "recall all 0.3559077809798271\n",
      "accuracy all 0.9075018208302986\n",
      "TP,FP,TN,FN\n",
      "494 249 10720 894\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "305644.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 4\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.10535405872193437, 0.05781966377992868, 0.05715797830113787, 0.07409585416054101, 0.04145454545454545, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7868852459016393, 0.6417033773861968, 0.6782407407407407, 0.6944444444444444, 0.2982456140350877, 0.0]\n",
      "individual recall\n",
      "[0.22535211267605634, 0.3719148936170213, 0.3917112299465241, 0.352112676056338, 0.12142857142857143, 0.0]\n",
      "DP all\n",
      "0.06389951326738892\n",
      "precision all 0.6536388140161725\n",
      "recall all 0.34942363112391933\n",
      "accuracy all 0.9061260823824553\n",
      "TP,FP,TN,FN\n",
      "485 257 10712 903\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "268502.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 5\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.11744386873920552, 0.05781966377992868, 0.05702566816618153, 0.07409585416054101, 0.04727272727272727, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7647058823529411, 0.6284875183553598, 0.6821345707656613, 0.7023809523809523, 0.13846153846153847, 0.0]\n",
      "individual recall\n",
      "[0.24413145539906103, 0.36425531914893616, 0.393048128342246, 0.3561368209255533, 0.06428571428571428, 0.0]\n",
      "DP all\n",
      "0.0739656078696403\n",
      "precision all 0.6408544726301736\n",
      "recall all 0.345821325648415\n",
      "accuracy all 0.904750343934612\n",
      "TP,FP,TN,FN\n",
      "480 269 10700 908\n",
      "dimension of data\n",
      "6 12357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal\n",
      "objective is:\n",
      "264159.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 6\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.11744386873920552, 0.05781966377992868, 0.05702566816618153, 0.07409585416054101, 0.04727272727272727, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7647058823529411, 0.6284875183553598, 0.6821345707656613, 0.7023809523809523, 0.13846153846153847, 0.0]\n",
      "individual recall\n",
      "[0.24413145539906103, 0.36425531914893616, 0.393048128342246, 0.3561368209255533, 0.06428571428571428, 0.0]\n",
      "DP all\n",
      "0.0739656078696403\n",
      "precision all 0.6408544726301736\n",
      "recall all 0.345821325648415\n",
      "accuracy all 0.904750343934612\n",
      "TP,FP,TN,FN\n",
      "480 269 10700 908\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "382569.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 7\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.11744386873920552, 0.05781966377992868, 0.05808414924583223, 0.07409585416054101, 0.04145454545454545, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7352941176470589, 0.6637298091042585, 0.6742596810933941, 0.6904761904761905, 0.5614035087719298, 0.0]\n",
      "individual recall\n",
      "[0.2347417840375587, 0.38468085106382977, 0.39572192513368987, 0.3501006036217304, 0.22857142857142856, 0.0]\n",
      "DP all\n",
      "0.07598932328466007\n",
      "precision all 0.6702269692923899\n",
      "recall all 0.361671469740634\n",
      "accuracy all 0.9083110787407946\n",
      "TP,FP,TN,FN\n",
      "502 247 10722 886\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "366810.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 8\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.11744386873920552, 0.05781966377992868, 0.05808414924583223, 0.07409585416054101, 0.04145454545454545, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7352941176470589, 0.6637298091042585, 0.6742596810933941, 0.6904761904761905, 0.5614035087719298, 0.0]\n",
      "individual recall\n",
      "[0.2347417840375587, 0.38468085106382977, 0.39572192513368987, 0.3501006036217304, 0.22857142857142856, 0.0]\n",
      "DP all\n",
      "0.07598932328466007\n",
      "precision all 0.6702269692923899\n",
      "recall all 0.361671469740634\n",
      "accuracy all 0.9083110787407946\n",
      "TP,FP,TN,FN\n",
      "502 247 10722 886\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "365276.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 9\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.11744386873920552, 0.05781966377992868, 0.05808414924583223, 0.07409585416054101, 0.04145454545454545, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7352941176470589, 0.6637298091042585, 0.6742596810933941, 0.6904761904761905, 0.5614035087719298, 0.0]\n",
      "individual recall\n",
      "[0.2347417840375587, 0.38468085106382977, 0.39572192513368987, 0.3501006036217304, 0.22857142857142856, 0.0]\n",
      "DP all\n",
      "0.07598932328466007\n",
      "precision all 0.6702269692923899\n",
      "recall all 0.361671469740634\n",
      "accuracy all 0.9083110787407946\n",
      "TP,FP,TN,FN\n",
      "502 247 10722 886\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "421002.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 10\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.11744386873920552, 0.05781966377992868, 0.05702566816618153, 0.0764481034989709, 0.04145454545454545, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.6617647058823529, 0.6637298091042585, 0.6890951276102089, 0.65, 0.543859649122807, 0.0]\n",
      "individual recall\n",
      "[0.2112676056338028, 0.38468085106382977, 0.39705882352941174, 0.34004024144869216, 0.22142857142857142, 0.0]\n",
      "DP all\n",
      "0.07598932328466007\n",
      "precision all 0.6635514018691588\n",
      "recall all 0.3580691642651297\n",
      "accuracy all 0.9075018208302986\n",
      "TP,FP,TN,FN\n",
      "497 252 10717 891\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "408224.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 11\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.11744386873920552, 0.05781966377992868, 0.05702566816618153, 0.0764481034989709, 0.04145454545454545, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.6617647058823529, 0.6637298091042585, 0.6890951276102089, 0.65, 0.543859649122807, 0.0]\n",
      "individual recall\n",
      "[0.2112676056338028, 0.38468085106382977, 0.39705882352941174, 0.34004024144869216, 0.22142857142857142, 0.0]\n",
      "DP all\n",
      "0.07598932328466007\n",
      "precision all 0.6635514018691588\n",
      "recall all 0.3580691642651297\n",
      "accuracy all 0.9075018208302986\n",
      "TP,FP,TN,FN\n",
      "497 252 10717 891\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "406959.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 12\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.11744386873920552, 0.05781966377992868, 0.05702566816618153, 0.0764481034989709, 0.04145454545454545, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.6617647058823529, 0.6637298091042585, 0.6890951276102089, 0.65, 0.543859649122807, 0.0]\n",
      "individual recall\n",
      "[0.2112676056338028, 0.38468085106382977, 0.39705882352941174, 0.34004024144869216, 0.22142857142857142, 0.0]\n",
      "DP all\n",
      "0.07598932328466007\n",
      "precision all 0.6635514018691588\n",
      "recall all 0.3580691642651297\n",
      "accuracy all 0.9075018208302986\n",
      "TP,FP,TN,FN\n",
      "497 252 10717 891\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "495589.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 13\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.11744386873920552, 0.05781966377992868, 0.05702566816618153, 0.07409585416054101, 0.04727272727272727, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.75, 0.6798825256975036, 0.6844547563805105, 0.6944444444444444, 0.676923076923077, 0.0]\n",
      "individual recall\n",
      "[0.23943661971830985, 0.39404255319148934, 0.39438502673796794, 0.352112676056338, 0.3142857142857143, 0.0]\n",
      "DP all\n",
      "0.0739656078696403\n",
      "precision all 0.6862483311081442\n",
      "recall all 0.3703170028818444\n",
      "accuracy all 0.9102532977259853\n",
      "TP,FP,TN,FN\n",
      "514 235 10734 874\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "482295.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 14\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.11744386873920552, 0.05781966377992868, 0.05702566816618153, 0.07409585416054101, 0.04727272727272727, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.75, 0.684287812041116, 0.6844547563805105, 0.6944444444444444, 0.7230769230769231, 0.0]\n",
      "individual recall\n",
      "[0.23943661971830985, 0.39659574468085107, 0.39438502673796794, 0.352112676056338, 0.3357142857142857, 0.0]\n",
      "DP all\n",
      "0.0739656078696403\n",
      "precision all 0.6902536715620827\n",
      "recall all 0.37247838616714696\n",
      "accuracy all 0.9107388524722829\n",
      "TP,FP,TN,FN\n",
      "517 232 10737 871\n",
      "dimension of data\n",
      "6 12357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal\n",
      "objective is:\n",
      "480783.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 15\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.11744386873920552, 0.05781966377992868, 0.05702566816618153, 0.07409585416054101, 0.04727272727272727, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.75, 0.684287812041116, 0.6844547563805105, 0.6944444444444444, 0.7230769230769231, 0.0]\n",
      "individual recall\n",
      "[0.23943661971830985, 0.39659574468085107, 0.39438502673796794, 0.352112676056338, 0.3357142857142857, 0.0]\n",
      "DP all\n",
      "0.0739656078696403\n",
      "precision all 0.6902536715620827\n",
      "recall all 0.37247838616714696\n",
      "accuracy all 0.9107388524722829\n",
      "TP,FP,TN,FN\n",
      "517 232 10737 871\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "537854.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 16\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.10535405872193437, 0.05781966377992868, 0.05702566816618153, 0.07409585416054101, 0.04145454545454545, 0.08695652173913043]\n",
      "individul precision\n",
      "[0.6885245901639344, 0.657856093979442, 0.6751740139211136, 0.6706349206349206, 0.5263157894736842, 0.0]\n",
      "individual recall\n",
      "[0.19718309859154928, 0.38127659574468087, 0.3890374331550802, 0.34004024144869216, 0.21428571428571427, 0.0]\n",
      "DP all\n",
      "0.06389951326738892\n",
      "precision all 0.660377358490566\n",
      "recall all 0.3530259365994236\n",
      "accuracy all 0.9069353402929513\n",
      "TP,FP,TN,FN\n",
      "490 252 10717 898\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "537716.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 17\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.10535405872193437, 0.05781966377992868, 0.05702566816618153, 0.07409585416054101, 0.04145454545454545, 0.08695652173913043]\n",
      "individul precision\n",
      "[0.7049180327868853, 0.6593245227606461, 0.6774941995359629, 0.6706349206349206, 0.543859649122807, 0.0]\n",
      "individual recall\n",
      "[0.20187793427230047, 0.3821276595744681, 0.39037433155080214, 0.34004024144869216, 0.22142857142857142, 0.0]\n",
      "DP all\n",
      "0.06389951326738892\n",
      "precision all 0.6630727762803235\n",
      "recall all 0.35446685878962536\n",
      "accuracy all 0.9072590434571498\n",
      "TP,FP,TN,FN\n",
      "492 250 10719 896\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "537702.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 18\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.10535405872193437, 0.05781966377992868, 0.05702566816618153, 0.07409585416054101, 0.04145454545454545, 0.08695652173913043]\n",
      "individul precision\n",
      "[0.7049180327868853, 0.6593245227606461, 0.6774941995359629, 0.6706349206349206, 0.543859649122807, 0.0]\n",
      "individual recall\n",
      "[0.20187793427230047, 0.3821276595744681, 0.39037433155080214, 0.34004024144869216, 0.22142857142857142, 0.0]\n",
      "DP all\n",
      "0.06389951326738892\n",
      "precision all 0.6630727762803235\n",
      "recall all 0.35446685878962536\n",
      "accuracy all 0.9072590434571498\n",
      "TP,FP,TN,FN\n",
      "492 250 10719 896\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "302823.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 19\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.10535405872193437, 0.05781966377992868, 0.05715797830113787, 0.07409585416054101, 0.04145454545454545, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7868852459016393, 0.6431718061674009, 0.6736111111111112, 0.7063492063492064, 0.2982456140350877, 0.0]\n",
      "individual recall\n",
      "[0.22535211267605634, 0.3727659574468085, 0.3890374331550802, 0.358148893360161, 0.12142857142857143, 0.0]\n",
      "DP all\n",
      "0.06389951326738892\n",
      "precision all 0.6549865229110512\n",
      "recall all 0.35014409221902015\n",
      "accuracy all 0.9062879339645545\n",
      "TP,FP,TN,FN\n",
      "486 256 10713 902\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "264489.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 20\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.11744386873920552, 0.05781966377992868, 0.05702566816618153, 0.07409585416054101, 0.04727272727272727, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7058823529411765, 0.6270190895741556, 0.6751740139211136, 0.6944444444444444, 0.13846153846153847, 0.0]\n",
      "individual recall\n",
      "[0.22535211267605634, 0.36340425531914894, 0.3890374331550802, 0.352112676056338, 0.06428571428571428, 0.0]\n",
      "DP all\n",
      "0.0739656078696403\n",
      "precision all 0.6341789052069426\n",
      "recall all 0.34221902017291067\n",
      "accuracy all 0.9039410860241159\n",
      "TP,FP,TN,FN\n",
      "475 274 10695 913\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "260097.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 21\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.11744386873920552, 0.05781966377992868, 0.05702566816618153, 0.07409585416054101, 0.04727272727272727, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7058823529411765, 0.6270190895741556, 0.6751740139211136, 0.6944444444444444, 0.13846153846153847, 0.0]\n",
      "individual recall\n",
      "[0.22535211267605634, 0.36340425531914894, 0.3890374331550802, 0.352112676056338, 0.06428571428571428, 0.0]\n",
      "DP all\n",
      "0.0739656078696403\n",
      "precision all 0.6341789052069426\n",
      "recall all 0.34221902017291067\n",
      "accuracy all 0.9039410860241159\n",
      "TP,FP,TN,FN\n",
      "475 274 10695 913\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "264463.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 22\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.11744386873920552, 0.05781966377992868, 0.05702566816618153, 0.07409585416054101, 0.04727272727272727, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7058823529411765, 0.6270190895741556, 0.6751740139211136, 0.6944444444444444, 0.13846153846153847, 0.0]\n",
      "individual recall\n",
      "[0.22535211267605634, 0.36340425531914894, 0.3890374331550802, 0.352112676056338, 0.06428571428571428, 0.0]\n",
      "DP all\n",
      "0.0739656078696403\n",
      "precision all 0.6341789052069426\n",
      "recall all 0.34221902017291067\n",
      "accuracy all 0.9039410860241159\n",
      "TP,FP,TN,FN\n",
      "475 274 10695 913\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "302449.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 23\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.10535405872193437, 0.05781966377992868, 0.05715797830113787, 0.07409585416054101, 0.04145454545454545, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7868852459016393, 0.6431718061674009, 0.6736111111111112, 0.7063492063492064, 0.2982456140350877, 0.0]\n",
      "individual recall\n",
      "[0.22535211267605634, 0.3727659574468085, 0.3890374331550802, 0.358148893360161, 0.12142857142857143, 0.0]\n",
      "DP all\n",
      "0.06389951326738892\n",
      "precision all 0.6549865229110512\n",
      "recall all 0.35014409221902015\n",
      "accuracy all 0.9062879339645545\n",
      "TP,FP,TN,FN\n",
      "486 256 10713 902\n",
      "dimension of data\n",
      "6 12357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal\n",
      "objective is:\n",
      "302473.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.2970639  0.05815928 0.06311193 0.09114966 0.05018182 0.04347826] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 24\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.10535405872193437, 0.05781966377992868, 0.05715797830113787, 0.07409585416054101, 0.04145454545454545, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7868852459016393, 0.6431718061674009, 0.6736111111111112, 0.7063492063492064, 0.2982456140350877, 0.0]\n",
      "individual recall\n",
      "[0.22535211267605634, 0.3727659574468085, 0.3890374331550802, 0.358148893360161, 0.12142857142857143, 0.0]\n",
      "DP all\n",
      "0.06389951326738892\n",
      "precision all 0.6549865229110512\n",
      "recall all 0.35014409221902015\n",
      "accuracy all 0.9062879339645545\n",
      "TP,FP,TN,FN\n",
      "486 256 10713 902\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-dd9082b92883>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#bilal basic2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maccu_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDP_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macceptance_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-1db49712da01>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(datax, y_test, y_test_pred, e)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0meps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0mu1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_max_lp_all_ng5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0;31m#######################Disp_impact#######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gamma-epsilon-delta\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#bilal basic2\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitive attribute  1\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "579\n",
      "213\n",
      "0.36787564766839376\n",
      "sensitive attribute  2\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "11778\n",
      "1175\n",
      "0.09976226863644082\n",
      "sensitive attribute  3\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "7558\n",
      "748\n",
      "0.09896798094734056\n",
      "sensitive attribute  4\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "3401\n",
      "497\n",
      "0.14613349014995589\n",
      "sensitive attribute  5\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "1375\n",
      "140\n",
      "0.10181818181818182\n",
      "sensitive attribute  6\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "23\n",
      "3\n",
      "0.13043478260869565\n",
      "data acceptance rates\n",
      "[0.36787564766839376, 0.09976226863644082, 0.09896798094734056, 0.14613349014995589, 0.10181818181818182, 0.13043478260869565]\n",
      "data DP\n",
      "0.2689076667210532\n",
      "sensitive attribute  1\n",
      "prec reca accuracy for each sens\n",
      "0.7142857142857143 0.5633802816901409 0.7564766839378239\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "579\n",
      "168\n",
      "0.29015544041450775\n",
      "sensitive attribute  2\n",
      "prec reca accuracy for each sens\n",
      "0.6625 0.451063829787234 0.9223127865511972\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "11778\n",
      "800\n",
      "0.06792324673119375\n",
      "sensitive attribute  3\n",
      "prec reca accuracy for each sens\n",
      "0.6734317343173432 0.4879679144385027 0.9259063244244509\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "7558\n",
      "542\n",
      "0.071712093146335\n",
      "sensitive attribute  4\n",
      "prec reca accuracy for each sens\n",
      "0.659942363112392 0.4607645875251509 0.8865039694207586\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "3401\n",
      "347\n",
      "0.10202881505439576\n",
      "sensitive attribute  5\n",
      "prec reca accuracy for each sens\n",
      "0.717948717948718 0.4 0.9229090909090909\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "1375\n",
      "78\n",
      "0.05672727272727273\n",
      "sensitive attribute  6\n",
      "prec reca accuracy for each sens\n",
      "0.0 0.0 0.8260869565217391\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "23\n",
      "1\n",
      "0.043478260869565216\n",
      "data acceptance rates\n",
      "[0.29015544041450775, 0.06792324673119375, 0.071712093146335, 0.10202881505439576, 0.05672727272727273, 0.043478260869565216]\n",
      "data DP\n",
      "0.24667717954494253\n",
      "SVM accuracy--------------------------\n",
      "0.6714876033057852 0.46829971181556196 0.9145423646516144\n",
      "[[1, 1, 1, 1, 1, 1], [0.1, 1, 1, 1, 1, 1], [0.01, 1, 1, 1, 1, 1], [0.001, 1, 1, 1, 1, 1], [1, 0.1, 1, 1, 1, 1], [1, 0.01, 1, 1, 1, 1], [1, 0.001, 1, 1, 1, 1], [1, 1, 0.1, 1, 1, 1], [1, 1, 0.01, 1, 1, 1], [1, 1, 0.001, 1, 1, 1], [1, 1, 1, 0.1, 1, 1], [1, 1, 1, 0.01, 1, 1], [1, 1, 1, 0.001, 1, 1], [1, 1, 1, 1, 0.1, 1], [1, 1, 1, 1, 0.01, 1], [1, 1, 1, 1, 0.001, 1], [1, 1, 1, 1, 1, 0.1], [1, 1, 1, 1, 1, 0.01], [1, 1, 1, 1, 1, 0.001], [0.1, 0.1, 1, 1, 1, 1], [0.01, 0.01, 1, 1, 1, 1], [0.001, 0.001, 1, 1, 1, 1], [0.001, 0.01, 1, 1, 1, 1], [0.001, 0.1, 1, 1, 1, 1], [0.01, 0.1, 1, 1, 1, 1]]\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "426561.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 0\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.08117443868739206, 0.05136695534046527, 0.050410161418364643, 0.06292266980299911, 0.04072727272727273, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7021276595744681, 0.6776859504132231, 0.6902887139107612, 0.6915887850467289, 0.5714285714285714, 0.0]\n",
      "individual recall\n",
      "[0.15492957746478872, 0.34893617021276596, 0.3516042780748663, 0.2977867203219316, 0.22857142857142856, 0.0]\n",
      "DP all\n",
      "0.04044716596011933\n",
      "precision all 0.6794478527607362\n",
      "recall all 0.319164265129683\n",
      "accuracy all 0.9066116371287529\n",
      "TP,FP,TN,FN\n",
      "443 209 10760 945\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "422302.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 1\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.0846286701208981, 0.05136695534046527, 0.05067478168827732, 0.06292266980299911, 0.04072727272727273, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.673469387755102, 0.6743801652892562, 0.6866840731070496, 0.6915887850467289, 0.5357142857142857, 0.0]\n",
      "individual recall\n",
      "[0.15492957746478872, 0.3472340425531915, 0.3516042780748663, 0.2977867203219316, 0.21428571428571427, 0.0]\n",
      "DP all\n",
      "0.04390139739362537\n",
      "precision all 0.6743119266055045\n",
      "recall all 0.3177233429394813\n",
      "accuracy all 0.9061260823824553\n",
      "TP,FP,TN,FN\n",
      "441 213 10756 947\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "421816.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 2\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.0846286701208981, 0.05136695534046527, 0.05067478168827732, 0.06292266980299911, 0.04072727272727273, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.6530612244897959, 0.6760330578512397, 0.6866840731070496, 0.6915887850467289, 0.5357142857142857, 0.0]\n",
      "individual recall\n",
      "[0.15023474178403756, 0.34808510638297874, 0.3516042780748663, 0.2977867203219316, 0.21428571428571427, 0.0]\n",
      "DP all\n",
      "0.04390139739362537\n",
      "precision all 0.6743119266055045\n",
      "recall all 0.3177233429394813\n",
      "accuracy all 0.9061260823824553\n",
      "TP,FP,TN,FN\n",
      "441 213 10756 947\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "421781.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 3\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.0846286701208981, 0.05136695534046527, 0.05067478168827732, 0.06292266980299911, 0.04072727272727273, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.6530612244897959, 0.6760330578512397, 0.6866840731070496, 0.6915887850467289, 0.5357142857142857, 0.0]\n",
      "individual recall\n",
      "[0.15023474178403756, 0.34808510638297874, 0.3516042780748663, 0.2977867203219316, 0.21428571428571427, 0.0]\n",
      "DP all\n",
      "0.04390139739362537\n",
      "precision all 0.6743119266055045\n",
      "recall all 0.3177233429394813\n",
      "accuracy all 0.9061260823824553\n",
      "TP,FP,TN,FN\n",
      "441 213 10756 947\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "240623.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 4\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.07426597582037997, 0.05136695534046527, 0.0498809208785393, 0.06292266980299911, 0.04072727272727273, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7209302325581395, 0.6462809917355372, 0.6816976127320955, 0.6962616822429907, 0.2857142857142857, 0.0]\n",
      "individual recall\n",
      "[0.14553990610328638, 0.33276595744680854, 0.34358288770053474, 0.29979879275653926, 0.11428571428571428, 0.0]\n",
      "DP all\n",
      "0.03353870309310724\n",
      "precision all 0.6512345679012346\n",
      "recall all 0.30403458213256485\n",
      "accuracy all 0.9035364570688679\n",
      "TP,FP,TN,FN\n",
      "422 226 10743 966\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "209172.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 5\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.0846286701208981, 0.05136695534046527, 0.04961630060862662, 0.06292266980299911, 0.04654545454545454, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7755102040816326, 0.6231404958677685, 0.68, 0.705607476635514, 0.140625, 0.0]\n",
      "individual recall\n",
      "[0.1784037558685446, 0.32085106382978723, 0.3409090909090909, 0.3038229376257545, 0.06428571428571428, 0.0]\n",
      "DP all\n",
      "0.041150409251332884\n",
      "precision all 0.6345565749235474\n",
      "recall all 0.2989913544668588\n",
      "accuracy all 0.9019179412478757\n",
      "TP,FP,TN,FN\n",
      "415 239 10730 973\n",
      "dimension of data\n",
      "6 12357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal\n",
      "objective is:\n",
      "205289.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 6\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.0846286701208981, 0.05136695534046527, 0.04961630060862662, 0.06292266980299911, 0.04654545454545454, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7755102040816326, 0.6231404958677685, 0.6773333333333333, 0.7102803738317757, 0.140625, 0.0]\n",
      "individual recall\n",
      "[0.1784037558685446, 0.32085106382978723, 0.339572192513369, 0.3058350100603622, 0.06428571428571428, 0.0]\n",
      "DP all\n",
      "0.041150409251332884\n",
      "precision all 0.6345565749235474\n",
      "recall all 0.2989913544668588\n",
      "accuracy all 0.9019179412478757\n",
      "TP,FP,TN,FN\n",
      "415 239 10730 973\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "307129.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 7\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.0846286701208981, 0.05136695534046527, 0.05067478168827732, 0.06292266980299911, 0.04072727272727273, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.6938775510204082, 0.6743801652892562, 0.6866840731070496, 0.6915887850467289, 0.5535714285714286, 0.0]\n",
      "individual recall\n",
      "[0.1596244131455399, 0.3472340425531915, 0.3516042780748663, 0.2977867203219316, 0.22142857142857142, 0.0]\n",
      "DP all\n",
      "0.04390139739362537\n",
      "precision all 0.6758409785932722\n",
      "recall all 0.3184438040345821\n",
      "accuracy all 0.9062879339645545\n",
      "TP,FP,TN,FN\n",
      "442 212 10757 946\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "295187.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 8\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.0846286701208981, 0.05136695534046527, 0.05067478168827732, 0.06292266980299911, 0.04072727272727273, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.6938775510204082, 0.6743801652892562, 0.6866840731070496, 0.6915887850467289, 0.5535714285714286, 0.0]\n",
      "individual recall\n",
      "[0.1596244131455399, 0.3472340425531915, 0.3516042780748663, 0.2977867203219316, 0.22142857142857142, 0.0]\n",
      "DP all\n",
      "0.04390139739362537\n",
      "precision all 0.6758409785932722\n",
      "recall all 0.3184438040345821\n",
      "accuracy all 0.9062879339645545\n",
      "TP,FP,TN,FN\n",
      "442 212 10757 946\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "294051.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 9\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.0846286701208981, 0.05136695534046527, 0.05067478168827732, 0.06292266980299911, 0.04072727272727273, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.6938775510204082, 0.6743801652892562, 0.6866840731070496, 0.6915887850467289, 0.5535714285714286, 0.0]\n",
      "individual recall\n",
      "[0.1596244131455399, 0.3472340425531915, 0.3516042780748663, 0.2977867203219316, 0.22142857142857142, 0.0]\n",
      "DP all\n",
      "0.04390139739362537\n",
      "precision all 0.6758409785932722\n",
      "recall all 0.3184438040345821\n",
      "accuracy all 0.9062879339645545\n",
      "TP,FP,TN,FN\n",
      "442 212 10757 946\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "338693.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 10\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.0846286701208981, 0.05136695534046527, 0.04961630060862662, 0.065274919141429, 0.04072727272727273, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.6326530612244898, 0.6628099173553719, 0.6826666666666666, 0.6576576576576577, 0.5357142857142857, 0.0]\n",
      "individual recall\n",
      "[0.14553990610328638, 0.34127659574468083, 0.3422459893048128, 0.2937625754527163, 0.21428571428571427, 0.0]\n",
      "DP all\n",
      "0.04390139739362537\n",
      "precision all 0.6605504587155964\n",
      "recall all 0.3112391930835735\n",
      "accuracy all 0.9046694181435624\n",
      "TP,FP,TN,FN\n",
      "432 222 10747 956\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "329423.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 11\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.0846286701208981, 0.05136695534046527, 0.04961630060862662, 0.065274919141429, 0.04072727272727273, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.6326530612244898, 0.6628099173553719, 0.6826666666666666, 0.6576576576576577, 0.5357142857142857, 0.0]\n",
      "individual recall\n",
      "[0.14553990610328638, 0.34127659574468083, 0.3422459893048128, 0.2937625754527163, 0.21428571428571427, 0.0]\n",
      "DP all\n",
      "0.04390139739362537\n",
      "precision all 0.6605504587155964\n",
      "recall all 0.3112391930835735\n",
      "accuracy all 0.9046694181435624\n",
      "TP,FP,TN,FN\n",
      "432 222 10747 956\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "328502.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 12\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.0846286701208981, 0.05136695534046527, 0.04961630060862662, 0.065274919141429, 0.04072727272727273, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.6326530612244898, 0.6628099173553719, 0.6826666666666666, 0.6576576576576577, 0.5357142857142857, 0.0]\n",
      "individual recall\n",
      "[0.14553990610328638, 0.34127659574468083, 0.3422459893048128, 0.2937625754527163, 0.21428571428571427, 0.0]\n",
      "DP all\n",
      "0.04390139739362537\n",
      "precision all 0.6605504587155964\n",
      "recall all 0.3112391930835735\n",
      "accuracy all 0.9046694181435624\n",
      "TP,FP,TN,FN\n",
      "432 222 10747 956\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "389103.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 13\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.08117443868739206, 0.05136695534046527, 0.04961630060862662, 0.06292266980299911, 0.04509090909090909, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7446808510638298, 0.684297520661157, 0.6826666666666666, 0.7009345794392523, 0.6935483870967742, 0.0]\n",
      "individual recall\n",
      "[0.1643192488262911, 0.3523404255319149, 0.3422459893048128, 0.30181086519114686, 0.30714285714285716, 0.0]\n",
      "DP all\n",
      "0.037696177817826845\n",
      "precision all 0.6886503067484663\n",
      "recall all 0.3234870317002882\n",
      "accuracy all 0.9075827466213482\n",
      "TP,FP,TN,FN\n",
      "449 203 10766 939\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "376195.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 14\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.0846286701208981, 0.05136695534046527, 0.04961630060862662, 0.06292266980299911, 0.04654545454545454, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7551020408163265, 0.6859504132231405, 0.6826666666666666, 0.7009345794392523, 0.71875, 0.0]\n",
      "individual recall\n",
      "[0.17370892018779344, 0.35319148936170214, 0.3422459893048128, 0.30181086519114686, 0.32857142857142857, 0.0]\n",
      "DP all\n",
      "0.041150409251332884\n",
      "precision all 0.691131498470948\n",
      "recall all 0.3256484149855908\n",
      "accuracy all 0.9079064497855467\n",
      "TP,FP,TN,FN\n",
      "452 202 10767 936\n",
      "dimension of data\n",
      "6 12357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal\n",
      "objective is:\n",
      "374706.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 15\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.0846286701208981, 0.05136695534046527, 0.04961630060862662, 0.06292266980299911, 0.04654545454545454, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7551020408163265, 0.6859504132231405, 0.6826666666666666, 0.7009345794392523, 0.71875, 0.0]\n",
      "individual recall\n",
      "[0.17370892018779344, 0.35319148936170214, 0.3422459893048128, 0.30181086519114686, 0.32857142857142857, 0.0]\n",
      "DP all\n",
      "0.041150409251332884\n",
      "precision all 0.691131498470948\n",
      "recall all 0.3256484149855908\n",
      "accuracy all 0.9079064497855467\n",
      "TP,FP,TN,FN\n",
      "452 202 10767 936\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "425798.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 16\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.08290155440414508, 0.05136695534046527, 0.050410161418364643, 0.06292266980299911, 0.04072727272727273, 0.08695652173913043]\n",
      "individul precision\n",
      "[0.6875, 0.6760330578512397, 0.6902887139107612, 0.6915887850467289, 0.5535714285714286, 0.0]\n",
      "individual recall\n",
      "[0.15492957746478872, 0.34808510638297874, 0.3516042780748663, 0.2977867203219316, 0.22142857142857142, 0.0]\n",
      "DP all\n",
      "0.0462292490118577\n",
      "precision all 0.6768759571209801\n",
      "recall all 0.3184438040345821\n",
      "accuracy all 0.9063688597556041\n",
      "TP,FP,TN,FN\n",
      "442 211 10758 946\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "425649.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 17\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.08290155440414508, 0.05136695534046527, 0.05027785128340831, 0.06292266980299911, 0.04072727272727273, 0.13043478260869565]\n",
      "individul precision\n",
      "[0.6875, 0.6743801652892562, 0.6894736842105263, 0.6915887850467289, 0.5535714285714286, 0.0]\n",
      "individual recall\n",
      "[0.15492957746478872, 0.3472340425531915, 0.3502673796791444, 0.2977867203219316, 0.22142857142857142, 0.0]\n",
      "DP all\n",
      "0.08970750988142293\n",
      "precision all 0.6753445635528331\n",
      "recall all 0.3177233429394813\n",
      "accuracy all 0.9062070081735049\n",
      "TP,FP,TN,FN\n",
      "441 212 10757 947\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "425621.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 18\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.0846286701208981, 0.05136695534046527, 0.050410161418364643, 0.06292266980299911, 0.04072727272727273, 0.13043478260869565]\n",
      "individul precision\n",
      "[0.6938775510204082, 0.6743801652892562, 0.6902887139107612, 0.6915887850467289, 0.5535714285714286, 0.0]\n",
      "individual recall\n",
      "[0.1596244131455399, 0.3472340425531915, 0.3516042780748663, 0.2977867203219316, 0.22142857142857142, 0.0]\n",
      "DP all\n",
      "0.08970750988142293\n",
      "precision all 0.6758409785932722\n",
      "recall all 0.3184438040345821\n",
      "accuracy all 0.9062879339645545\n",
      "TP,FP,TN,FN\n",
      "442 212 10757 946\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "238883.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 19\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.0846286701208981, 0.05136695534046527, 0.05067478168827732, 0.06292266980299911, 0.04072727272727273, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7959183673469388, 0.6528925619834711, 0.6892950391644909, 0.7102803738317757, 0.32142857142857145, 0.0]\n",
      "individual recall\n",
      "[0.18309859154929578, 0.33617021276595743, 0.35294117647058826, 0.3058350100603622, 0.12857142857142856, 0.0]\n",
      "DP all\n",
      "0.04390139739362537\n",
      "precision all 0.6636085626911316\n",
      "recall all 0.3126801152737752\n",
      "accuracy all 0.9049931213077608\n",
      "TP,FP,TN,FN\n",
      "434 220 10749 954\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "206935.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 20\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.0846286701208981, 0.05136695534046527, 0.04961630060862662, 0.06292266980299911, 0.04654545454545454, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7755102040816326, 0.631404958677686, 0.6826666666666666, 0.7242990654205608, 0.140625, 0.0]\n",
      "individual recall\n",
      "[0.1784037558685446, 0.3251063829787234, 0.3422459893048128, 0.3118712273641851, 0.06428571428571428, 0.0]\n",
      "DP all\n",
      "0.041150409251332884\n",
      "precision all 0.6422018348623854\n",
      "recall all 0.3025936599423631\n",
      "accuracy all 0.9027271991583717\n",
      "TP,FP,TN,FN\n",
      "420 234 10735 968\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "203033.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 21\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.0846286701208981, 0.05136695534046527, 0.04961630060862662, 0.06292266980299911, 0.04654545454545454, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7755102040816326, 0.631404958677686, 0.6826666666666666, 0.7242990654205608, 0.140625, 0.0]\n",
      "individual recall\n",
      "[0.1784037558685446, 0.3251063829787234, 0.3422459893048128, 0.3118712273641851, 0.06428571428571428, 0.0]\n",
      "DP all\n",
      "0.041150409251332884\n",
      "precision all 0.6422018348623854\n",
      "recall all 0.3025936599423631\n",
      "accuracy all 0.9027271991583717\n",
      "TP,FP,TN,FN\n",
      "420 234 10735 968\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "206924.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 22\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.0846286701208981, 0.05136695534046527, 0.04961630060862662, 0.06292266980299911, 0.04654545454545454, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.7755102040816326, 0.631404958677686, 0.6826666666666666, 0.7242990654205608, 0.140625, 0.0]\n",
      "individual recall\n",
      "[0.1784037558685446, 0.3251063829787234, 0.3422459893048128, 0.3118712273641851, 0.06428571428571428, 0.0]\n",
      "DP all\n",
      "0.041150409251332884\n",
      "precision all 0.6422018348623854\n",
      "recall all 0.3025936599423631\n",
      "accuracy all 0.9027271991583717\n",
      "TP,FP,TN,FN\n",
      "420 234 10735 968\n",
      "dimension of data\n",
      "6 12357\n",
      "Optimal\n",
      "objective is:\n",
      "238550.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 23\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.08290155440414508, 0.05136695534046527, 0.050542471553320985, 0.06292266980299911, 0.04072727272727273, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.8125, 0.6528925619834711, 0.6884816753926701, 0.7149532710280374, 0.32142857142857145, 0.0]\n",
      "individual recall\n",
      "[0.18309859154929578, 0.33617021276595743, 0.3516042780748663, 0.30784708249496984, 0.12857142857142856, 0.0]\n",
      "DP all\n",
      "0.04217428167687235\n",
      "precision all 0.664624808575804\n",
      "recall all 0.3126801152737752\n",
      "accuracy all 0.9050740470988103\n",
      "TP,FP,TN,FN\n",
      "434 219 10750 954\n",
      "dimension of data\n",
      "6 12357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal\n",
      "objective is:\n",
      "238570.0\n",
      "discripency is:\n",
      "None\n",
      "gamma-epsilon-delta [0.074266  0.051367  0.0497486 0.0629227 0.0407273 0.0869565] 0.01\n",
      "<--------------------------------------->\n",
      "iteration t 24\n",
      "sensitive attribute  1\n",
      "sensitive attribute  2\n",
      "sensitive attribute  3\n",
      "sensitive attribute  4\n",
      "sensitive attribute  5\n",
      "sensitive attribute  6\n",
      "individual acceptance rates\n",
      "[0.08290155440414508, 0.05136695534046527, 0.050542471553320985, 0.06292266980299911, 0.04072727272727273, 0.043478260869565216]\n",
      "individul precision\n",
      "[0.8125, 0.6528925619834711, 0.6884816753926701, 0.7149532710280374, 0.32142857142857145, 0.0]\n",
      "individual recall\n",
      "[0.18309859154929578, 0.33617021276595743, 0.3516042780748663, 0.30784708249496984, 0.12857142857142856, 0.0]\n",
      "DP all\n",
      "0.04217428167687235\n",
      "precision all 0.664624808575804\n",
      "recall all 0.3126801152737752\n",
      "accuracy all 0.9050740470988103\n",
      "TP,FP,TN,FN\n",
      "434 219 10750 954\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-1899abde17c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#agarwal basic2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maccu_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDP_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macceptance_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-46f15f0c521c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(datax, y_test, y_test_pred, e)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0meps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mu1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_max_lp_all_ng5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m             \u001b[0;31m#######################Disp_impact#######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gamma-epsilon-delta\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#agarwal basic2\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
