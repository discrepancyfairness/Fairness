{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "from time import time\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Import the three supervised learning models from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA    \n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['choice', 'random', 'triangular', 'multivariate_normal', 'time', 'randint', 'uniform', 'e', 'sample', 'shuffle', 'seed']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "from random import *\n",
    "from subprocess import check_output\n",
    "def synthetic_svm(X,Y):\n",
    "    #Split data into training and test datasets (training will be based on 70% of data)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0,shuffle=True) \n",
    "    #test_size: if integer, number of examples into test dataset; if between 0.0 and 1.0, means proportion\n",
    "    print('There are {} samples in the training set and {} samples in the test set'.format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "    \n",
    "    #Scaling data\n",
    "    #from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    #sc = StandardScaler(with_mean=False)\n",
    "    \n",
    "    \n",
    "    #sc.fit(X_train)\n",
    "    #X_train_std = sc.transform(X_train)\n",
    "    #X_test_std = sc.transform(X_test)\n",
    "\n",
    "    #X_train_std and X_test_std are the scaled datasets to be used in algorithms\n",
    "    #.1,.10\n",
    "    #Applying SVC (Support Vector Classification)\n",
    "    from sklearn.svm import SVC\n",
    "    svm = SVC(kernel='rbf', random_state=0, gamma=.1, C=10.0,probability=True)\n",
    "    \n",
    "    print(Y_train.dtypes)\n",
    "    Y_train=Y_train.astype('int')\n",
    "    print(Y_train.dtypes)\n",
    "    \n",
    "    print(Y_test.dtypes)\n",
    "    Y_test=Y_test.astype('int')\n",
    "    print(Y_test.dtypes)\n",
    "    \n",
    "    \n",
    "    svm.fit(X_train, Y_train)\n",
    "    print('The accuracy of the SVM classifier on training data is {:.2f}'.format(svm.score(X_train, Y_train)))\n",
    "    print('The accuracy of the SVM classifier on test data is {:.2f}'.format(svm.score(X_test, Y_test)))\n",
    "    print('####Train prediction Label###############################################')\n",
    "    Y_train_pred=svm.predict(X_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(y_1)\n",
    "    Y_test_pred=svm.predict(X_test)\n",
    "    d=svm.decision_function(X_test)\n",
    "    e=svm.predict_proba(X_test)\n",
    "    print(e)\n",
    "    print(d)\n",
    "    \n",
    "    \n",
    "           \n",
    "\n",
    "        \n",
    "    \n",
    "    return X_test,Y_test,Y_test_pred,e \n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without accuracy ---> 2\n",
    "def main(datax, y_test, y_test_pred): \n",
    "        \n",
    "    n=datax.shape[1]\n",
    "    s=datax.shape[0]    \n",
    "    data = np.zeros((s, n), dtype = int)\n",
    "    \n",
    "    r = np.zeros(n, dtype = int) \n",
    "    \n",
    "    for i in range(n):\n",
    "        if int(y_test.iloc[i])==1 :\n",
    "            r[i]=1\n",
    "        else :\n",
    "            r[i]= -1  \n",
    "    \n",
    "    r2 = np.zeros(n, dtype = int) \n",
    "    for i in range(n):\n",
    "        if int(y_test_pred[i])==1 :\n",
    "            r2[i]=1\n",
    "        else :\n",
    "            r2[i]= -1          \n",
    "    ar=[]\n",
    "    \n",
    "    for j in range(s):\n",
    "        print(\"sensitive attribute \",(j+1)) \n",
    "        a=0\n",
    "        b=0\n",
    "        acc1=0\n",
    "        acc2=0\n",
    "        for i in range(n):\n",
    "                data[j][i]= datax.iloc[j,i]\n",
    "                if data[j][i]== 1 :\n",
    "                    a=a+1\n",
    "                    if r[i]==1:\n",
    "                         acc1=acc1+1 \n",
    "\n",
    "        print(\"ACTUAL----------total ,accepted, aceeptance rate:\")             \n",
    "        a1=float(acc1/a)\n",
    "        print(a)\n",
    "        \n",
    "        print(acc1)\n",
    "        print(a1)\n",
    "        ar.append(a1)\n",
    "        \n",
    "    maxi= max(ar)\n",
    "    mini= min(ar)\n",
    "    DP=float(maxi-mini)\n",
    "    print(\"data acceptance rates\")\n",
    "    print(ar)\n",
    "    print(\"data DP\")\n",
    "    print(DP)\n",
    "    \n",
    "    ar=[]\n",
    "    \n",
    "    for j in range(s):\n",
    "        print(\"sensitive attribute \",(j+1)) \n",
    "        a=0\n",
    "        b=0\n",
    "        acc1=0\n",
    "        acc2=0\n",
    "        prec=0\n",
    "        reca=0\n",
    "        accur=0\n",
    "        FP=0\n",
    "        FN=0\n",
    "        TP=0\n",
    "        TN=0\n",
    "        for i in range(n):\n",
    "             if data[j][i]== 1 :\n",
    "                    a=a+1\n",
    "                    if r2[i]==1:\n",
    "                        acc1=acc1+1 \n",
    "                        if r[i]==1:\n",
    "                            TP=TP+1\n",
    "                        else:\n",
    "                             FP=FP+1                \n",
    "                    else:\n",
    "                        if r[i]==1:\n",
    "                            FN=FN+1\n",
    "                        else:\n",
    "                            TN=TN+1    \n",
    "        \n",
    "        print(\"prec reca accuracy for each sens\") \n",
    "        prec= float(TP/(TP+FP))\n",
    "        reca= float(TP/(TP+FN))\n",
    "        accur= float((TP+TN)/a)\n",
    "        print(prec,reca,accur)\n",
    "        \n",
    "        print(\"SVM----------total , accepted, aceeptance rate:\")             \n",
    "        \n",
    "        a1=float(acc1/a)\n",
    "        print(a)\n",
    "        \n",
    "        print(acc1)\n",
    "        print(a1)\n",
    "        ar.append(a1)\n",
    "        \n",
    "    maxi= max(ar)\n",
    "    mini= min(ar)\n",
    "    DP=float(maxi-mini)\n",
    "    print(\"data acceptance rates\")\n",
    "    print(ar)\n",
    "    print(\"data DP\")\n",
    "    print(DP) \n",
    "    \n",
    "    print(\"SVM accuracy--------------------------\")\n",
    "    prec=0\n",
    "    reca=0\n",
    "    accur=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    TP=0\n",
    "    TN=0\n",
    "    for i in range(n):\n",
    "            if r2[i]==1:\n",
    "                acc1=acc1+1 \n",
    "                if r[i]==1:\n",
    "                    TP=TP+1\n",
    "                else:\n",
    "                     FP=FP+1                \n",
    "            else:\n",
    "                if r[i]==1:\n",
    "                     FN=FN+1\n",
    "                else:\n",
    "                     TN=TN+1    \n",
    "\n",
    "        \n",
    "    prec= float(TP/(TP+FP))\n",
    "    reca= float(TP/(TP+FN))\n",
    "    accur= float((TP+TN)/n)\n",
    "    print(prec,reca,accur)\n",
    "    print(\"precision recall accuracy\")\n",
    "    \n",
    "#     delta1=[.70,.75,.80,.85,.90,.95]\n",
    "    #gamma=.05,.06,.07\n",
    "    #delta1=[.80,.85,.90,.95]\n",
    "# (for reproducibility)  \n",
    "\n",
    "# delta1=[.8], gama=[.1], epsilon=[.05]  \n",
    "# delta1=[.8], gama=[.15], epsilon=[.01]\n",
    " \n",
    "#     delta1=np.arange(1,.79,-.01)\n",
    "\n",
    "    delta=1\n",
    "#     gama=[.1572]\n",
    "#     epsilon=[.0090]\n",
    "    epsilon=[.02,.04,.10,.15,.20,.30,.40,.50,.60]\n",
    "    gama=[.35]\n",
    "    \n",
    "#     epsilon=[.02,.04,.10,.15,.20,.30,.40,.50,.60]\n",
    "#     gama=[.30,.40,.50,.60,.70]\n",
    "#     epsilon=[.0090]\n",
    "    fi= np.zeros(n,dtype=int) \n",
    "#     for delta in delta1:\n",
    "    for gamma in gama:\n",
    "        for eps in epsilon:\n",
    "            u1,u2=min_max_lp_all_ng2(data,gamma,eps,r2,delta)\n",
    "            #######################Disp_impact#######################  \n",
    "            print(\"gamma-epsilon-delta\",gamma,eps,delta)\n",
    "            accu_all=[]\n",
    "            DP_all=[]\n",
    "            precision_all=[]\n",
    "            recall_all=[]\n",
    "            acceptance_rate=np.zeros((7,28),dtype=float)\n",
    "            count=0\n",
    "#                 for alpha in np.arange(0,1.05,0.05):\n",
    "#                     print(\"alpha: \",alpha)\n",
    "#                     for i in range(n):\n",
    "\n",
    "#                         z=random()\n",
    "#                         if z < alpha:\n",
    "#                                fi[i]= u1[i] \n",
    "\n",
    "#                         else:\n",
    "#                                fi[i]= r2[i]\n",
    "\n",
    "            for i in range(n):\n",
    "                 fi[i] = u1[i]\n",
    "            ar=[]\n",
    "\n",
    "            print(\"################################\")\n",
    "            \n",
    "            for j in range(s):\n",
    "                print(\"sensitive attribute \",(j+1)) \n",
    "                a=0\n",
    "                b=0\n",
    "                acc1=0\n",
    "                acc2=0\n",
    "                prec=0\n",
    "                reca=0\n",
    "                accur=0\n",
    "                FP=0\n",
    "                FN=0\n",
    "                TP=0\n",
    "                TN=0\n",
    "                for i in range(n):\n",
    "                     if data[j][i]== 1 :\n",
    "                            a=a+1\n",
    "                            if fi[i]==1:\n",
    "                                acc1=acc1+1 \n",
    "                                if r[i]==1:\n",
    "                                    TP=TP+1\n",
    "                                else:\n",
    "                                     FP=FP+1                \n",
    "                            else:\n",
    "                                if r[i]==1:\n",
    "                                    FN=FN+1\n",
    "                                else:\n",
    "                                    TN=TN+1    \n",
    "\n",
    "                print(\"lp ############### prec reca accuracy for each sens\") \n",
    "                prec= float(TP/(TP+FP))\n",
    "                reca= float(TP/(TP+FN))\n",
    "                accur= float((TP+TN)/a)\n",
    "                print(prec,reca,accur)\n",
    "\n",
    "                print(\"By lp---------total , accepted, aceeptance rate:\")             \n",
    "\n",
    "                a1=float(acc1/a)\n",
    "                print(a,acc1,a1)\n",
    "                ar.append(a1)\n",
    "\n",
    "\n",
    "            maxi= max(ar)\n",
    "            mini= min(ar)\n",
    "            DP=float(maxi-mini)\n",
    "            print(\"data acceptance rates\")\n",
    "            print(ar)\n",
    "            print(\"data DP\")\n",
    "            print(DP) \n",
    "            TP=0\n",
    "            FP=0\n",
    "            FN=0\n",
    "            TN=0\n",
    "            accurr=0\n",
    "            precision=0\n",
    "            recall=0\n",
    "            for i in range(n):\n",
    "                    if fi[i]==1 and r[i]==1:\n",
    "                        TP=TP+1\n",
    "                    if fi[i]==-1 and r[i]==-1:\n",
    "                        TN=TN+1     \n",
    "                    if fi[i]==1 and r[i]==-1:\n",
    "                        FP=FP+1 \n",
    "                    if fi[i]==-1 and r[i]==1:\n",
    "                        FN=FN+1\n",
    "            print(\"total accepted \")            \n",
    "            precision=float(TP/(TP+FP))\n",
    "            print(\"finalprecision\",precision)\n",
    "            recall=float(TP/(TP+FN))\n",
    "            print(\"finalrecall\",recall)\n",
    "            accurr=float((TP+TN)/(TP+TN+FP+FN))\n",
    "            print(\"finalaccuracy\",accurr)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "      \n",
    "    alpha_weight=np.arange(0,1.05,.05)        \n",
    "    return accu_all,DP_all,acceptance_rate,alpha_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NG\n",
    "import time\n",
    "import pulp as p \n",
    "def min_max_lp_all_ng2(data1,gamma,eps,r,delta):\n",
    "    import pulp as p \n",
    "    \n",
    "    m=data1.shape[0]\n",
    "    n=data1.shape[1]\n",
    "    print('dimension of data')\n",
    "    print(m,n)\n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMaximize)  \n",
    "   \n",
    "    \n",
    "#     X=np.zeros(n+1,dtype=p.LpVariable)\n",
    "    X=np.zeros(n+1,dtype=p.LpVariable)\n",
    "    sizes=np.zeros(m,dtype=int)\n",
    "    for i in range(m):\n",
    "        count=0\n",
    "        for j in range(n):\n",
    "            if data1[i][j]==1:\n",
    "                count=count+1               \n",
    "        sizes[i]=count\n",
    "  \n",
    "\n",
    "    for i in range(n):\n",
    "        var1=str(i)       \n",
    "        X[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Integer')\n",
    "    \n",
    "    X[n]=p.LpVariable(str(n),lowBound=0,upBound=1,cat='Continuous')   \n",
    "        \n",
    "#     X[n]=  p.LpVariable(\"z1\",lowBound=0)\n",
    "    #X[n+1]=  p.LpVariable(\"z2\",lowBound=0)\n",
    "\n",
    "\n",
    "    #########objective function#####################\n",
    "#     Lp_prob += X[n] \n",
    "            \n",
    "    Lp_prob += X[n]\n",
    "\n",
    "\n",
    "    ##############constraint#################\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "#             Lp_prob += X[n] >= p.lpSum([2*(X[j]-0.5)*data1[i][j] for j in range(n)])\n",
    "            Lp_prob += p.lpSum([2*(X[j]-0.5)*data1[i][j] for j in range(n)]) >= (2*gamma-1)*sizes[i]\n",
    "            Lp_prob += p.lpSum([2*(X[j]-0.5)*data1[i][j] for j in range(n)]) <= ((2*gamma-1)+eps)*sizes[i]\n",
    "            \n",
    "#         else:        \n",
    "#             Lp_prob += X[n] >= p.lpSum([-1*2*(X[j]-0.5)*data1[i-m][j] for j in range(n)])\n",
    "            #Lp_prob += X[n+1] >= p.lpSum([-1*2*(X[j]-0.5)+r[j] for j in range(n)]) \n",
    "#     Lp_prob += X[n+1] >= p.lpSum([2*(X[j]-0.5)-r[j] for j in range(n)])\n",
    "#     Lp_prob += X[n+1] >= p.lpSum([-1*2*(X[j]-0.5)+r[j] for j in range(n)])       \n",
    "         \n",
    "    Lp_prob += p.lpSum([2*(X[i]-0.5)*r[i] for i in range(n)]) >= X[n]*n\n",
    "    #n is the number of elements in sensitive attribute \n",
    "                 \n",
    "#     Lp_prob += X[n] <= 42000\n",
    "    \n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status]) \n",
    "    print(\"discripency is:\")        \n",
    "    print(p.value(Lp_prob.objective))\n",
    "    \n",
    "    x=np.zeros(n,dtype=float)\n",
    "\n",
    "   # The solution status \n",
    "    Synth1={}\n",
    "    Synth2={}\n",
    "    # # Printing the final solution \n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])==1):\n",
    "            Synth1[i]=1 \n",
    "            Synth2[i]=-1\n",
    "        else:\n",
    "            Synth1[i]=-1\n",
    "            Synth2[i]=1\n",
    "    Synthu1=Synth1  \n",
    "    Synthu2=Synth2  \n",
    "    \n",
    "              \n",
    "    return Synthu1,Synthu2   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table1 for Adult\n",
    "\n",
    "# import time\n",
    "# import pulp as p \n",
    "def min_max_lp_all(data1,gamma,eps,r):\n",
    "    import time\n",
    "    import pulp as p \n",
    "    m=data1.shape[0]\n",
    "    n=data1.shape[1]\n",
    "    print('dimension of data')\n",
    "    print(m,n)\n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "   \n",
    "    \n",
    "    X=np.zeros(n+1,dtype=p.LpVariable)\n",
    "    sizes=np.zeros(m,dtype=int)\n",
    "    for i in range(m):\n",
    "        count=0\n",
    "        for j in range(n):\n",
    "            if data1[i][j]==1:\n",
    "                count=count+1\n",
    "                \n",
    "        sizes[i]=count\n",
    "  \n",
    "\n",
    "    for i in range(n):\n",
    "        var1=str(i)\n",
    "        \n",
    "        X[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Integer')\n",
    "       \n",
    "        \n",
    "    X[n] =  p.LpVariable(\"z1\",lowBound=0)\n",
    "\n",
    "\n",
    "    #########objective function#####################\n",
    "    Lp_prob += X[n]\n",
    "\n",
    "\n",
    "    ##############constraint#################\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "            Lp_prob += X[n] >= p.lpSum([2*(X[j]-0.5)*data1[i][j] for j in range(n)])\n",
    "            Lp_prob += p.lpSum([2*(X[j]-0.5)*data1[i][j] for j in range(n)]) >= (2*gamma-1)*sizes[i]\n",
    "            Lp_prob += p.lpSum([2*(X[j]-0.5)*data1[i][j] for j in range(n)]) <= ((2*gamma-1)+eps)*sizes[i]\n",
    "            \n",
    "        else:        \n",
    "            Lp_prob += X[n] >= p.lpSum([-1*2*(X[j]-0.5)*data1[i-m][j] for j in range(n)])\n",
    "            \n",
    "         \n",
    " \n",
    "   \n",
    "    \n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status]) \n",
    "    print(\"discripency is:\")        \n",
    "    print(p.value(Lp_prob.objective))\n",
    "    x=np.zeros(n,dtype=float)\n",
    "\n",
    "   # The solution status \n",
    "    Synth1={}\n",
    "    Synth2={}\n",
    "    # # Printing the final solution \n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])==1):\n",
    "            Synth1[i]=1 \n",
    "            Synth2[i]=-1\n",
    "        else:\n",
    "            Synth1[i]=-1\n",
    "            Synth2[i]=1\n",
    "    Synthu1=Synth1  \n",
    "    Synthu2=Synth2  \n",
    "    \n",
    "              \n",
    "    return Synthu1,Synthu2   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            x1        x2        x3        x4        x5        x6        x7  \\\n",
      "0     1.392243  1.679704  1.340495  1.169002 -0.169651  1.388412  1.295138   \n",
      "1     0.281930  0.707585  2.675535 -0.119078 -2.308004  1.925658  1.426423   \n",
      "2     0.627546 -1.091224 -1.030816 -2.612045 -0.022696  0.068534 -0.092952   \n",
      "3     1.539515  1.139298  0.632225  0.576092  1.016257  0.141090 -1.288185   \n",
      "4     3.593012  2.077929  2.319466 -1.762514 -3.055532  4.126875  3.522920   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "7995 -2.126879 -3.555727  0.071769 -0.986176  2.558081  2.983460  0.846630   \n",
      "7996  2.754907 -1.817496  4.405390 -1.870844  2.225684  0.876259 -2.341649   \n",
      "7997  0.177864 -1.524149  2.712979  0.013804 -0.611786 -0.381373  1.269916   \n",
      "7998  2.455750  0.216205  4.581337 -3.531081 -1.558274  0.338572 -0.721618   \n",
      "7999  3.218231  1.572063  0.092973 -1.331167  1.232236 -0.501353  0.321379   \n",
      "\n",
      "            x8        x9       x10       x11       x12        x13        x14  \\\n",
      "0    -1.895428 -1.148357  1.614701 -1.049498  2.660067   0.037983  -4.219779   \n",
      "1    -1.184452  1.280644  1.888044 -0.990781  0.864279   6.091637  -8.104712   \n",
      "2    -4.457771 -2.416174  2.009805 -1.455803  1.670899   1.846383  -0.512428   \n",
      "3     2.764486 -0.035432  0.414372 -1.879933  1.767752  -1.977889   0.792234   \n",
      "4    -3.015858  4.153499  0.263969 -0.137930  2.148686   9.614354 -14.961108   \n",
      "...        ...       ...       ...       ...       ...        ...        ...   \n",
      "7995 -1.050211  0.588597  0.740106 -4.282749 -2.794996   3.025729   2.182613   \n",
      "7996  2.896888  1.644242  1.025150 -6.581075 -2.436871   6.117929  -3.159735   \n",
      "7997  1.446300  1.571569  1.309040 -3.710406 -0.375081   5.804239  -4.759974   \n",
      "7998  3.727277  4.616415 -1.762766 -2.002525 -2.463831  10.359781  -8.509465   \n",
      "7999  0.841131  0.745692  3.554162 -5.447069  6.053599   1.035093  -3.759005   \n",
      "\n",
      "           x15        x16        x17       x18       x19       x20  \n",
      "0    -1.514455  -0.292254  -0.073725  0.586313  3.424058 -0.627274  \n",
      "1     2.181631   3.892096  -2.103797  2.268848 -0.261387  2.047578  \n",
      "2    -1.256517  -4.991383  -3.077433 -1.348873  3.291993 -1.381279  \n",
      "3    -0.789747   0.843799   4.119767  0.438513 -0.414191  0.467554  \n",
      "4     8.028063  12.853176 -12.024976  6.678605 -0.840528  3.388474  \n",
      "...        ...        ...        ...       ...       ...       ...  \n",
      "7995  4.820896  -1.844148  -1.334843 -1.502188 -4.716004  5.190138  \n",
      "7996  4.422718   2.333759   5.759854  2.641768 -2.884294  7.506101  \n",
      "7997  2.171444   1.518408   2.995542  1.567182 -1.766561  4.972580  \n",
      "7998  7.235481  12.417189  -0.970669  8.152111 -5.739933  5.964156  \n",
      "7999 -1.677852  -1.063530   3.387187 -1.603658  0.248711  2.940528  \n",
      "\n",
      "[8000 rows x 20 columns]\n",
      "      y\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "...  ..\n",
      "7995  1\n",
      "7996  1\n",
      "7997  1\n",
      "7998  1\n",
      "7999  1\n",
      "\n",
      "[8000 rows x 1 columns]\n",
      "There are 5600 samples in the training set and 2400 samples in the test set\n",
      "y    int64\n",
      "dtype: object\n",
      "y    int64\n",
      "dtype: object\n",
      "y    int64\n",
      "dtype: object\n",
      "y    int64\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the SVM classifier on training data is 1.00\n",
      "The accuracy of the SVM classifier on test data is 0.96\n",
      "####Train prediction Label###############################################\n",
      "[[9.99872581e-01 1.27418803e-04]\n",
      " [9.98531918e-01 1.46808186e-03]\n",
      " [9.16411675e-07 9.99999084e-01]\n",
      " ...\n",
      " [3.63959211e-02 9.63604079e-01]\n",
      " [1.99659556e-02 9.80034044e-01]\n",
      " [9.99999900e-01 1.00000010e-07]]\n",
      "[-0.78036573 -0.5887034   0.51103164 ...  0.17968937  0.22813585\n",
      " -1.38292185]\n",
      "            x1        x2        x3        x4        x5        x6        x7  \\\n",
      "0     3.726016  1.413642  2.273420 -0.922466 -1.824458  1.962949  1.624339   \n",
      "1     2.688174 -1.027868 -1.682078 -1.840101  1.103014 -1.896824  0.124650   \n",
      "2     1.023729 -2.973104  0.426373  0.225930 -2.585958  0.902453  2.545473   \n",
      "3    -1.808053  1.236258  3.721401 -0.016646 -2.008842  0.492476  2.205975   \n",
      "4    -0.215031  0.124284  2.116305 -3.074894 -2.958696 -0.016511  2.452041   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2395  3.315519  0.862938  1.894183 -3.243664 -1.783574  0.940924  1.852839   \n",
      "2396  1.201637  0.780115  0.833288 -2.137964  1.745226 -0.618062 -0.108009   \n",
      "2397  2.498353 -0.012291  0.513396 -1.679410 -1.621630  0.898963  1.233787   \n",
      "2398  5.475439  2.043320  5.369473 -1.754758 -1.682912 -0.778325 -1.984432   \n",
      "2399  0.805834  0.938246  0.770220 -1.652054 -0.580682  0.038329  1.814350   \n",
      "\n",
      "            x8        x9       x10       x11        x12       x13       x14  \\\n",
      "0     0.490037  0.547875 -0.885342 -1.692963   3.168391  4.698117 -7.795435   \n",
      "1    -3.586503 -2.984660  0.327856 -1.335388   2.160897 -1.187367  1.151882   \n",
      "2     3.559631 -1.532219  1.689894 -7.023949   6.414109  4.844646 -2.448145   \n",
      "3     4.457250 -1.697281  2.870452 -6.327482   6.388491  4.590396 -3.818664   \n",
      "4     0.338043  0.124814  1.456617 -3.475118   3.996575  8.407927 -6.913455   \n",
      "...        ...       ...       ...       ...        ...       ...       ...   \n",
      "2395 -2.169884 -0.367307  0.728958 -2.818645   3.968014  6.930969 -8.504277   \n",
      "2396 -0.500619  2.754513  1.420149 -2.168208  -0.302743  2.942150 -3.360247   \n",
      "2397  1.805487 -2.192609  4.713881 -8.342469  10.009026  4.077224 -4.372858   \n",
      "2398  4.449797  0.828297  0.176962 -3.799636   2.542284  6.225360 -8.531017   \n",
      "2399  0.024413 -1.009131  1.479877 -3.514554   4.815701  2.772282 -3.309942   \n",
      "\n",
      "           x15       x16       x17       x18       x19       x20  \n",
      "0     4.017561  9.101517 -4.328087  8.033234  0.870161  0.404177  \n",
      "1    -2.383541 -5.407531 -1.744925 -0.462722  5.848033 -2.127948  \n",
      "2     3.284144  3.037343  1.079736  5.994343 -1.364255  1.522722  \n",
      "3    -2.816748  2.271956  8.413762  4.993741 -3.301473  0.878408  \n",
      "4     1.090160  4.530454 -1.103086  5.525074 -2.242880  1.229985  \n",
      "...        ...       ...       ...       ...       ...       ...  \n",
      "2395  2.225361  5.222216 -4.870262  6.321041  1.874691  0.440226  \n",
      "2396  0.578984  0.117923  0.975259 -2.284575 -2.098053  4.621331  \n",
      "2397 -0.882410  0.009383  2.961416  3.044971  0.356333  0.686769  \n",
      "2398  1.516578  8.493274  5.096081  8.542786  0.947459  2.223054  \n",
      "2399 -1.210632  1.043588  0.651040  2.721024 -0.021531  0.062070  \n",
      "\n",
      "[2400 rows x 20 columns]\n",
      "[0 0 1 ... 1 1 0]\n",
      "      y\n",
      "0     0\n",
      "1     0\n",
      "2     1\n",
      "3     0\n",
      "4     0\n",
      "...  ..\n",
      "2395  0\n",
      "2396  1\n",
      "2397  1\n",
      "2398  1\n",
      "2399  0\n",
      "\n",
      "[2400 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/home/subham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/subham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0     1     2     3     4     5     6     7     8     9     ...  2390  \\\n",
      "x1_0.0     0     0     0     1     1     0     0     0     0     0  ...     0   \n",
      "x1_1.0     1     1     1     0     0     1     1     1     1     1  ...     1   \n",
      "x2_0.0     0     1     1     0     0     1     1     1     0     1  ...     1   \n",
      "x2_1.0     1     0     0     1     1     0     0     0     1     0  ...     0   \n",
      "x3_0.0     0     1     0     0     0     0     0     1     0     0  ...     1   \n",
      "x3_1.0     1     0     1     1     1     1     1     0     1     1  ...     0   \n",
      "x4_0.0     1     1     0     1     1     1     0     1     1     1  ...     0   \n",
      "x4_1.0     0     0     1     0     0     0     1     0     0     0  ...     1   \n",
      "x5_0.0     1     0     1     1     1     1     1     0     1     0  ...     0   \n",
      "x5_1.0     0     1     0     0     0     0     0     1     0     1  ...     1   \n",
      "\n",
      "        2391  2392  2393  2394  2395  2396  2397  2398  2399  \n",
      "x1_0.0     0     0     1     0     0     0     0     0     0  \n",
      "x1_1.0     1     1     0     1     1     1     1     1     1  \n",
      "x2_0.0     1     1     1     1     0     0     1     0     0  \n",
      "x2_1.0     0     0     0     0     1     1     0     1     1  \n",
      "x3_0.0     0     0     1     0     0     0     0     0     0  \n",
      "x3_1.0     1     1     0     1     1     1     1     1     1  \n",
      "x4_0.0     1     0     1     1     1     1     1     1     1  \n",
      "x4_1.0     0     1     0     0     0     0     0     0     0  \n",
      "x5_0.0     1     0     0     0     1     0     1     1     1  \n",
      "x5_1.0     0     1     1     1     0     1     0     0     0  \n",
      "\n",
      "[10 rows x 2400 columns]\n",
      "sensitive attribute  1\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "698\n",
      "365\n",
      "0.5229226361031518\n",
      "sensitive attribute  2\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "1702\n",
      "838\n",
      "0.49236192714453586\n",
      "sensitive attribute  3\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "1203\n",
      "873\n",
      "0.7256857855361596\n",
      "sensitive attribute  4\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "1197\n",
      "330\n",
      "0.2756892230576441\n",
      "sensitive attribute  5\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "719\n",
      "328\n",
      "0.4561891515994437\n",
      "sensitive attribute  6\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "1681\n",
      "875\n",
      "0.520523497917906\n",
      "sensitive attribute  7\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "1715\n",
      "911\n",
      "0.5311953352769679\n",
      "sensitive attribute  8\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "685\n",
      "292\n",
      "0.42627737226277373\n",
      "sensitive attribute  9\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "1188\n",
      "359\n",
      "0.3021885521885522\n",
      "sensitive attribute  10\n",
      "ACTUAL----------total ,accepted, aceeptance rate:\n",
      "1212\n",
      "844\n",
      "0.6963696369636964\n",
      "data acceptance rates\n",
      "[0.5229226361031518, 0.49236192714453586, 0.7256857855361596, 0.2756892230576441, 0.4561891515994437, 0.520523497917906, 0.5311953352769679, 0.42627737226277373, 0.3021885521885522, 0.6963696369636964]\n",
      "data DP\n",
      "0.4499965624785155\n",
      "sensitive attribute  1\n",
      "prec reca accuracy for each sens\n",
      "0.9971014492753624 0.9424657534246575 0.9684813753581661\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "698\n",
      "345\n",
      "0.49426934097421205\n",
      "sensitive attribute  2\n",
      "prec reca accuracy for each sens\n",
      "0.9886506935687264 0.9355608591885441 0.9629847238542891\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "1702\n",
      "793\n",
      "0.46592244418331374\n",
      "sensitive attribute  3\n",
      "prec reca accuracy for each sens\n",
      "0.9964071856287425 0.9530355097365406 0.9634247714048213\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "1203\n",
      "835\n",
      "0.6940980881130507\n",
      "sensitive attribute  4\n",
      "prec reca accuracy for each sens\n",
      "0.976897689768977 0.896969696969697 0.9657477025898078\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "1197\n",
      "303\n",
      "0.2531328320802005\n",
      "sensitive attribute  5\n",
      "prec reca accuracy for each sens\n",
      "0.9967948717948718 0.948170731707317 0.9749652294853964\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "719\n",
      "312\n",
      "0.4339360222531293\n",
      "sensitive attribute  6\n",
      "prec reca accuracy for each sens\n",
      "0.9891041162227603 0.9337142857142857 0.9601427721594289\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "1681\n",
      "826\n",
      "0.4913741820345033\n",
      "sensitive attribute  7\n",
      "prec reca accuracy for each sens\n",
      "0.9908675799086758 0.9527991218441273 0.970262390670554\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "1715\n",
      "876\n",
      "0.5107871720116618\n",
      "sensitive attribute  8\n",
      "prec reca accuracy for each sens\n",
      "0.9923664122137404 0.8904109589041096 0.9503649635036496\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "685\n",
      "262\n",
      "0.38248175182481753\n",
      "sensitive attribute  9\n",
      "prec reca accuracy for each sens\n",
      "0.9783950617283951 0.883008356545961 0.9587542087542088\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "1188\n",
      "324\n",
      "0.2727272727272727\n",
      "sensitive attribute  10\n",
      "prec reca accuracy for each sens\n",
      "0.9963144963144963 0.9609004739336493 0.9702970297029703\n",
      "SVM----------total , accepted, aceeptance rate:\n",
      "1212\n",
      "814\n",
      "0.6716171617161716\n",
      "data acceptance rates\n",
      "[0.49426934097421205, 0.46592244418331374, 0.6940980881130507, 0.2531328320802005, 0.4339360222531293, 0.4913741820345033, 0.5107871720116618, 0.38248175182481753, 0.2727272727272727, 0.6716171617161716]\n",
      "data DP\n",
      "0.44096525603285025\n",
      "SVM accuracy--------------------------\n",
      "0.9912126537785588 0.9376558603491272 0.9645833333333333\n",
      "precision recall accuracy\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.56666667\n",
      "gamma-epsilon-delta 0.3 0.02 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9953703703703703 0.589041095890411 0.7836676217765043\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 216 0.30945558739255014\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8798449612403101 0.5417661097852029 0.7379553466509988\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 516 0.30317273795534666\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9946236559139785 0.4238258877434135 0.5802161263507897\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 372 0.3092269326683292\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8305555555555556 0.906060606060606 0.923141186299081\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 360 0.3007518796992481\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8709677419354839 0.5762195121951219 0.7677329624478443\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 217 0.30180806675938804\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9320388349514563 0.5485714285714286 0.7441998810232004\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 515 0.30636525877453896\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9486692015209125 0.5477497255762898 0.7440233236151603\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 526 0.30670553935860057\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8252427184466019 0.5821917808219178 0.7693430656934307\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 206 0.3007299270072993\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.845108695652174 0.8662952646239555 0.9116161616161617\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 368 0.30976430976430974\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9835164835164835 0.42417061611374407 0.594059405940594\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 364 0.30033003300330036\n",
      "data acceptance rates\n",
      "[0.30945558739255014, 0.30317273795534666, 0.3092269326683292, 0.3007518796992481, 0.30180806675938804, 0.30636525877453896, 0.30670553935860057, 0.3007299270072993, 0.30976430976430974, 0.30033003300330036]\n",
      "data DP\n",
      "0.009434276761009386\n",
      "total accepted \n",
      "finalprecision 0.9139344262295082\n",
      "finalrecall 0.5561097256857855\n",
      "finalaccuracy 0.75125\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.57666667\n",
      "gamma-epsilon-delta 0.3 0.04 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9596412556053812 0.5863013698630137 0.7707736389684814\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 223 0.3194842406876791\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8944337811900192 0.5560859188544153 0.7491186839012925\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 521 0.30611045828437133\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9947916666666666 0.43757159221076747 0.5901911886949294\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 384 0.3192019950124688\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8277777777777777 0.9030303030303031 0.9214703425229741\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 360 0.3007518796992481\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8425925925925926 0.5548780487804879 0.7496522948539638\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 216 0.3004172461752434\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9431818181818182 0.5691428571428572 0.7578822129684711\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 528 0.314098750743605\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9609665427509294 0.5675082327113062 0.7580174927113703\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 538 0.31370262390670556\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7912621359223301 0.5582191780821918 0.7489051094890511\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 206 0.3007299270072993\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8879551820728291 0.883008356545961 0.930976430976431\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 357 0.3005050505050505\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.937984496124031 0.43009478672985785 0.5833333333333334\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 387 0.3193069306930693\n",
      "data acceptance rates\n",
      "[0.3194842406876791, 0.30611045828437133, 0.3192019950124688, 0.3007518796992481, 0.3004172461752434, 0.314098750743605, 0.31370262390670556, 0.3007299270072993, 0.3005050505050505, 0.3193069306930693]\n",
      "data DP\n",
      "0.01906699451243571\n",
      "total accepted \n",
      "finalprecision 0.9139784946236559\n",
      "finalrecall 0.5652535328345802\n",
      "finalaccuracy 0.7554166666666666\n",
      "dimension of data\n",
      "10 2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal\n",
      "discripency is:\n",
      "0.6075\n",
      "gamma-epsilon-delta 0.3 0.1 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9508196721311475 0.6356164383561644 0.7922636103151862\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 244 0.3495702005730659\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9124767225325885 0.5847255369928401 0.7679200940070505\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 537 0.31551116333725027\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.995249406175772 0.47995418098510884 0.6209476309226932\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 421 0.34995843724023273\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8416666666666667 0.9181818181818182 0.9298245614035088\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 360 0.3007518796992481\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9083665338645418 0.6951219512195121 0.8289290681502086\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 251 0.34909596662030595\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9320754716981132 0.5645714285714286 0.7519333729922665\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 530 0.31528851873884595\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9391304347826087 0.5927552140504939 0.763265306122449\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 575 0.33527696793002915\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.883495145631068 0.6232876712328768 0.8043795620437956\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 206 0.3007299270072993\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8851540616246498 0.8802228412256268 0.9292929292929293\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 357 0.3005050505050505\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9575471698113207 0.48104265402843605 0.6237623762376238\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 424 0.34983498349834985\n",
      "data acceptance rates\n",
      "[0.3495702005730659, 0.31551116333725027, 0.34995843724023273, 0.3007518796992481, 0.34909596662030595, 0.31528851873884595, 0.33527696793002915, 0.3007299270072993, 0.3005050505050505, 0.34983498349834985]\n",
      "data DP\n",
      "0.049453386735182236\n",
      "total accepted \n",
      "finalprecision 0.9244558258642765\n",
      "finalrecall 0.600166251039069\n",
      "finalaccuracy 0.775\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.6325\n",
      "gamma-epsilon-delta 0.3 0.15 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9501915708812261 0.6794520547945205 0.8137535816618912\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 261 0.37392550143266473\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9090909090909091 0.5966587112171837 0.7720329024676851\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 550 0.32314923619271446\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9955654101995566 0.5143184421534936 0.6458852867830424\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 451 0.37489609310058186\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8305555555555556 0.906060606060606 0.923141186299081\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 360 0.3007518796992481\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8 0.5609756097560976 0.7357440890125174\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 230 0.3198887343532684\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9707401032702238 0.6445714285714286 0.8048780487804879\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 581 0.3456276026174896\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9203980099502488 0.6092206366630076 0.7644314868804665\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 603 0.3516034985422741\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9278846153846154 0.660958904109589 0.8335766423357664\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 208 0.30364963503649633\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8879551820728291 0.883008356545961 0.930976430976431\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 357 0.3005050505050505\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9493392070484582 0.5106635071090048 0.6402640264026402\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 454 0.37458745874587457\n",
      "data acceptance rates\n",
      "[0.37392550143266473, 0.32314923619271446, 0.37489609310058186, 0.3007518796992481, 0.3198887343532684, 0.3456276026174896, 0.3516034985422741, 0.30364963503649633, 0.3005050505050505, 0.37458745874587457]\n",
      "data DP\n",
      "0.07439104259553136\n",
      "total accepted \n",
      "finalprecision 0.9223181257706535\n",
      "finalrecall 0.6217788861180382\n",
      "finalaccuracy 0.7841666666666667\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.6575\n",
      "gamma-epsilon-delta 0.3 0.2 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8698884758364313 0.6410958904109589 0.7621776504297995\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 269 0.3853868194842407\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9475524475524476 0.6467780429594272 0.8084606345475911\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 572 0.33607520564042304\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9937629937629938 0.5475372279495991 0.6691604322527016\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 481 0.399833748960931\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8277777777777777 0.9030303030303031 0.9214703425229741\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 360 0.3007518796992481\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7870370370370371 0.5182926829268293 0.7162726008344924\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 216 0.3004172461752434\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9696 0.6925714285714286 0.8286734086853064\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 625 0.37180249851279\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9691558441558441 0.6553238199780461 0.8058309037900875\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 616 0.35918367346938773\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7955555555555556 0.613013698630137 0.7678832116788321\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 225 0.3284671532846715\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.888268156424581 0.8857938718662952 0.9318181818181818\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 358 0.30134680134680136\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.94824016563147 0.542654028436019 0.6608910891089109\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 483 0.39851485148514854\n",
      "data acceptance rates\n",
      "[0.3853868194842407, 0.33607520564042304, 0.399833748960931, 0.3007518796992481, 0.3004172461752434, 0.37180249851279, 0.35918367346938773, 0.3284671532846715, 0.30134680134680136, 0.39851485148514854]\n",
      "data DP\n",
      "0.09941650278568759\n",
      "total accepted \n",
      "finalprecision 0.9227110582639715\n",
      "finalrecall 0.6450540315876975\n",
      "finalaccuracy 0.795\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.7075\n",
      "gamma-epsilon-delta 0.3 0.3 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8726114649681529 0.7506849315068493 0.8123209169054442\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 314 0.4498567335243553\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9574105621805792 0.6706443914081146 0.8231492361927144\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 587 0.34488836662749706\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9963031423290203 0.6174112256586484 0.7206982543640897\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 541 0.44970906068162925\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.825 0.9 0.9197994987468672\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 360 0.3007518796992481\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7950819672131147 0.5914634146341463 0.7440890125173852\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 244 0.33936022253129344\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9771689497716894 0.7337142857142858 0.8524687685901249\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 657 0.3908387864366449\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9769230769230769 0.6970362239297475 0.8303206997084548\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 650 0.37900874635568516\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8007968127490039 0.6883561643835616 0.7941605839416058\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 251 0.36642335766423356\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8907563025210085 0.8857938718662952 0.9326599326599326\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 357 0.3005050505050505\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9522058823529411 0.6137440758293838 0.7095709570957096\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 544 0.44884488448844884\n",
      "data acceptance rates\n",
      "[0.4498567335243553, 0.34488836662749706, 0.44970906068162925, 0.3007518796992481, 0.33936022253129344, 0.3908387864366449, 0.37900874635568516, 0.36642335766423356, 0.3005050505050505, 0.44884488448844884]\n",
      "data DP\n",
      "0.1493516830193048\n",
      "total accepted \n",
      "finalprecision 0.9278579356270811\n",
      "finalrecall 0.6949293433083957\n",
      "finalaccuracy 0.82\n",
      "dimension of data\n",
      "10 2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal\n",
      "discripency is:\n",
      "0.7575\n",
      "gamma-epsilon-delta 0.3 0.4 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8565573770491803 0.5726027397260274 0.7263610315186246\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 244 0.3495702005730659\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9581589958158996 0.8198090692124105 0.8936545240893067\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 717 0.4212690951821387\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9950083194675541 0.6849942726231386 0.7689110556940981\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 601 0.4995843724023275\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8277777777777777 0.9030303030303031 0.9214703425229741\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 360 0.3007518796992481\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7870370370370371 0.5182926829268293 0.7162726008344924\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 216 0.3004172461752434\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.974496644295302 0.8297142857142857 0.900059488399762\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 745 0.44318857822724567\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9736842105263158 0.7716794731064764 0.8676384839650145\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 722 0.4209912536443149\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8075313807531381 0.660958904109589 0.7883211678832117\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 239 0.34890510948905107\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.888268156424581 0.8857938718662952 0.9318181818181818\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 358 0.30134680134680136\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9585406301824212 0.6848341232227488 0.7599009900990099\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 603 0.4975247524752475\n",
      "data acceptance rates\n",
      "[0.3495702005730659, 0.4212690951821387, 0.4995843724023275, 0.3007518796992481, 0.3004172461752434, 0.44318857822724567, 0.4209912536443149, 0.34890510948905107, 0.30134680134680136, 0.4975247524752475]\n",
      "data DP\n",
      "0.1991671262270841\n",
      "total accepted \n",
      "finalprecision 0.9323621227887617\n",
      "finalrecall 0.744804655029094\n",
      "finalaccuracy 0.845\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.56833333\n",
      "gamma-epsilon-delta 0.4 0.02 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7237762237762237 0.5671232876712329 0.660458452722063\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 286 0.40974212034383956\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8527696793002916 0.698090692124105 0.7920094007050529\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 686 0.40305522914218567\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9959432048681541 0.5624284077892325 0.6807980049875312\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 493 0.40980881130507063\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6283924843423799 0.9121212121212121 0.8270676691729323\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 479 0.40016708437761067\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.717687074829932 0.6432926829268293 0.721835883171071\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 294 0.4089012517385257\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8569321533923304 0.664 0.7674003569303985\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 678 0.4033313503866746\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.832378223495702 0.6377607025246982 0.7393586005830903\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 698 0.40699708454810496\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7700729927007299 0.7226027397260274 0.7897810218978102\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 274 0.4\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6440329218106996 0.871866295264624 0.8156565656565656\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 486 0.4090909090909091\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.98559670781893 0.5675355450236966 0.693069306930693\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 486 0.400990099009901\n",
      "data acceptance rates\n",
      "[0.40974212034383956, 0.40305522914218567, 0.40980881130507063, 0.40016708437761067, 0.4089012517385257, 0.4033313503866746, 0.40699708454810496, 0.4, 0.4090909090909091, 0.400990099009901]\n",
      "data DP\n",
      "0.009808811305070608\n",
      "total accepted \n",
      "finalprecision 0.8148148148148148\n",
      "finalrecall 0.6583541147132169\n",
      "finalaccuracy 0.75375\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.57833333\n",
      "gamma-epsilon-delta 0.4 0.04 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7178571428571429 0.5506849315068493 0.6518624641833811\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 280 0.40114613180515757\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8579545454545454 0.720763723150358 0.8037602820211516\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 704 0.4136310223266745\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.998019801980198 0.5773195876288659 0.6924355777223608\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 505 0.4197838736492103\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6283924843423799 0.9121212121212121 0.8270676691729323\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 479 0.40016708437761067\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7142857142857143 0.6554878048780488 0.7232267037552156\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 301 0.41863699582753827\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8638360175695461 0.6742857142857143 0.7751338488994646\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 683 0.40630577037477694\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8309859154929577 0.6476399560922064 0.7428571428571429\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 710 0.4139941690962099\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7846715328467153 0.7363013698630136 0.8014598540145985\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 274 0.4\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6491935483870968 0.8969359331476323 0.8223905723905723\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 496 0.4175084175084175\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9897540983606558 0.5722748815165877 0.698019801980198\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 488 0.40264026402640263\n",
      "data acceptance rates\n",
      "[0.40114613180515757, 0.4136310223266745, 0.4197838736492103, 0.40016708437761067, 0.41863699582753827, 0.40630577037477694, 0.4139941690962099, 0.4, 0.4175084175084175, 0.40264026402640263]\n",
      "data DP\n",
      "0.019783873649210304\n",
      "total accepted \n",
      "finalprecision 0.818089430894309\n",
      "finalrecall 0.6691604322527016\n",
      "finalaccuracy 0.7595833333333334\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.60833333\n",
      "gamma-epsilon-delta 0.4 0.1 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.734982332155477 0.5698630136986301 0.667621776504298\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 283 0.4054441260744986\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8629579375848032 0.7589498806682577 0.8219741480611046\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 737 0.43301997649823737\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9963031423290203 0.6174112256586484 0.7206982543640897\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 541 0.44970906068162925\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6367432150313153 0.9242424242424242 0.83375104427736\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 479 0.40016708437761067\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8148148148148148 0.7378048780487805 0.803894297635605\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 297 0.41307371349095967\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8326417704011065 0.688 0.7656157049375372\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 723 0.43010113027959546\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8651685393258427 0.6761800219538968 0.7720116618075802\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 712 0.4151603498542274\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7402597402597403 0.7808219178082192 0.7897810218978102\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 308 0.44963503649635034\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6827731092436975 0.9052924791086351 0.8442760942760943\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 476 0.4006734006734007\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9540441176470589 0.6149289099526066 0.7112211221122112\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 544 0.44884488448844884\n",
      "data acceptance rates\n",
      "[0.4054441260744986, 0.43301997649823737, 0.44970906068162925, 0.40016708437761067, 0.41307371349095967, 0.43010113027959546, 0.4151603498542274, 0.44963503649635034, 0.4006734006734007, 0.44884488448844884]\n",
      "data DP\n",
      "0.049541976304018576\n",
      "total accepted \n",
      "finalprecision 0.8274509803921568\n",
      "finalrecall 0.7015793848711555\n",
      "finalaccuracy 0.7770833333333333\n",
      "dimension of data\n",
      "10 2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal\n",
      "discripency is:\n",
      "0.63333333\n",
      "gamma-epsilon-delta 0.4 0.15 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6642857142857143 0.5095890410958904 0.6088825214899714\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 280 0.40114613180515757\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8935064935064935 0.8210023866348448 0.863689776733255\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 770 0.45240893066980026\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9947460595446584 0.6506300114547537 0.743973399833749\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 571 0.4746467165419784\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6388308977035491 0.9272727272727272 0.835421888053467\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 479 0.40016708437761067\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.78125 0.6859756097560976 0.7691237830319889\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 288 0.40055632823365783\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8517060367454068 0.7417142857142857 0.7983343248066627\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 762 0.45330160618679355\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.896551724137931 0.7135016465422612 0.8040816326530612\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 725 0.4227405247813411\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6892307692307692 0.7671232876712328 0.7532846715328467\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 325 0.4744525547445255\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6764705882352942 0.8969359331476323 0.8392255892255892\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 476 0.4006734006734007\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9616724738675958 0.6540284360189573 0.740924092409241\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 574 0.4735973597359736\n",
      "data acceptance rates\n",
      "[0.40114613180515757, 0.45240893066980026, 0.4746467165419784, 0.40016708437761067, 0.40055632823365783, 0.45330160618679355, 0.4227405247813411, 0.4744525547445255, 0.4006734006734007, 0.4735973597359736]\n",
      "data DP\n",
      "0.0744796321643677\n",
      "total accepted \n",
      "finalprecision 0.8323809523809523\n",
      "finalrecall 0.7265170407315046\n",
      "finalaccuracy 0.7895833333333333\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.65833333\n",
      "gamma-epsilon-delta 0.4 0.2 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7007042253521126 0.5452054794520548 0.6404011461318052\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 284 0.4068767908309456\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8844221105527639 0.8400954653937948 0.8672150411280846\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 796 0.46768507638072854\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9950083194675541 0.6849942726231386 0.7689110556940981\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 601 0.4995843724023275\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6367432150313153 0.9242424242424242 0.83375104427736\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 479 0.40016708437761067\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8090277777777778 0.7103658536585366 0.7913769123783032\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 288 0.40055632823365783\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8459595959595959 0.7657142857142857 0.8054729327781083\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 792 0.4711481261154075\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8998664886515354 0.7398463227222832 0.8180758017492712\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 749 0.43673469387755104\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6918429003021148 0.7842465753424658 0.7591240875912408\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 331 0.4832116788321168\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6848739495798319 0.9080779944289693 0.8459595959595959\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 476 0.4006734006734007\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9552980132450332 0.683649289099526 0.7574257425742574\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 604 0.49834983498349833\n",
      "data acceptance rates\n",
      "[0.4068767908309456, 0.46768507638072854, 0.4995843724023275, 0.40016708437761067, 0.40055632823365783, 0.4711481261154075, 0.43673469387755104, 0.4832116788321168, 0.4006734006734007, 0.49834983498349833]\n",
      "data DP\n",
      "0.09941728802471683\n",
      "total accepted \n",
      "finalprecision 0.8361111111111111\n",
      "finalrecall 0.7506234413965087\n",
      "finalaccuracy 0.80125\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.70833333\n",
      "gamma-epsilon-delta 0.4 0.3 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.75 0.5753424657534246 0.6776504297994269\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 280 0.40114613180515757\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8697674418604651 0.8926014319809069 0.881316098707403\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 860 0.5052878965922444\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9954614220877458 0.7537227949599083 0.8187863674147964\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 661 0.5494596841230258\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6263048016701461 0.9090909090909091 0.8253968253968254\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 479 0.40016708437761067\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6777777777777778 0.7439024390243902 0.721835883171071\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 360 0.5006954102920723\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9153846153846154 0.816 0.8649613325401546\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 780 0.4640095181439619\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.851039260969977 0.8090010976948409 0.8233236151603499\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 866 0.5049562682215744\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8065693430656934 0.7568493150684932 0.8189781021897811\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 274 0.4\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6743697478991597 0.8941504178272981 0.8375420875420876\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 476 0.4006734006734007\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9593373493975904 0.754739336492891 0.806930693069307\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 664 0.5478547854785478\n",
      "data acceptance rates\n",
      "[0.40114613180515757, 0.5052878965922444, 0.5494596841230258, 0.40016708437761067, 0.5006954102920723, 0.4640095181439619, 0.5049562682215744, 0.4, 0.4006734006734007, 0.5478547854785478]\n",
      "data DP\n",
      "0.1494596841230258\n",
      "total accepted \n",
      "finalprecision 0.8403508771929824\n",
      "finalrecall 0.7963424771404821\n",
      "finalaccuracy 0.8220833333333334\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.75833333\n",
      "gamma-epsilon-delta 0.4 0.4 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8631578947368421 0.673972602739726 0.7736389684813754\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 285 0.40830945558739257\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8426229508196721 0.9200477326968973 0.8760282021151586\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 915 0.5376028202115158\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9958391123439667 0.8224513172966781 0.8686616791354946\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 721 0.5993349958437241\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6242171189979123 0.906060606060606 0.8237259816207184\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 479 0.40016708437761067\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7493975903614458 0.948170731707317 0.8317107093184979\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 415 0.5771905424200278\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8993630573248408 0.8068571428571428 0.8524687685901249\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 785 0.46698393813206424\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8563656147986942 0.8638858397365532 0.8507288629737609\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 919 0.5358600583090379\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8185053380782918 0.7876712328767124 0.8350364963503649\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 281 0.41021897810218977\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6722689075630253 0.8913649025069638 0.8358585858585859\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 476 0.4006734006734007\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.962707182320442 0.8258293838862559 0.8564356435643564\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 724 0.5973597359735974\n",
      "data acceptance rates\n",
      "[0.40830945558739257, 0.5376028202115158, 0.5993349958437241, 0.40016708437761067, 0.5771905424200278, 0.46698393813206424, 0.5358600583090379, 0.41021897810218977, 0.4006734006734007, 0.5973597359735974]\n",
      "data DP\n",
      "0.1991679114661134\n",
      "total accepted \n",
      "finalprecision 0.8475\n",
      "finalrecall 0.8453865336658354\n",
      "finalaccuracy 0.84625\n",
      "dimension of data\n",
      "10 2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal\n",
      "discripency is:\n",
      "0.56833333\n",
      "gamma-epsilon-delta 0.5 0.02 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5787965616045845 0.5534246575342465 0.5558739255014327\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 349 0.5\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8273464658169177 0.8520286396181385 0.8396004700352526\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 863 0.5070505287896592\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9951060358890701 0.6987399770904925 0.7788861180382377\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 613 0.5095594347464671\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5108514190317195 0.9272727272727272 0.7351712614870509\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 599 0.5004177109440268\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7361111111111112 0.8079268292682927 0.780250347705146\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 360 0.5006954102920723\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7640845070422535 0.744 0.7471743010113028\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 852 0.5068411659726353\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8768699654775605 0.8364434687156971 0.8507288629737609\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 869 0.5067055393586006\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.4489795918367347 0.5273972602739726 0.5226277372262774\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 343 0.5007299270072992\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5374376039933444 0.8997214484679665 0.7356902356902357\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 601 0.5058922558922558\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9705400981996727 0.70260663507109 0.778052805280528\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 611 0.5041254125412541\n",
      "data acceptance rates\n",
      "[0.5, 0.5070505287896592, 0.5095594347464671, 0.5004177109440268, 0.5006954102920723, 0.5068411659726353, 0.5067055393586006, 0.5007299270072992, 0.5058922558922558, 0.5041254125412541]\n",
      "data DP\n",
      "0.009559434746467144\n",
      "total accepted \n",
      "finalprecision 0.7557755775577558\n",
      "finalrecall 0.7614297589359933\n",
      "finalaccuracy 0.7570833333333333\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.57833333\n",
      "gamma-epsilon-delta 0.5 0.04 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.569060773480663 0.5643835616438356 0.5487106017191977\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 362 0.5186246418338109\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8329466357308585 0.8568019093078759 0.8448883666274971\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 862 0.5064629847238543\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9952 0.7124856815578465 0.7888611803823774\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 625 0.5195344970906068\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5041736227045075 0.9151515151515152 0.7284878863826232\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 599 0.5004177109440268\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7472222222222222 0.8201219512195121 0.7913769123783032\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 360 0.5006954102920723\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7581018518518519 0.7485714285714286 0.744794765020821\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 864 0.5139797739440809\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8308740068104427 0.8035126234906695 0.8087463556851312\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 881 0.5137026239067055\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5597667638483965 0.6575342465753424 0.6335766423357664\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 343 0.5007299270072992\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5420875420875421 0.8969359331476323 0.73989898989899\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 594 0.5\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9555555555555556 0.7132701421800948 0.7772277227722773\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 630 0.5198019801980198\n",
      "data acceptance rates\n",
      "[0.5186246418338109, 0.5064629847238543, 0.5195344970906068, 0.5004177109440268, 0.5006954102920723, 0.5139797739440809, 0.5137026239067055, 0.5007299270072992, 0.5, 0.5198019801980198]\n",
      "data DP\n",
      "0.01980198019801982\n",
      "total accepted \n",
      "finalprecision 0.7549019607843137\n",
      "finalrecall 0.7680798004987531\n",
      "finalaccuracy 0.75875\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.60833333\n",
      "gamma-epsilon-delta 0.5 0.1 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5039164490861618 0.5287671232876713 0.4813753581661891\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 383 0.5487106017191977\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8734321550741163 0.9140811455847255 0.8924794359576969\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 877 0.5152761457109283\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9954614220877458 0.7537227949599083 0.8187863674147964\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 661 0.5494596841230258\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5025041736227045 0.9121212121212121 0.7268170426065163\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 599 0.5004177109440268\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7091412742382271 0.7804878048780488 0.7538247566063978\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 361 0.502086230876217\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7819799777530589 0.8034285714285714 0.7810826888756692\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 899 0.5348007138607972\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8396946564885496 0.845225027442371 0.8320699708454811\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 917 0.5346938775510204\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5510204081632653 0.6472602739726028 0.6248175182481752\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 343 0.5007299270072992\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5420875420875421 0.8969359331476323 0.73989898989899\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 594 0.5\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9564564564564565 0.754739336492891 0.8052805280528053\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 666 0.5495049504950495\n",
      "data acceptance rates\n",
      "[0.5487106017191977, 0.5152761457109283, 0.5494596841230258, 0.5004177109440268, 0.502086230876217, 0.5348007138607972, 0.5346938775510204, 0.5007299270072992, 0.5, 0.5495049504950495]\n",
      "data DP\n",
      "0.04950495049504955\n",
      "total accepted \n",
      "finalprecision 0.7611111111111111\n",
      "finalrecall 0.7971737323358271\n",
      "finalaccuracy 0.7729166666666667\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.63333333\n",
      "gamma-epsilon-delta 0.5 0.15 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5202020202020202 0.5643835616438356 0.5\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 396 0.5673352435530086\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8758389261744967 0.9343675417661098 0.9024676850763808\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 894 0.5252643948296122\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9956584659913169 0.7880870561282932 0.8437240232751455\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 691 0.5743973399833749\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5025041736227045 0.9121212121212121 0.7268170426065163\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 599 0.5004177109440268\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7192513368983957 0.8201219512195121 0.7719054242002782\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 374 0.5201668984700973\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7860262008733624 0.8228571428571428 0.7911957168352172\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 916 0.544913741820345\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8447729672650475 0.8781558726673985 0.8495626822157435\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 947 0.5521865889212828\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5510204081632653 0.6472602739726028 0.6248175182481752\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 343 0.5007299270072992\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5411764705882353 0.8969359331476323 0.7390572390572391\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 595 0.5008417508417509\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9597122302158273 0.7902843601895735 0.8308580858085809\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 695 0.5734323432343235\n",
      "data acceptance rates\n",
      "[0.5673352435530086, 0.5252643948296122, 0.5743973399833749, 0.5004177109440268, 0.5201668984700973, 0.544913741820345, 0.5521865889212828, 0.5007299270072992, 0.5008417508417509, 0.5734323432343235]\n",
      "data DP\n",
      "0.07397962903934818\n",
      "total accepted \n",
      "finalprecision 0.7666666666666667\n",
      "finalrecall 0.8221113881961762\n",
      "finalaccuracy 0.7854166666666667\n",
      "dimension of data\n",
      "10 2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal\n",
      "discripency is:\n",
      "0.65833333\n",
      "gamma-epsilon-delta 0.5 0.2 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5686274509803921 0.6356164383561644 0.5573065902578797\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 408 0.5845272206303725\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8651315789473685 0.9415274463007159 0.8989424206815512\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 912 0.535840188014101\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9958391123439667 0.8224513172966781 0.8686616791354946\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 721 0.5993349958437241\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5058430717863105 0.9181818181818182 0.7301587301587301\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 599 0.5004177109440268\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7472222222222222 0.8201219512195121 0.7913769123783032\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 360 0.5006954102920723\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7833333333333333 0.8594285714285714 0.8030933967876264\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 960 0.5710886377156454\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8345473465140478 0.8803512623490669 0.8437317784256559\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 961 0.5603498542274052\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6100278551532033 0.75 0.689051094890511\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 359 0.5240875912408759\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5353535353535354 0.8857938718662952 0.7331649831649831\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 594 0.5\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9683195592286501 0.8329383886255924 0.8646864686468647\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 726 0.599009900990099\n",
      "data acceptance rates\n",
      "[0.5845272206303725, 0.535840188014101, 0.5993349958437241, 0.5004177109440268, 0.5006954102920723, 0.5710886377156454, 0.5603498542274052, 0.5240875912408759, 0.5, 0.599009900990099]\n",
      "data DP\n",
      "0.09933499584372407\n",
      "total accepted \n",
      "finalprecision 0.7734848484848484\n",
      "finalrecall 0.8487115544472152\n",
      "finalaccuracy 0.7995833333333333\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.70833333\n",
      "gamma-epsilon-delta 0.5 0.3 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6912114014251781 0.7972602739726027 0.7077363896848138\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 421 0.6031518624641834\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.821689259645464 0.9403341288782816 0.8701527614571093\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 959 0.563454759106933\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9961587708066582 0.8911798396334479 0.9185369908561929\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 781 0.6492103075644223\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5025041736227045 0.9121212121212121 0.7268170426065163\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 599 0.5004177109440268\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7430939226519337 0.8201219512195121 0.7885952712100139\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 362 0.5034770514603616\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7956777996070727 0.9257142857142857 0.8375966686496134\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 1018 0.6055919095776323\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8439646712463199 0.9440175631174533 0.8775510204081632\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 1019 0.5941690962099125\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6066481994459834 0.75 0.6861313868613139\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 361 0.527007299270073\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5210084033613446 0.8635097493036211 0.7188552188552189\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 595 0.5008417508417509\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9796178343949045 0.9111374407582938 0.9249174917491749\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 785 0.6476897689768977\n",
      "data acceptance rates\n",
      "[0.6031518624641834, 0.563454759106933, 0.6492103075644223, 0.5004177109440268, 0.5034770514603616, 0.6055919095776323, 0.5941690962099125, 0.527007299270073, 0.5008417508417509, 0.6476897689768977]\n",
      "data DP\n",
      "0.14879259662039557\n",
      "total accepted \n",
      "finalprecision 0.7818840579710145\n",
      "finalrecall 0.8969243557772236\n",
      "finalaccuracy 0.8229166666666666\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.75333333\n",
      "gamma-epsilon-delta 0.5 0.4 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7084188911704312 0.9452054794520548 0.7679083094555874\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 487 0.6977077363896849\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8342133051742344 0.9427207637231504 0.8795534665099882\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 947 0.5564042303172738\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9964071856287425 0.9530355097365406 0.9634247714048213\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 835 0.6940980881130507\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5058430717863105 0.9181818181818182 0.7301587301587301\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 599 0.5004177109440268\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8567493112947658 0.948170731707317 0.9040333796940194\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 363 0.5048678720445062\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.76937441643324 0.9417142857142857 0.8227245687091017\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 1071 0.637120761451517\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.8585461689587426 0.9593852908891328 0.894460641399417\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 1018 0.5935860058309038\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6274038461538461 0.8938356164383562 0.7284671532846715\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 416 0.6072992700729927\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5454545454545454 0.9025069637883009 0.7432659932659933\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 594 0.5\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9654761904761905 0.9609004739336493 0.9488448844884488\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 840 0.693069306930693\n",
      "data acceptance rates\n",
      "[0.6977077363896849, 0.5564042303172738, 0.6940980881130507, 0.5004177109440268, 0.5048678720445062, 0.637120761451517, 0.5935860058309038, 0.6072992700729927, 0.5, 0.693069306930693]\n",
      "data DP\n",
      "0.19770773638968486\n",
      "total accepted \n",
      "finalprecision 0.791492329149233\n",
      "finalrecall 0.943474646716542\n",
      "finalaccuracy 0.8470833333333333\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.56666667\n",
      "gamma-epsilon-delta 0.6 0.02 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6517647058823529 0.7589041095890411 0.66189111747851\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 425 0.6088825214899714\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7370983446932814 0.9033412887828163 0.7937720329024677\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 1027 0.6034077555816686\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9945429740791268 0.8350515463917526 0.8769742310889443\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 733 0.6093100581878637\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.4242002781641168 0.9242424242424242 0.633249791144528\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 719 0.6006683375104428\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7199074074074074 0.948170731707317 0.808066759388039\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 432 0.6008344923504868\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7088235294117647 0.8262857142857143 0.7328970850684117\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 1020 0.6067816775728733\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7425552353506244 0.8485181119648738 0.763265306122449\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 1041 0.606997084548105\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.635036496350365 0.8938356164383562 0.7357664233576642\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 411 0.6\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.45722300140252453 0.9080779944289693 0.6464646464646465\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 713 0.6001683501683501\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9580514208389715 0.8388625592417062 0.8622112211221122\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 739 0.6097359735973598\n",
      "data acceptance rates\n",
      "[0.6088825214899714, 0.6034077555816686, 0.6093100581878637, 0.6006683375104428, 0.6008344923504868, 0.6067816775728733, 0.606997084548105, 0.6, 0.6001683501683501, 0.6097359735973598]\n",
      "data DP\n",
      "0.009735973597359782\n",
      "total accepted \n",
      "finalprecision 0.7121212121212122\n",
      "finalrecall 0.8595178719866999\n",
      "finalaccuracy 0.7554166666666666\n",
      "dimension of data\n",
      "10 2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal\n",
      "discripency is:\n",
      "0.57666667\n",
      "gamma-epsilon-delta 0.6 0.04 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6990740740740741 0.8273972602739726 0.7234957020057307\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 432 0.6189111747851003\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7218992248062015 0.8890214797136038 0.7767332549941246\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 1032 0.6063454759106933\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9946308724832215 0.8487972508591065 0.8869492934330839\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 745 0.6192851205320034\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.42559109874826145 0.9272727272727272 0.6349206349206349\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 719 0.6006683375104428\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7199074074074074 0.948170731707317 0.808066759388039\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 432 0.6008344923504868\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7131782945736435 0.8411428571428572 0.7412254610350981\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 1032 0.6139202855443189\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7730294396961064 0.893523600439078 0.8040816326530612\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 1053 0.61399416909621\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5669099756690997 0.797945205479452 0.654014598540146\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 411 0.6\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.4586255259467041 0.9108635097493036 0.6481481481481481\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 713 0.6001683501683501\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9587217043941412 0.8530805687203792 0.8721122112211221\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 751 0.6196369636963697\n",
      "data acceptance rates\n",
      "[0.6189111747851003, 0.6063454759106933, 0.6192851205320034, 0.6006683375104428, 0.6008344923504868, 0.6139202855443189, 0.61399416909621, 0.6, 0.6001683501683501, 0.6196369636963697]\n",
      "data DP\n",
      "0.01963696369636969\n",
      "total accepted \n",
      "finalprecision 0.7151639344262295\n",
      "finalrecall 0.8703241895261845\n",
      "finalaccuracy 0.76125\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.60666667\n",
      "gamma-epsilon-delta 0.6 0.1 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6473214285714286 0.7945205479452054 0.666189111747851\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 448 0.6418338108882522\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7519011406844106 0.9439140811455847 0.8190364277320799\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 1052 0.618096357226792\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9948783610755442 0.8900343642611683 0.9168744804655029\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 781 0.6492103075644223\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.4228094575799722 0.9212121212121213 0.631578947368421\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 719 0.6006683375104428\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7199074074074074 0.948170731707317 0.808066759388039\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 432 0.6008344923504868\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7209737827715356 0.88 0.760261748958953\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 1068 0.6353361094586556\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7578558225508318 0.9001097694840834 0.7941690962099125\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 1082 0.6309037900874636\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6244019138755981 0.8938356164383562 0.7255474452554744\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 418 0.6102189781021898\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.45582047685834504 0.9052924791086351 0.6447811447811448\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 713 0.6001683501683501\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9606099110546379 0.8957345971563981 0.9018151815181518\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 787 0.6493399339933993\n",
      "data acceptance rates\n",
      "[0.6418338108882522, 0.618096357226792, 0.6492103075644223, 0.6006683375104428, 0.6008344923504868, 0.6353361094586556, 0.6309037900874636, 0.6102189781021898, 0.6001683501683501, 0.6493399339933993]\n",
      "data DP\n",
      "0.04917158382504916\n",
      "total accepted \n",
      "finalprecision 0.7206666666666667\n",
      "finalrecall 0.8985868661679135\n",
      "finalaccuracy 0.7745833333333333\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.6325\n",
      "gamma-epsilon-delta 0.6 0.15 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6815286624203821 0.8794520547945206 0.7220630372492837\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 471 0.6747851002865329\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7462264150943396 0.9439140811455847 0.8143360752056404\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 1060 0.6227967097532315\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9950738916256158 0.9255441008018328 0.942643391521197\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 812 0.6749792186201163\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.4228094575799722 0.9212121212121213 0.631578947368421\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 719 0.6006683375104428\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7199074074074074 0.948170731707317 0.808066759388039\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 432 0.6008344923504868\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7288444040036397 0.9154285714285715 0.7787031528851874\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 1099 0.65377751338489\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7605004468275246 0.9341383095499451 0.8087463556851312\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 1119 0.6524781341107871\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.633495145631068 0.8938356164383562 0.7343065693430657\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 412 0.6014598540145986\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.45582047685834504 0.9052924791086351 0.6447811447811448\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 713 0.6001683501683501\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9621026894865525 0.9324644549763034 0.9273927392739274\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 818 0.6749174917491749\n",
      "data acceptance rates\n",
      "[0.6747851002865329, 0.6227967097532315, 0.6749792186201163, 0.6006683375104428, 0.6008344923504868, 0.65377751338489, 0.6524781341107871, 0.6014598540145986, 0.6001683501683501, 0.6749174917491749]\n",
      "data DP\n",
      "0.07481086845176621\n",
      "total accepted \n",
      "finalprecision 0.7263226649248857\n",
      "finalrecall 0.9243557772236076\n",
      "finalaccuracy 0.7875\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.6525\n",
      "gamma-epsilon-delta 0.6 0.2 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7069672131147541 0.9452054794520548 0.7664756446991404\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 488 0.6991404011461319\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7432052483598875 0.9463007159904535 0.8125734430082256\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 1067 0.6269095182138661\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9952153110047847 0.9530355097365406 0.9625935162094763\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 836 0.6949293433083957\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.42559109874826145 0.9272727272727272 0.6349206349206349\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 719 0.6006683375104428\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7199074074074074 0.948170731707317 0.808066759388039\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 432 0.6008344923504868\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.736420302760463 0.9451428571428572 0.7953599048185603\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 1123 0.6680547293277811\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7657342657342657 0.9615806805708014 0.8233236151603499\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 1144 0.6670553935860059\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6374695863746959 0.8972602739726028 0.7386861313868613\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 411 0.6\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.4586255259467041 0.9108635097493036 0.6481481481481481\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 713 0.6001683501683501\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9631828978622328 0.9609004739336493 0.9471947194719472\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 842 0.6947194719471947\n",
      "data acceptance rates\n",
      "[0.6991404011461319, 0.6269095182138661, 0.6949293433083957, 0.6006683375104428, 0.6008344923504868, 0.6680547293277811, 0.6670553935860059, 0.6, 0.6001683501683501, 0.6947194719471947]\n",
      "data DP\n",
      "0.09914040114613187\n",
      "total accepted \n",
      "finalprecision 0.7318327974276527\n",
      "finalrecall 0.9459684123025769\n",
      "finalaccuracy 0.7991666666666667\n",
      "dimension of data\n",
      "10 2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal\n",
      "discripency is:\n",
      "0.6525\n",
      "gamma-epsilon-delta 0.6 0.3 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6858846918489065 0.9452054794520548 0.7449856733524355\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 503 0.7206303724928367\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7519011406844106 0.9439140811455847 0.8190364277320799\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 1052 0.618096357226792\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9952153110047847 0.9530355097365406 0.9625935162094763\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 836 0.6949293433083957\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.4228094575799722 0.9212121212121213 0.631578947368421\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 719 0.6006683375104428\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7199074074074074 0.948170731707317 0.808066759388039\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 432 0.6008344923504868\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7346393588601959 0.9428571428571428 0.7929803688280785\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 1123 0.6680547293277811\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7695690413368513 0.960482985729967 0.8262390670553936\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 1137 0.6629737609329446\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6244019138755981 0.8938356164383562 0.7255474452554744\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 418 0.6102189781021898\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.45582047685834504 0.9052924791086351 0.6447811447811448\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 713 0.6001683501683501\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9631828978622328 0.9609004739336493 0.9471947194719472\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 842 0.6947194719471947\n",
      "data acceptance rates\n",
      "[0.7206303724928367, 0.618096357226792, 0.6949293433083957, 0.6006683375104428, 0.6008344923504868, 0.6680547293277811, 0.6629737609329446, 0.6102189781021898, 0.6001683501683501, 0.6947194719471947]\n",
      "data DP\n",
      "0.12046202232448655\n",
      "total accepted \n",
      "finalprecision 0.7305466237942122\n",
      "finalrecall 0.9443059019118869\n",
      "finalaccuracy 0.7975\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.6525\n",
      "gamma-epsilon-delta 0.6 0.4 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6858846918489065 0.9452054794520548 0.7449856733524355\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 503 0.7206303724928367\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7519011406844106 0.9439140811455847 0.8190364277320799\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 1052 0.618096357226792\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9952153110047847 0.9530355097365406 0.9625935162094763\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 836 0.6949293433083957\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.4228094575799722 0.9212121212121213 0.631578947368421\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 719 0.6006683375104428\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7199074074074074 0.948170731707317 0.808066759388039\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 432 0.6008344923504868\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7346393588601959 0.9428571428571428 0.7929803688280785\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 1123 0.6680547293277811\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7695690413368513 0.960482985729967 0.8262390670553936\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 1137 0.6629737609329446\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6244019138755981 0.8938356164383562 0.7255474452554744\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 418 0.6102189781021898\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.45582047685834504 0.9052924791086351 0.6447811447811448\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 713 0.6001683501683501\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9631828978622328 0.9609004739336493 0.9471947194719472\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 842 0.6947194719471947\n",
      "data acceptance rates\n",
      "[0.7206303724928367, 0.618096357226792, 0.6949293433083957, 0.6006683375104428, 0.6008344923504868, 0.6680547293277811, 0.6629737609329446, 0.6102189781021898, 0.6001683501683501, 0.6947194719471947]\n",
      "data DP\n",
      "0.12046202232448655\n",
      "total accepted \n",
      "finalprecision 0.7305466237942122\n",
      "finalrecall 0.9443059019118869\n",
      "finalaccuracy 0.7975\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.50833333\n",
      "gamma-epsilon-delta 0.7 0.02 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6768916155419223 0.9068493150684932 0.7249283667621776\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 489 0.7005730659025788\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6683291770573566 0.9594272076372315 0.745593419506463\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 1203 0.7068155111633373\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9578454332552693 0.9369988545246277 0.9243557772236076\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 854 0.7098919368246052\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.37828162291169454 0.9606060606060606 0.5538847117794486\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 838 0.7000835421888053\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.626984126984127 0.9634146341463414 0.721835883171071\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 504 0.7009735744089013\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6893939393939394 0.936 0.7471743010113028\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 1188 0.7067221891731112\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7197346600331676 0.9527991218441273 0.7778425655976676\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 1206 0.7032069970845481\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5493827160493827 0.9143835616438356 0.6437956204379562\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 486 0.7094890510948905\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.4098557692307692 0.9498607242339833 0.5715488215488216\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 832 0.7003367003367004\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9232558139534883 0.9407582938388626 0.9042904290429042\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 860 0.7095709570957096\n",
      "data acceptance rates\n",
      "[0.7005730659025788, 0.7068155111633373, 0.7098919368246052, 0.7000835421888053, 0.7009735744089013, 0.7067221891731112, 0.7032069970845481, 0.7094890510948905, 0.7003367003367004, 0.7095709570957096]\n",
      "data DP\n",
      "0.009808394635799855\n",
      "total accepted \n",
      "finalprecision 0.6708037825059102\n",
      "finalrecall 0.943474646716542\n",
      "finalaccuracy 0.7395833333333334\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.51833333\n",
      "gamma-epsilon-delta 0.7 0.04 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6952191235059761 0.9561643835616438 0.7578796561604585\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 502 0.7191977077363897\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6647254575707154 0.9534606205250596 0.7403055229142186\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 1202 0.7062279670975323\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9595842956120092 0.9518900343642611 0.9359933499584372\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 866 0.7198669991687449\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.37828162291169454 0.9606060606060606 0.5538847117794486\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 838 0.7000835421888053\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.628968253968254 0.9664634146341463 0.7246175243393602\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 504 0.7009735744089013\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6925 0.9497142857142857 0.7543129089827484\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 1200 0.7138607971445569\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7178014766201805 0.960482985729967 0.7784256559766763\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 1219 0.7107871720116619\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5628865979381443 0.934931506849315 0.6627737226277373\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 485 0.708029197080292\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.4110576923076923 0.9526462395543176 0.5732323232323232\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 832 0.7003367003367004\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9243119266055045 0.9549763033175356 0.9141914191419142\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 872 0.7194719471947195\n",
      "data acceptance rates\n",
      "[0.7191977077363897, 0.7062279670975323, 0.7198669991687449, 0.7000835421888053, 0.7009735744089013, 0.7138607971445569, 0.7107871720116619, 0.708029197080292, 0.7003367003367004, 0.7194719471947195]\n",
      "data DP\n",
      "0.01978345697993955\n",
      "total accepted \n",
      "finalprecision 0.6737089201877934\n",
      "finalrecall 0.9542809642560266\n",
      "finalaccuracy 0.7454166666666666\n",
      "dimension of data\n",
      "10 2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal\n",
      "discripency is:\n",
      "0.52333333\n",
      "gamma-epsilon-delta 0.7 0.1 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6718146718146718 0.9534246575342465 0.7320916905444126\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 518 0.7421203438395415\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6719798657718121 0.9558472553699284 0.7485311398354877\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 1192 0.700352526439483\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9587155963302753 0.9576174112256587 0.9393183707398172\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 872 0.7248545303408146\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.373508353221957 0.9484848484848485 0.5472013366750209\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 838 0.7000835421888053\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.625 0.9603658536585366 0.7190542420027817\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 504 0.7009735744089013\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6915422885572139 0.9531428571428572 0.7543129089827484\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 1206 0.7174301011302796\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7287853577371048 0.9615806805708014 0.7895043731778426\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 1202 0.7008746355685131\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5374015748031497 0.934931506849315 0.6291970802919709\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 508 0.7416058394160584\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.40625 0.9415041782729805 0.5664983164983165\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 832 0.7003367003367004\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9236902050113895 0.9609004739336493 0.9174917491749175\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 878 0.7244224422442245\n",
      "data acceptance rates\n",
      "[0.7421203438395415, 0.700352526439483, 0.7248545303408146, 0.7000835421888053, 0.7009735744089013, 0.7174301011302796, 0.7008746355685131, 0.7416058394160584, 0.7003367003367004, 0.7244224422442245]\n",
      "data DP\n",
      "0.0420368016507362\n",
      "total accepted \n",
      "finalprecision 0.6719298245614035\n",
      "finalrecall 0.9551122194513716\n",
      "finalaccuracy 0.74375\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.52333333\n",
      "gamma-epsilon-delta 0.7 0.15 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6718146718146718 0.9534246575342465 0.7320916905444126\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 518 0.7421203438395415\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6719798657718121 0.9558472553699284 0.7485311398354877\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 1192 0.700352526439483\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9587155963302753 0.9576174112256587 0.9393183707398172\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 872 0.7248545303408146\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.373508353221957 0.9484848484848485 0.5472013366750209\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 838 0.7000835421888053\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.625 0.9603658536585366 0.7190542420027817\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 504 0.7009735744089013\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6915422885572139 0.9531428571428572 0.7543129089827484\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 1206 0.7174301011302796\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7287853577371048 0.9615806805708014 0.7895043731778426\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 1202 0.7008746355685131\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5374015748031497 0.934931506849315 0.6291970802919709\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 508 0.7416058394160584\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.40625 0.9415041782729805 0.5664983164983165\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 832 0.7003367003367004\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9236902050113895 0.9609004739336493 0.9174917491749175\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 878 0.7244224422442245\n",
      "data acceptance rates\n",
      "[0.7421203438395415, 0.700352526439483, 0.7248545303408146, 0.7000835421888053, 0.7009735744089013, 0.7174301011302796, 0.7008746355685131, 0.7416058394160584, 0.7003367003367004, 0.7244224422442245]\n",
      "data DP\n",
      "0.0420368016507362\n",
      "total accepted \n",
      "finalprecision 0.6719298245614035\n",
      "finalrecall 0.9551122194513716\n",
      "finalaccuracy 0.74375\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.52333333\n",
      "gamma-epsilon-delta 0.7 0.2 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6718146718146718 0.9534246575342465 0.7320916905444126\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 518 0.7421203438395415\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6719798657718121 0.9558472553699284 0.7485311398354877\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 1192 0.700352526439483\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9587155963302753 0.9576174112256587 0.9393183707398172\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 872 0.7248545303408146\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.373508353221957 0.9484848484848485 0.5472013366750209\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 838 0.7000835421888053\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.625 0.9603658536585366 0.7190542420027817\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 504 0.7009735744089013\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6915422885572139 0.9531428571428572 0.7543129089827484\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 1206 0.7174301011302796\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7287853577371048 0.9615806805708014 0.7895043731778426\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 1202 0.7008746355685131\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5374015748031497 0.934931506849315 0.6291970802919709\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 508 0.7416058394160584\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.40625 0.9415041782729805 0.5664983164983165\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 832 0.7003367003367004\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9236902050113895 0.9609004739336493 0.9174917491749175\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 878 0.7244224422442245\n",
      "data acceptance rates\n",
      "[0.7421203438395415, 0.700352526439483, 0.7248545303408146, 0.7000835421888053, 0.7009735744089013, 0.7174301011302796, 0.7008746355685131, 0.7416058394160584, 0.7003367003367004, 0.7244224422442245]\n",
      "data DP\n",
      "0.0420368016507362\n",
      "total accepted \n",
      "finalprecision 0.6719298245614035\n",
      "finalrecall 0.9551122194513716\n",
      "finalaccuracy 0.74375\n",
      "dimension of data\n",
      "10 2400\n",
      "Optimal\n",
      "discripency is:\n",
      "0.52333333\n",
      "gamma-epsilon-delta 0.7 0.3 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6718146718146718 0.9534246575342465 0.7320916905444126\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 518 0.7421203438395415\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6719798657718121 0.9558472553699284 0.7485311398354877\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 1192 0.700352526439483\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9587155963302753 0.9576174112256587 0.9393183707398172\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 872 0.7248545303408146\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.373508353221957 0.9484848484848485 0.5472013366750209\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 838 0.7000835421888053\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.625 0.9603658536585366 0.7190542420027817\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 504 0.7009735744089013\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6915422885572139 0.9531428571428572 0.7543129089827484\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 1206 0.7174301011302796\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7287853577371048 0.9615806805708014 0.7895043731778426\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 1202 0.7008746355685131\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5374015748031497 0.934931506849315 0.6291970802919709\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 508 0.7416058394160584\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.40625 0.9415041782729805 0.5664983164983165\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 832 0.7003367003367004\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9236902050113895 0.9609004739336493 0.9174917491749175\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 878 0.7244224422442245\n",
      "data acceptance rates\n",
      "[0.7421203438395415, 0.700352526439483, 0.7248545303408146, 0.7000835421888053, 0.7009735744089013, 0.7174301011302796, 0.7008746355685131, 0.7416058394160584, 0.7003367003367004, 0.7244224422442245]\n",
      "data DP\n",
      "0.0420368016507362\n",
      "total accepted \n",
      "finalprecision 0.6719298245614035\n",
      "finalrecall 0.9551122194513716\n",
      "finalaccuracy 0.74375\n",
      "dimension of data\n",
      "10 2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal\n",
      "discripency is:\n",
      "0.52333333\n",
      "gamma-epsilon-delta 0.7 0.4 1\n",
      "################################\n",
      "sensitive attribute  1\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6718146718146718 0.9534246575342465 0.7320916905444126\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "698 518 0.7421203438395415\n",
      "sensitive attribute  2\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6719798657718121 0.9558472553699284 0.7485311398354877\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1702 1192 0.700352526439483\n",
      "sensitive attribute  3\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9587155963302753 0.9576174112256587 0.9393183707398172\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1203 872 0.7248545303408146\n",
      "sensitive attribute  4\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.373508353221957 0.9484848484848485 0.5472013366750209\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1197 838 0.7000835421888053\n",
      "sensitive attribute  5\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.625 0.9603658536585366 0.7190542420027817\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "719 504 0.7009735744089013\n",
      "sensitive attribute  6\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.6915422885572139 0.9531428571428572 0.7543129089827484\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1681 1206 0.7174301011302796\n",
      "sensitive attribute  7\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.7287853577371048 0.9615806805708014 0.7895043731778426\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1715 1202 0.7008746355685131\n",
      "sensitive attribute  8\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.5374015748031497 0.934931506849315 0.6291970802919709\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "685 508 0.7416058394160584\n",
      "sensitive attribute  9\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.40625 0.9415041782729805 0.5664983164983165\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1188 832 0.7003367003367004\n",
      "sensitive attribute  10\n",
      "lp ############### prec reca accuracy for each sens\n",
      "0.9236902050113895 0.9609004739336493 0.9174917491749175\n",
      "By lp---------total , accepted, aceeptance rate:\n",
      "1212 878 0.7244224422442245\n",
      "data acceptance rates\n",
      "[0.7421203438395415, 0.700352526439483, 0.7248545303408146, 0.7000835421888053, 0.7009735744089013, 0.7174301011302796, 0.7008746355685131, 0.7416058394160584, 0.7003367003367004, 0.7244224422442245]\n",
      "data DP\n",
      "0.0420368016507362\n",
      "total accepted \n",
      "finalprecision 0.6719298245614035\n",
      "finalrecall 0.9551122194513716\n",
      "finalaccuracy 0.74375\n"
     ]
    }
   ],
   "source": [
    "from random import seed, shuffle\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "data3 = make_classification(n_samples=8000, n_features=20, n_informative=10, n_redundant=10, n_repeated=0, \n",
    "                            n_classes=2, n_clusters_per_class=1, weights=None, flip_y=0.00, class_sep=1.0, \n",
    "                            hypercube=True, shift=0.0, scale=1.0, shuffle=False, random_state=11)\n",
    "df3 = pd.DataFrame(data3[0],columns=['x'+str(i) for i in range(1,21)])\n",
    "df3['y'] = data3[1]\n",
    "# print(df3.head())\n",
    "\n",
    "data=df3.drop(columns=['y'])\n",
    "print(data)\n",
    "r=df3[['y']]\n",
    "print(r)\n",
    "\n",
    "\n",
    "\n",
    "X_test,Y_test,Y_test_pred,e = synthetic_svm(data , r)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "# Y_test_pred.reset_index()\n",
    "Y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(X_test)\n",
    "print(Y_test_pred)\n",
    "print(Y_test)\n",
    "# set_k=2\n",
    "p=5\n",
    "for set_k in np.arange(p,6,2):\n",
    "#for set_k in np.arange(2,11,2): \n",
    "    \n",
    "    sens=X_test[['x'+str(k) for k in range(1,set_k+1)]]\n",
    "#     print(set_k)\n",
    "#     print(sens)\n",
    "\n",
    "\n",
    "    p=sens.shape[0]\n",
    "    q=set_k\n",
    "    for i in range(0,p): \n",
    "        for j in range(0,set_k):  \n",
    "            if sens.iloc[i,j] > 0 :\n",
    "                       sens.iloc[i,j] = 1 \n",
    "            else: \n",
    "                       sens.iloc[i,j] = 0 \n",
    "#     print(sens)\n",
    "\n",
    "    sens1 = pd.get_dummies(sens, columns=['x'+str(k) for k in range(1,set_k+1)])\n",
    "    sensitive=sens1.T\n",
    "\n",
    "    print(sensitive)\n",
    "\n",
    "    # print(r.value_counts())\n",
    "    accu_all,DP_all,acceptance_rate,alpha_weight=main(sensitive, Y_test, Y_test_pred)\n",
    "\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
