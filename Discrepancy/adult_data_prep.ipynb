{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "from time import time\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Import the three supervised learning models from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA    \n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['uniform', 'seed', 'randint', 'sample', 'choice', 'random', 'triangular', 'shuffle']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "#SVM \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "from random import *\n",
    "from subprocess import check_output\n",
    "def adult_svm(X,Y):\n",
    "    #Split data into training and test datasets (training will be based on 70% of data)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0,shuffle=True) \n",
    "    #test_size: if integer, number of examples into test dataset; if between 0.0 and 1.0, means proportion\n",
    "    print('There are {} samples in the training set and {} samples in the test set'.format(X_train.shape[0], X_test.shape[0]))\n",
    "     \n",
    "        \n",
    "    X1=pd.concat([X_train,Y_train],ignore_index=True,axis=1)\n",
    "    X2=pd.concat([X_test,Y_test],ignore_index=True,axis=1)\n",
    "    df=pd.concat([X1,X2],ignore_index=True)\n",
    "    \n",
    "    print(X_train)\n",
    "    print(df)\n",
    "    compression_opts = dict(method='zip', archive_name='adult.csv')  \n",
    "    df.to_csv('adult.zip', index=False, compression=compression_opts)     \n",
    "    \n",
    "    #Scaling data\n",
    "    #from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    #sc = StandardScaler(with_mean=False)\n",
    "    \n",
    "    \n",
    "    #sc.fit(X_train)\n",
    "    #X_train_std = sc.transform(X_train)\n",
    "    #X_test_std = sc.transform(X_test)\n",
    "\n",
    "    #X_train_std and X_test_std are the scaled datasets to be used in algorithms\n",
    "\n",
    "    #Applying SVC (Support Vector Classification)\n",
    "    from sklearn.svm import SVC\n",
    "    svm = SVC(kernel='rbf', random_state=0, gamma=.1, C=10.0)\n",
    "    \n",
    "    print(Y_train.dtypes)\n",
    "    Y_train=Y_train.astype('int')\n",
    "    print(Y_train.dtypes)\n",
    "    \n",
    "    print(Y_test.dtypes)\n",
    "    Y_test=Y_test.astype('int')\n",
    "    print(Y_test.dtypes)\n",
    "    \n",
    "    \n",
    "    svm.fit(X_train, Y_train)\n",
    "    print('The accuracy of the SVM classifier on training data is {:.2f}'.format(svm.score(X_train, Y_train)))\n",
    "    print('The accuracy of the SVM classifier on test data is {:.2f}'.format(svm.score(X_test, Y_test)))\n",
    "    print('####Train prediction Label###############################################')\n",
    "    Y_train_pred=svm.predict(X_train)\n",
    "    #print(y_1)\n",
    "    Y_test_pred=svm.predict(X_test)\n",
    "\n",
    "    print('####Actual Train Label###############################################')\n",
    "\n",
    "\n",
    "    print('####Change to colors###############################################')\n",
    "        \n",
    "    \n",
    "    return X_test,Y_test_pred,Y_test\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without accuracy ---> 2\n",
    "def main(datax, y_test, y_test_pred): \n",
    "        \n",
    "    n=datax.shape[1]\n",
    "    s=datax.shape[0]    \n",
    "    data = np.zeros((s, n), dtype = int)\n",
    "    \n",
    "    r = np.zeros(n, dtype = int) \n",
    "    \n",
    "    for i in range(n):\n",
    "        if int(y_test.iloc[i])==1 :\n",
    "            r[i]=1\n",
    "        else :\n",
    "            r[i]= -1  \n",
    "    \n",
    "    r2 = np.zeros(n, dtype = int) \n",
    "    for i in range(n):\n",
    "        if int(y_test_pred[i])==1 :\n",
    "            r2[i]=1\n",
    "        else :\n",
    "            r2[i]= -1          \n",
    "    ar=[]\n",
    "    \n",
    "    for j in range(s):\n",
    "        print(\"sensitive attribute \",(j+1)) \n",
    "        a=0\n",
    "        b=0\n",
    "        acc1=0\n",
    "        acc2=0\n",
    "        for i in range(n):\n",
    "                data[j][i]= datax.iloc[j,i]\n",
    "                if data[j][i]== 1 :\n",
    "                    a=a+1\n",
    "                    if r[i]==1:\n",
    "                         acc1=acc1+1 \n",
    "\n",
    "        print(\"ACTUAL----------total ,accepted, aceeptance rate:\")             \n",
    "        a1=float(acc1/a)\n",
    "        print(a)\n",
    "        \n",
    "        print(acc1)\n",
    "        print(a1)\n",
    "        ar.append(a1)\n",
    "        \n",
    "    maxi= max(ar)\n",
    "    mini= min(ar)\n",
    "    DP=float(maxi-mini)\n",
    "    print(\"data acceptance rates\")\n",
    "    print(ar)\n",
    "    print(\"data DP\")\n",
    "    print(DP)\n",
    "    \n",
    "    ar=[]\n",
    "    \n",
    "    for j in range(s):\n",
    "        print(\"sensitive attribute \",(j+1)) \n",
    "        a=0\n",
    "        b=0\n",
    "        acc1=0\n",
    "        acc2=0\n",
    "        prec=0\n",
    "        reca=0\n",
    "        accur=0\n",
    "        FP=0\n",
    "        FN=0\n",
    "        TP=0\n",
    "        TN=0\n",
    "        for i in range(n):\n",
    "             if data[j][i]== 1 :\n",
    "                    a=a+1\n",
    "                    if r2[i]==1:\n",
    "                        acc1=acc1+1 \n",
    "                        if r[i]==1:\n",
    "                            TP=TP+1\n",
    "                        else:\n",
    "                             FP=FP+1                \n",
    "                    else:\n",
    "                        if r[i]==1:\n",
    "                            FN=FN+1\n",
    "                        else:\n",
    "                            TN=TN+1    \n",
    "        \n",
    "        print(\"prec reca accuracy for each sens\") \n",
    "        prec= float(TP/(TP+FP))\n",
    "        reca= float(TP/(TP+FN))\n",
    "        accur= float((TP+TN)/a)\n",
    "        print(prec,reca,accur)\n",
    "        \n",
    "        print(\"SVM----------total , accepted, aceeptance rate:\")             \n",
    "        \n",
    "        a1=float(acc1/a)\n",
    "        print(a)\n",
    "        \n",
    "        print(acc1)\n",
    "        print(a1)\n",
    "        ar.append(a1)\n",
    "        \n",
    "    maxi= max(ar)\n",
    "    mini= min(ar)\n",
    "    DP=float(maxi-mini)\n",
    "    print(\"data acceptance rates\")\n",
    "    print(ar)\n",
    "    print(\"data DP\")\n",
    "    print(DP) \n",
    "    \n",
    "    print(\"SVM accuracy--------------------------\")\n",
    "    prec=0\n",
    "    reca=0\n",
    "    accur=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    TP=0\n",
    "    TN=0\n",
    "    for i in range(n):\n",
    "            if r2[i]==1:\n",
    "                acc1=acc1+1 \n",
    "                if r[i]==1:\n",
    "                    TP=TP+1\n",
    "                else:\n",
    "                     FP=FP+1                \n",
    "            else:\n",
    "                if r[i]==1:\n",
    "                     FN=FN+1\n",
    "                else:\n",
    "                     TN=TN+1    \n",
    "\n",
    "        \n",
    "    prec= float(TP/(TP+FP))\n",
    "    reca= float(TP/(TP+FN))\n",
    "    accur= float((TP+TN)/n)\n",
    "    print(prec,reca,accur)\n",
    "    \n",
    "    \n",
    "\n",
    "    delta=1\n",
    "    gama=[.05,.1,.15,.2,.25]\n",
    "    epsilon=[.01,.02,.05,.1,.15,.20,.25,.30,.35,.40,.50]\n",
    "    fi= np.zeros(n,dtype=int) \n",
    "#     for delta in delta1:\n",
    "    for gamma in gama:\n",
    "        for eps in epsilon:\n",
    "            u1,u2=lpc(data,gamma,eps,r2,delta)\n",
    "            #######################Disp_impact#######################  \n",
    "            print(\"gamma-epsilon-delta\",gamma,eps,delta)\n",
    "            accu_all=[]\n",
    "            DP_all=[]\n",
    "            precision_all=[]\n",
    "            recall_all=[]\n",
    "            acceptance_rate=np.zeros((7,28),dtype=float)\n",
    "            count=0\n",
    "#                 for alpha in np.arange(0,1.05,0.05):\n",
    "#                     print(\"alpha: \",alpha)\n",
    "#                     for i in range(n):\n",
    "\n",
    "#                         z=random()\n",
    "#                         if z < alpha:\n",
    "#                                fi[i]= u1[i] \n",
    "\n",
    "#                         else:\n",
    "#                                fi[i]= r2[i]\n",
    "\n",
    "            for i in range(n):\n",
    "                 fi[i] = u1[i]\n",
    "            ar=[]\n",
    "\n",
    "            for j in range(s):\n",
    "#                         print(\"sensitive attribute \",(j+1)) \n",
    "                a=0\n",
    "                b=0\n",
    "                acc1=0\n",
    "                acc2=0\n",
    "                for i in range(n):\n",
    "                        if data[j][i]== 1 :\n",
    "                            a=a+1\n",
    "                            if fi[i]==1:\n",
    "                                 acc1=acc1+1 \n",
    "\n",
    "#                         print(\"total ,fair accepted, aceeptance rate:\")             \n",
    "                a1=float(acc1/a)\n",
    "                acceptance_rate[j][count]=float(a1)\n",
    "                \n",
    "\n",
    "#                         print(a)\n",
    "#                         print(acc1)\n",
    "#                         print(a1)\n",
    "                ar.append(a1)\n",
    "  \n",
    "            count = count+1\n",
    "            maxi=max(ar)\n",
    "            mini= min(ar)\n",
    "            DP=float(maxi-mini)\n",
    "            print(\"acceptance rates\")\n",
    "            print(ar)\n",
    "            print(\"DP\")\n",
    "            print(DP)\n",
    "            f_acc=0\n",
    "            for i in range(n):\n",
    "                 if fi[i] == r[i]:\n",
    "                        f_acc=f_acc+1\n",
    "            f_acc_l=float((f_acc*100)/n) \n",
    "            \n",
    " #######################################################################33   \n",
    "           \n",
    "#                         print(\"sensitive attribute \",(j+1)) \n",
    "            TP=0\n",
    "            FP=0\n",
    "            FN=0\n",
    "            precision=1\n",
    "            for i in range(n):\n",
    "                    if fi[i]==1 and r[i]==1:\n",
    "                        TP=TP+1\n",
    "                    if fi[i]==1 and r[i]==-1:\n",
    "                        FP=FP+1 \n",
    "                    if fi[i]==-1 and r[i]==1:\n",
    "                        FN=FN+1\n",
    "                            \n",
    "            precision=float(TP/(TP+FP))\n",
    "            print(precision)\n",
    "            recall=float(TP/(TP+FN))\n",
    "            print(recall)\n",
    "#                         print(\"total ,fair accepted, aceeptance rate:\")             \n",
    "            a1=float(acc1/a)\n",
    "            acceptance_rate[j][count]=float(a1)\n",
    "                \n",
    "\n",
    "#                         print(a)\n",
    "#                         print(acc1)\n",
    "#                         print(a1)\n",
    "              \n",
    "    \n",
    " ###############################################################################################             \n",
    "#                     print(\"accuracy : \",f_acc_l)\n",
    "            \n",
    "            precision_all.append(precision)\n",
    "            recall_all.append(recall)\n",
    "            accu_all.append(f_acc_l)\n",
    "            DP_all.append(DP)\n",
    "            print(\"precision\", precision_all)\n",
    "            print(\"recall\", recall_all)\n",
    "            print(\"final: acc\", accu_all)\n",
    "            print(\"final: dp\", DP_all)\n",
    "            \n",
    "    alpha_weight=np.arange(0,1.05,.05)        \n",
    "    return accu_all,DP_all,acceptance_rate,alpha_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NG\n",
    "import time\n",
    "import pulp as p \n",
    "def lpc(data1,gamma,eps,r,delta):\n",
    "    import pulp as p \n",
    "    \n",
    "    m=data1.shape[0]\n",
    "    n=data1.shape[1]\n",
    "    print('dimension of data')\n",
    "    print(m,n)\n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMaximize)  \n",
    "   \n",
    "    \n",
    "#     X=np.zeros(n+1,dtype=p.LpVariable)\n",
    "    X=np.zeros(n+1,dtype=p.LpVariable)\n",
    "    sizes=np.zeros(m,dtype=int)\n",
    "    for i in range(m):\n",
    "        count=0\n",
    "        for j in range(n):\n",
    "            if data1[i][j]==1:\n",
    "                count=count+1               \n",
    "        sizes[i]=count\n",
    "  \n",
    "\n",
    "    for i in range(n):\n",
    "        var1=str(i)       \n",
    "        X[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Integer')\n",
    "    \n",
    "    X[n]=p.LpVariable(str(n),lowBound=0,upBound=1,cat='Continuous')   \n",
    "        \n",
    "\n",
    "    #########objective function#####################\n",
    "        \n",
    "    Lp_prob += X[n]\n",
    "\n",
    "\n",
    "    ##############constraint#################\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "#             Lp_prob += X[n] >= p.lpSum([2*(X[j]-0.5)*data1[i][j] for j in range(n)])\n",
    "            Lp_prob += p.lpSum([2*(X[j]-0.5)*data1[i][j] for j in range(n)]) >= (2*gamma-1)*sizes[i]\n",
    "            Lp_prob += p.lpSum([2*(X[j]-0.5)*data1[i][j] for j in range(n)]) <= ((2*gamma-1)+eps)*sizes[i]\n",
    "            \n",
    "  \n",
    "    Lp_prob += p.lpSum([2*(X[i]-0.5)*r[i] for i in range(n)]) >= X[n]*n\n",
    "\n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status]) \n",
    "    print(\"discripency is:\")        \n",
    "    print(p.value(Lp_prob.objective))\n",
    "    \n",
    "    x=np.zeros(n,dtype=float)\n",
    "\n",
    "   # The solution status \n",
    "    Synth1={}\n",
    "    Synth2={}\n",
    "    # # Printing the final solution \n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])==1):\n",
    "            Synth1[i]=1 \n",
    "            Synth2[i]=-1\n",
    "        else:\n",
    "            Synth1[i]=-1\n",
    "            Synth2[i]=1\n",
    "    Synthu1=Synth1  \n",
    "    Synthu2=Synth2  \n",
    "    \n",
    "              \n",
    "    return Synthu1,Synthu2   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "private             0.738877\n",
      "self-emp-not-inc    0.082853\n",
      "local-gov           0.068530\n",
      "state-gov           0.042404\n",
      "self-emp-inc        0.035608\n",
      "federal-gov         0.031265\n",
      "without-pay         0.000464\n",
      "Name: workclass, dtype: float64 \n",
      "\n",
      "hs-grad         0.326238\n",
      "some-college    0.221404\n",
      "bachelors       0.167230\n",
      "masters         0.053942\n",
      "assoc-voc       0.043333\n",
      "11th            0.034746\n",
      "assoc-acdm      0.033420\n",
      "10th            0.027187\n",
      "7th-8th         0.018467\n",
      "prof-school     0.017970\n",
      "9th             0.015085\n",
      "12th            0.012499\n",
      "doctorate       0.012433\n",
      "5th-6th         0.009548\n",
      "1st-4th         0.005006\n",
      "preschool       0.001492\n",
      "Name: education, dtype: float64 \n",
      "\n",
      "married-civ-spouse       0.466315\n",
      "never-married            0.322459\n",
      "divorced                 0.139712\n",
      "separated                0.031132\n",
      "widowed                  0.027419\n",
      "married-spouse-absent    0.012267\n",
      "married-af-spouse        0.000696\n",
      "Name: marital-status, dtype: float64 \n",
      "\n",
      "prof-specialty       0.133877\n",
      "craft-repair         0.133612\n",
      "exec-managerial      0.132352\n",
      "adm-clerical         0.123367\n",
      "sales                0.118825\n",
      "other-service        0.106492\n",
      "machine-op-inspct    0.065181\n",
      "transport-moving     0.052119\n",
      "handlers-cleaners    0.044758\n",
      "farming-fishing      0.032790\n",
      "tech-support         0.030237\n",
      "protective-serv      0.021351\n",
      "priv-house-serv      0.004741\n",
      "armed-forces         0.000298\n",
      "Name: occupation, dtype: float64 \n",
      "\n",
      "husband           0.413202\n",
      "not-in-family     0.256150\n",
      "own-child         0.148067\n",
      "unmarried         0.106492\n",
      "wife              0.046615\n",
      "other-relative    0.029474\n",
      "Name: relationship, dtype: float64 \n",
      "\n",
      "white                 0.859790\n",
      "black                 0.093396\n",
      "asian-pac-islander    0.029673\n",
      "amer-indian-eskimo    0.009482\n",
      "other                 0.007659\n",
      "Name: race, dtype: float64 \n",
      "\n",
      "male      0.675685\n",
      "female    0.324315\n",
      "Name: sex, dtype: float64 \n",
      "\n",
      "united-states                 0.911876\n",
      "mexico                        0.020224\n",
      "philippines                   0.006233\n",
      "germany                       0.004244\n",
      "puerto-rico                   0.003614\n",
      "canada                        0.003548\n",
      "el-salvador                   0.003315\n",
      "india                         0.003315\n",
      "cuba                          0.003050\n",
      "england                       0.002851\n",
      "jamaica                       0.002652\n",
      "south                         0.002354\n",
      "china                         0.002254\n",
      "italy                         0.002254\n",
      "dominican-republic            0.002221\n",
      "vietnam                       0.002122\n",
      "guatemala                     0.002089\n",
      "japan                         0.001956\n",
      "columbia                      0.001857\n",
      "poland                        0.001857\n",
      "haiti                         0.001392\n",
      "iran                          0.001392\n",
      "taiwan                        0.001392\n",
      "portugal                      0.001127\n",
      "nicaragua                     0.001094\n",
      "peru                          0.000995\n",
      "greece                        0.000961\n",
      "france                        0.000895\n",
      "ecuador                       0.000895\n",
      "ireland                       0.000796\n",
      "hong                          0.000630\n",
      "cambodia                      0.000597\n",
      "trinadad&tobago               0.000597\n",
      "thailand                      0.000564\n",
      "laos                          0.000564\n",
      "yugoslavia                    0.000530\n",
      "outlying-us(guam-usvi-etc)    0.000464\n",
      "hungary                       0.000431\n",
      "honduras                      0.000398\n",
      "scotland                      0.000365\n",
      "holand-netherlands            0.000033\n",
      "Name: native-country, dtype: float64 \n",
      "\n",
      "<=50k    0.751078\n",
      ">50k     0.248922\n",
      "Name: income, dtype: float64 \n",
      "\n",
      "There are 31654 samples in the training set and 13567 samples in the test set\n",
      "       age         workclass  fnlwgt     education  education-num  \\\n",
      "10300   18           private  190325          11th              7   \n",
      "39301   41           private  107845     bachelors             13   \n",
      "2666    42           private  200574  some-college             10   \n",
      "17989   20           private  164219       hs-grad              9   \n",
      "11495   40           private  110028  some-college             10   \n",
      "...    ...               ...     ...           ...            ...   \n",
      "30403   26           private  132179     bachelors             13   \n",
      "21243   39      self-emp-inc  188069     assoc-voc             11   \n",
      "42613   64  self-emp-not-inc  167877       hs-grad              9   \n",
      "43567   48           private  183000  some-college             10   \n",
      "2732    34           private  182177       hs-grad              9   \n",
      "\n",
      "           marital-status         occupation   relationship   race     sex  \\\n",
      "10300       never-married       craft-repair      own-child  white    male   \n",
      "39301  married-civ-spouse     prof-specialty           wife  white  female   \n",
      "2666   married-civ-spouse              sales        husband  white    male   \n",
      "17989       never-married  handlers-cleaners      own-child  white    male   \n",
      "11495  married-civ-spouse       craft-repair        husband  white    male   \n",
      "...                   ...                ...            ...    ...     ...   \n",
      "30403       never-married       adm-clerical      own-child  white  female   \n",
      "21243  married-civ-spouse    exec-managerial        husband  white    male   \n",
      "42613  married-civ-spouse     prof-specialty        husband  white    male   \n",
      "43567  married-civ-spouse      other-service        husband  black    male   \n",
      "2732             divorced       craft-repair  not-in-family  white    male   \n",
      "\n",
      "       capital-gain  capital-loss  hours-per-week native-country  \n",
      "10300             0             0              30  united-states  \n",
      "39301             0             0              40  united-states  \n",
      "2666              0             0              40  united-states  \n",
      "17989             0             0              45  united-states  \n",
      "11495             0             0              40  united-states  \n",
      "...             ...           ...             ...            ...  \n",
      "30403             0             0              40  united-states  \n",
      "21243             0             0              60  united-states  \n",
      "42613             0             0              60  united-states  \n",
      "43567             0             0              40  united-states  \n",
      "2732           3325             0              35  united-states  \n",
      "\n",
      "[31654 rows x 14 columns]\n",
      "        0        1       2             3   4                   5  \\\n",
      "0      18  private  190325          11th   7       never-married   \n",
      "1      41  private  107845     bachelors  13  married-civ-spouse   \n",
      "2      42  private  200574  some-college  10  married-civ-spouse   \n",
      "3      20  private  164219       hs-grad   9       never-married   \n",
      "4      40  private  110028  some-college  10  married-civ-spouse   \n",
      "...    ..      ...     ...           ...  ..                 ...   \n",
      "45216  34  private  177437  some-college  10  married-civ-spouse   \n",
      "45217  25  private  145434  some-college  10       never-married   \n",
      "45218  49  private  245305          10th   6  married-civ-spouse   \n",
      "45219  32  private  360593       hs-grad   9            divorced   \n",
      "45220  17  private   35603          12th   8       never-married   \n",
      "\n",
      "                       6              7      8       9     10  11  12  \\\n",
      "0           craft-repair      own-child  white    male      0   0  30   \n",
      "1         prof-specialty           wife  white  female      0   0  40   \n",
      "2                  sales        husband  white    male      0   0  40   \n",
      "3      handlers-cleaners      own-child  white    male      0   0  45   \n",
      "4           craft-repair        husband  white    male      0   0  40   \n",
      "...                  ...            ...    ...     ...    ...  ..  ..   \n",
      "45216       craft-repair        husband  white    male  15024   0  45   \n",
      "45217  machine-op-inspct  not-in-family  white  female      0   0  25   \n",
      "45218   transport-moving        husband  black    male      0   0  42   \n",
      "45219              sales      unmarried  black  female      0   0  30   \n",
      "45220              sales      own-child  white  female      0   0  20   \n",
      "\n",
      "                  13     14  \n",
      "0      united-states  <=50k  \n",
      "1      united-states   >50k  \n",
      "2      united-states  <=50k  \n",
      "3      united-states  <=50k  \n",
      "4      united-states  <=50k  \n",
      "...              ...    ...  \n",
      "45216  united-states   >50k  \n",
      "45217  united-states  <=50k  \n",
      "45218  united-states   >50k  \n",
      "45219  united-states  <=50k  \n",
      "45220  united-states  <=50k  \n",
      "\n",
      "[45221 rows x 15 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '<=50k'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e5a52e8e9ebb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madult_svm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-7eaa9fb577ad>\u001b[0m in \u001b[0;36madult_svm\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mY_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5696\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5697\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5698\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5699\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, filter, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0mvals1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[0;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype_intsafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0;31m# if we have a datetime/timedelta array of objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '<=50k'"
     ]
    }
   ],
   "source": [
    "# without accuracy\n",
    "import time\n",
    "# import pulp as p \n",
    "# from random import *\n",
    "\n",
    "# Add column names to data set\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', \n",
    "           'relationship', 'race','sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "\n",
    "# Read in train data\n",
    "adult_train = pd.read_csv('data/adult_actual/adult_train_data.csv', header=None, names=columns, skipinitialspace=True)\n",
    "\n",
    "# Drop the fnlwgt column which is useless for later analysis\n",
    "\n",
    "     #adult_train = adult_train.drop('fnlwgt', axis=1)\n",
    "\n",
    "# Read in test data\n",
    "\n",
    "adult_test = pd.read_csv('data/adult_actual/adult_test_data.csv', header=None, skiprows=1, names=columns, skipinitialspace=True)\n",
    "\n",
    "# Drop the fnlwgt column which is useless for later analysis\n",
    "\n",
    "     #adult_test = adult_test.drop('fnlwgt', axis=1)\n",
    "\n",
    "# Remove '.' in income column\n",
    "adult_test['income'] = adult_test['income'].apply(lambda x: '>50k' if x=='>50k.'  else '<=50k')\n",
    "\n",
    "\n",
    "# Convert '?' to NaNs and remove the entries with NaN value\n",
    "# Check missing value code and convert to NaNs\n",
    "object_col = adult_train.select_dtypes(include=object).columns.tolist()\n",
    "for col in object_col:\n",
    "    adult_train.loc[adult_train[col]=='?', col] = np.nan\n",
    "    adult_test.loc[adult_test[col]=='?', col] = np.nan\n",
    "\n",
    "# Perform an mssing assessment in each column of the dataset.\n",
    "col_missing_pct = adult_train.isna().sum()/adult_train.shape[0]\n",
    "col_missing_pct.sort_values(ascending=False)\n",
    "\n",
    "# Remove data entries with missing value\n",
    "adult_train = adult_train.dropna(axis=0, how='any')\n",
    "adult_test = adult_test.dropna(axis=0, how='any')\n",
    "\n",
    "# Show the results of the split\n",
    "# print(\"After removing the missing value:\")\n",
    "# print(\"Training set has {} samples.\".format(adult_train.shape[0]))\n",
    "# print(\"Testing set has {} samples.\".format(adult_test.shape[0]))\n",
    "for col in object_col:\n",
    "    print(adult_train[col].value_counts(dropna=False)/adult_train.shape[0],'\\n')\n",
    "# print(adult_train.head())\n",
    "# print(adult_test.head())    \n",
    "\n",
    "adult_train.reset_index(drop=True, inplace=True)\n",
    "adult_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "p=adult_train.shape[0]\n",
    "q =adult_test.shape[0]\n",
    "###############################################################I commented you uncomment\n",
    "    \n",
    "#####################################################################################3##########            \n",
    "# print(adult_train.head())\n",
    "# print(adult_test.head())\n",
    "DATA=pd.concat([adult_train,adult_test],ignore_index=True)\n",
    "# # print(DATA.tail())\n",
    "m=DATA.shape[1]\n",
    "\n",
    "dat=DATA.iloc[:,0:m-1]\n",
    "\n",
    "\n",
    "r=DATA.iloc[:,m-1]\n",
    "\n",
    "\n",
    "\n",
    "X_test,Y_test_pred,Y_test = adult_svm(dat , r)\n",
    "\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "# Y_test_pred.reset_index()\n",
    "Y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "sens=X_test[['s_male', 's_female'  ,'r_white', 'r_black', 'r_asian-pac-islander','r_amer-indian-eskimo','r_other']]\n",
    "# print(sens)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "sensitive = sens.T\n",
    "\n",
    "\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred )\n",
    "\n",
    "\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
